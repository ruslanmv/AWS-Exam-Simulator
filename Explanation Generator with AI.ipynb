{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation Generator with AI\n",
    "In this program we are going to check and create the explation of all questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Get the current working directory\n",
    "json_file_paths=[]\n",
    "current_dir = os.getcwd()\n",
    "directory = os.path.join(current_dir,\"questions\")\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            #pdf_file_paths.append(file)  # remove the .json extension\n",
    "            json_file_paths.append(os.path.join(root, file))  # include the full path\n",
    "\n",
    "print(\"JSON files:\", json_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_paths[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def qa(prompt):\n",
    "    # In a real application, replace with your LLM API call (e.g., OpenAI)\n",
    "    return prompt\n",
    "def process_question(question_data):\n",
    "    \"\"\"Constructs a string for LLM prompt and gets an explanation.\"\"\"\n",
    "    system= '''You are expert in the Cloud, your task is give an explanation about the\n",
    "    correct answer and explain why the other options are wrong. The question is the following:'''\n",
    "\n",
    "    context = f\"Question: {question_data['question']}\\n\"\n",
    "    for i, option in enumerate(question_data['options']):\n",
    "        context += f\"{i+1}. {option}\\n\"\n",
    "    context += f\"Correct Answer: {question_data['correct']}\\n\\n\"\n",
    "    prompt=system+context\n",
    "    #This is where you'd get an explanation from your LLM.\n",
    "    explanation = qa(prompt)\n",
    "    return explanation\n",
    "\n",
    "\n",
    "def update_json_file(file_path):\n",
    "    \"\"\"Reads, processes, and updates the JSON file with explanations.\"\"\"\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        questions = json.load(file)\n",
    "\n",
    "    for question in questions:\n",
    "        # Check if the question already has an explanation\n",
    "        if \"explanation\" not in question:\n",
    "            #print(question)\n",
    "            explanation = process_question(question)\n",
    "            print(explanation)\n",
    "\n",
    "            question[\"explanation\"] = explanation\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(questions, file, indent=4)  # Format with indentation \n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "file_path = r'c:\\Blog\\AWS-Exam-Simulator\\questions\\CLF-C02-v1.json'  # Raw string\n",
    "update_json_file(file_path)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "# Replace 'YOUR_AZURE_OPENAI_API_KEY' and 'YOUR_AZURE_OPENAI_ENDPOINT' with your actual key and endpoint\n",
    "AZURE_OPENAI_API_KEY = 'YOUR_AZURE_OPENAI_API_KEY'\n",
    "AZURE_OPENAI_ENDPOINT = 'YOUR_AZURE_OPENAI_ENDPOINT'\n",
    "\n",
    "openai.api_key = AZURE_OPENAI_API_KEY\n",
    "openai.api_base = AZURE_OPENAI_ENDPOINT\n",
    "\n",
    "def qa(prompt):\n",
    "    \"\"\"\n",
    "    Function to call Azure OpenAI API with the given prompt.\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",  # Use the appropriate engine name\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "def process_question(question_data):\n",
    "    \"\"\"Constructs a string for LLM prompt and gets an explanation.\"\"\"\n",
    "    system = '''You are an expert in the Cloud. Your task is to give an explanation about the correct answer and explain why the other options are wrong. The question is the following:\\n\\n'''\n",
    "    context = f\"Question: {question_data['question']}\\n\"\n",
    "    for i, option in enumerate(question_data['options']):\n",
    "        context += f\"{i+1}. {option}\\n\"\n",
    "    context += f\"Correct Answer: {question_data['correct']}\\n\\n\"\n",
    "    prompt = system + context\n",
    "\n",
    "    # Get an explanation from Azure OpenAI\n",
    "    explanation = qa(prompt)\n",
    "    return explanation\n",
    "\n",
    "def update_json_file(file_path):\n",
    "    \"\"\"Reads, processes, and updates the JSON file with explanations.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        questions = json.load(file)\n",
    "\n",
    "    for question in questions:\n",
    "        # Check if the question already has an explanation\n",
    "        if \"explanation\" not in question:\n",
    "            explanation = process_question(question)\n",
    "            print(explanation)\n",
    "            question[\"explanation\"] = explanation\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(questions, file, indent=4)  # Format with indentation\n",
    "\n",
    "# --- Main Execution ---\n",
    "file_path = r'c:\\Blog\\AWS-Exam-Simulator\\questions\\CLF-C02-v1.json'  # Raw string\n",
    "update_json_file(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
