{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ibm import WatsonxLLM\n",
    "from dotenv import load_dotenv\n",
    "from os import environ, getenv\n",
    "from getpass import getpass\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Function to set environment variables\n",
    "def set_env(var: str):\n",
    "    env_var = getenv(var)\n",
    "    if not env_var:\n",
    "        env_var = getpass(f\"{var}: \")\n",
    "        environ[var] = env_var\n",
    "    return env_var\n",
    "\n",
    "# Define IBM connection parameters\n",
    "class IbmConnectionParams(BaseModel):\n",
    "    api_key: str\n",
    "    project_id: str\n",
    "    url: str\n",
    "    credentials: dict[str, str]\n",
    "\n",
    "    def __init__(self, api_key: str, project_id: str, url: str) -> None:\n",
    "        super().__init__(api_key=api_key, project_id=project_id, url=url, credentials={\"url\": url, \"apikey\": api_key})\n",
    "\n",
    "# Load IBM connection parameters from environment variables\n",
    "def load_connection_params() -> IbmConnectionParams:\n",
    "    api_key = set_env(\"WATSONX_API_KEY\")\n",
    "    project_id = set_env(\"PROJECT_ID\")\n",
    "    url = set_env(\"WATSONX_URL\")\n",
    "\n",
    "    return IbmConnectionParams(api_key=api_key, project_id=project_id, url=url)\n",
    "\n",
    "connection_params: IbmConnectionParams = load_connection_params()\n",
    "\n",
    "# Define parameters for the model\n",
    "parameters = {\n",
    "    \"decoding_method\": \"sample\",\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"min_new_tokens\": 1,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 1,\n",
    "}\n",
    "\n",
    "# Initialize the WatsonxLLM model\n",
    "watsonx_llm = WatsonxLLM(\n",
    "    model_id=\"meta-llama/llama-3-70b-instruct\",\n",
    "    apikey=connection_params.api_key,\n",
    "    url=connection_params.url,\n",
    "    project_id=connection_params.project_id,\n",
    "    params=parameters,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the system prompt\n",
    "system_prompt = (\n",
    "    \"You are an expert in Cloud technologies. Your task is to provide an explanation about the \"\n",
    "    \"correct answer and explain why the other options are incorrect. \"\n",
    ")\n",
    "\n",
    "# Initialize the prompt template\n",
    "prompt_template = PromptTemplate(input_variables=[], template=system_prompt)\n",
    "\n",
    "# Combine the system prompt with the user's prompt\n",
    "def create_full_prompt(user_prompt: str) -> str:\n",
    "    return f\"{system_prompt}\\n\\n{user_prompt}\"\n",
    "\n",
    "# Function to interact with the WatsonxLLM model\n",
    "def qa(prompt):\n",
    "    full_prompt = create_full_prompt(prompt)\n",
    "    response = watsonx_llm.invoke(full_prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question(question_data, exp=False):\n",
    "    \"\"\"Constructs a string for LLM prompt and gets an explanation.\"\"\"\n",
    "    if exp:\n",
    "       system = '''You are an expert in the Cloud. Your task is to give an explanation about the\n",
    "    correct answer and explain why the other options are wrong. The question is the following:'''\n",
    "    else: \n",
    "        system = '''You are an expert in the Cloud. Your task is to give an explanation about the\n",
    "    correct answer and explain why the other options are wrong.\n",
    "    You will recieve additional explantion that maybe can help otherwise give your explanation. \n",
    "    The question and explanation are the following:'''\n",
    "\n",
    "    context = f\"Question: {question_data['question']}\\n\"\n",
    "    for i, option in enumerate(question_data['options']):\n",
    "        context += f\"{i+1}. {option}\\n\"\n",
    "    context += f\"Correct Answer: {question_data['correct']}\\n\\n\"\n",
    "    prompt = system + context\n",
    "    print(\"prompt:\",prompt)\n",
    "    explanation = qa(prompt)\n",
    "    return explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution ---\n",
    "file_path = r'c:\\Blog\\AWS-Exam-Simulator\\questions\\CLF-C02-v1.json'  # Raw string\n",
    "with open(file_path, 'r') as file:\n",
    "    questions = json.load(file)\n",
    "    len(questions)\n",
    "for question in questions[:1]:\n",
    "    print(question)\n",
    "    # Check if the question already has an explanation\n",
    "    #if \"explanation\" not in question:\n",
    "    explanation = process_question(question)\n",
    "    print(\"explanation:\",explanation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_json_file(file_path):\n",
    "    \"\"\"Reads, processes, and updates the JSON file with explanations.\"\"\"  \n",
    "    with open(file_path, 'r') as file:\n",
    "        questions = json.load(file)\n",
    "    for question in questions[:1]:\n",
    "        # Check if the question already has an explanation\n",
    "        if \"explanation\" not in question:\n",
    "            explanation = process_question(question,exp=False)\n",
    "            print(explanation)\n",
    "            question[\"explanation\"] = explanation\n",
    "        else:\n",
    "            old_explanation=question[\"explanation\"]\n",
    "            prompt= question + \" Explanation \" + str(old_explanation)\n",
    "            explanation = process_question(prompt, exp=True)\n",
    "            print(explanation)\n",
    "            question[\"explanation\"] = explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def update_json_file(file_path):\n",
    "    \"\"\"Reads, processes, and updates the JSON file with explanations.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        questions = json.load(file)\n",
    "\n",
    "    for question in questions[:1]:\n",
    "        # Check if the question already has an explanation\n",
    "        if \"explanation\" not in question:\n",
    "            explanation = process_question(question, exp=False)\n",
    "            print(f\"New Explanation: {explanation}\")\n",
    "        else:\n",
    "            old_explanation = question[\"explanation\"]\n",
    "            explanation = process_question(question, exp=True)\n",
    "            print(\"Old Explanation:\", old_explanation)\n",
    "            print(\"New Explanation:\", explanation)\n",
    "\n",
    "        # Update the question's explanation in both cases\n",
    "        question[\"explanation\"] = explanation\n",
    "\n",
    "    # Write the updated questions back to the JSON file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(questions, file, indent=4) \n",
    "        # Format with indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution ---\n",
    "#file_path = r'c:\\Blog\\AWS-Exam-Simulator\\questions\\CLF-C02-v1.json'  # Raw string\n",
    "file_path = r'c:\\Blog\\AWS-Exam-Simulator\\questions\\GCP-ML-vA.json'  # Raw string\n",
    "update_json_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Get the current working directory\n",
    "json_file_paths=[]\n",
    "current_dir = os.getcwd()\n",
    "directory = os.path.join(current_dir,\"questions\")\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            #pdf_file_paths.append(file)  # remove the .json extension\n",
    "            json_file_paths.append(os.path.join(root, file))  # include the full path\n",
    "\n",
    "print(\"JSON files:\", json_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_paths=[\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\GCP-ML-vA.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\GCP-ML-vB.json',  \n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\SAA-C03-v1.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\SAA-C03-v2.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\SAP-C02-v1.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\MLS-C01-v0624.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\MLS-C01-v1.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\MLS-C01-v2.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\MLS-C01-v3.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\MLS-C01-v4.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\MLS-C01.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\AI-102.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\AI-900-v1.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\AI-900-v2.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\AI-900-v3.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\CLF-C02-v1.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\DOP-C02-v1.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\DP-100-v1.json',\n",
    " 'c:\\\\Blog\\\\AWS-Exam-Simulator\\\\questions\\\\GCP-CA.json',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# --- Main Execution ---\n",
    "for file_path in json_file_paths[:2]:\n",
    "    #file_path = r'c:\\Blog\\AWS-Exam-Simulator\\questions\\CLF-C02-v1.json'  # Raw string\n",
    "    #file_path = r'c:\\Blog\\AWS-Exam-Simulator\\questions\\GCP-ML-vA.json'  # Raw string  \n",
    "    file_name = os.path.basename(file_path) # Extract file name with extension\n",
    "    print(\"Working with:\", file_name) \n",
    "    update_json_file(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
