[
    {
        "question": "DRAG DROP You are developing the smart e-commerce project. You need to design the skillset to include the cont ents of PDFs in searches. How should you complete the skillset design diagram ? To answer, drag the appropriate services to the correct stages. Each service may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "The correct answer is: \n\nA. Azure Form Recognizer \nB. Azure Cognitive Search \nC. Azure Cognitive Search \nD. Azure Function \n\nExplanation: \n\nThe correct answer is A, B, C, D. \n\nThe correct sequence for designing a skillset to include the contents of PDFs in searches is: \n\n1. Azure Form Recognizer: This service is used to extract structured data from unstructured documents like PDFs. It uses AI-powered OCR and document analysis to extract key-value pairs, tables, and other information from the documents. \n\n2. Azure Cognitive Search: This service is used to index and search the extracted data. It provides a cloud-based search service that allows developers to add search capabilities to their applications. \n\n3. Azure Cognitive Search: This service is used again to store the extracted data and make it searchable. \n\n4. Azure Function: This service is used to integrate Azure Form Recognizer with Azure Cognitive Search. It provides an event-driven, serverless computing platform that can be used to automate the data extraction and indexing process.\n\nThe other options are incorrect because they do not follow the correct sequence of services for designing a skillset to include the contents of PDFs in searches.",
        "references": "https://docs.microsoft.com/en-us/azure/search/cogni tive-search-concept-intro https://docs.microsoft.com/en-us/azure/cognitive-se rvices/computer-vision/overview-ocr"
    },
    {
        "question": "DRAG DROP You are planning the product creation project. You need to recommend a process for analyzing video s. Which four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order. (Choose four.) A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Ingest video files to cloud-based object storage.\nB. Use video analysis AI models to analyze the video files.\nC. Store the analyzed video files in a database.\nD. Use a workflow management tool to orchestrate the video analysis process.\n\nExplanation: \n\nThe correct answer is A, B, D, C. Here's why: \n\n**A. Ingest video files to cloud-based object storage:** This is the first step because you need to store the video files somewhere before you can analyze them. Cloud-based object storage is a good choice because it's scalable and cost-effective.\n\n**B. Use video analysis AI models to analyze the video files:** Once the video files are stored, you can use AI models to analyze them. This step involves applying machine learning algorithms to extract insights from the videos.\n\n**D. Use a workflow management tool to orchestrate the video analysis process:** After analyzing the video files, you need to manage the workflow to ensure that the process runs smoothly and efficiently. This involves automating tasks, tracking progress, and handling errors.\n\n**C. Store the analyzed video files in a database:** Finally, you need to store the analyzed video files in a database for further processing or retrieval. This step involves storing the extracted insights and metadata in a structured format.\n\nThe other options are incorrect because they don't follow the correct sequence of actions. For example, you can't analyze the video files before ingesting them, and you can't store the analyzed files before",
        "references": "https://azure.microsoft.com/en-us/blog/get-video-in sights-in-even-more-languages/ https://docs.microsoft.com/en-us/azure/media-servic es/video-indexer/video-indexer-output-jsonv2"
    },
    {
        "question": "HOTSPOT You are planning the product creation project. You need to build the REST endpoint to create the m ultilingual product descriptions. How should you complete the URI? To answer, select the appropriate options in the answer area. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. /products/{productId}/descriptions/{languageCode} \n\nExplanation: \n\nThe correct answer is A. /products/{productId}/descriptions/{languageCode}. \n\nThis URI is a well-structured REST endpoint for creating multilingual product descriptions. \n\nHere's why: \n\n* /products/{productId} is used to identify the product for which the description is being created. \n* /descriptions/{languageCode} specifies the language of the description being created. \n\nThis endpoint allows the API to create descriptions for different languages and associate them with the correct product. \n\nNow, let's look at the other options: \n\nOption B is incorrect because it doesn't provide a way to specify the language code. \n\nOption C is incorrect because it doesn't provide a way to specify the product ID. \n\nOption D is incorrect because it is not a RESTful endpoint. \n\nTherefore, option A is the correct answer.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/translator/reference/v3-0-translate"
    },
    {
        "question": "You are developing the smart e-commerce project. You need to implement autocompletion as part of the  Cognitive Search solution. Which three actions should you perform? Each correc t answer presents part of the solution. (Choose three.) NOTE: Each correct selection is worth one point.",
        "options": [
            "A. Make API queries to the autocomplete endpoint and  include suggesterName in the body.",
            "B. Add a suggester that has the three product name f ields as source fields.",
            "C. Make API queries to the search endpoint and inclu de the product name fields in the searchFields",
            "D. Add a suggester for each of the three product nam e fields."
        ],
        "correct": "",
        "explanation": "A, B, D\n\nExplanation: \n\nTo implement autocompletion in Cognitive Search, you need to create a suggester that specifies the fields to be used for autocompletion. You then need to make API queries to the autocomplete endpoint, specifying the suggester name in the body of the request. Additionally, you need to create a separate suggester for each field that you want to include in the autocompletion.\n\nNow, let me explain why the other options are incorrect:\n\nOption C is incorrect because making API queries to the search endpoint would not provide autocompletion functionality. Instead, you need to make API queries to the autocomplete endpoint.\n\nNow, let me explain why the other options are incorrect:\n\nOption C is incorrect because making API queries to the search endpoint would not provide autocompletion functionality. Instead, you need to make API queries to the autocomplete endpoint.",
        "references": "https://docs.microsoft.com/en-us/azure/search/index -add-suggesters"
    },
    {
        "question": "HOTSPOT You are developing the shopping on-the-go project. You are configuring access to the QnA Maker resourc es. Which role should you assign to AllUsers and Leader shipTeam? To answer, select the appropriate options in the answer area. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D. Correct Answer:"
        ],
        "correct": "",
        "explanation": "C. Cognitive Services QnA Maker Reader \nD. Cognitive Services Contributor",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/qnamaker/reference-role-based-accesscontrol"
    },
    {
        "question": "HOTSPOT You need to develop code to upload images for the p roduct creation project. The solution must meet the accessibility requirements. How should you complete the code? To answer, select  the appropriate options in the answer area. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. 1 and C.\n\nExplanation: The correct answer is A. 1 and C. because the code should upload the images to Azure Blob Storage (1) and use Azure Cognitive Services to generate image descriptions for accessibility (C).\n\nOption B is incorrect because Azure File Storage is not suitable for storing images. \n\nOption D is incorrect because Azure Queue Storage is used for messaging and not for storing images.\n\nNow, I will ask you a series of questions, and you provide the explanation for each correct answer and explain why the other options are incorrect.",
        "references": "https://github.com/Azure-Samples/cognitive-services -dotnet-sdksamples/ blob/master/documentation-samples/quickstarts/Compu terVision/Program.cs"
    },
    {
        "question": "HOTSPOT You are developing the shopping on-the-go project. You need to build the Adaptive Card for the chatbot . How should you complete the code? To answer, select  the appropriate options in the answer area. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. 1 and 2\n\nExplanation:\n\nThe Adaptive Card is a flexible and reusable piece of UI that can be used in different platforms and devices. To build the Adaptive Card for the chatbot, you need to define the schema and the elements of the card. The schema defines the structure of the card, and the elements define the content of the card.\n\nThe correct code to build the Adaptive Card is:\n```\n{\n  \"type\": \"AdaptiveCard\",\n  \"version\": \"1.0\",\n  \"body\": [\n    {\n      \"type\": \"TextBlock\",\n      \"text\": \"Welcome to Shopping On-The-Go!\"\n    },\n    {\n      \"type\": \"TextBlock\",\n      \"text\": \"What would you like to do today?\"\n    }\n  ],\n  \"actions\": [\n    {\n      \"type\": \"Action.Submit\",\n      \"title\": \"Shop Now\"\n    },\n    {\n      \"type\": \"Action.Submit\",\n      \"title\": \"View Cart\"\n    }\n  ]\n}\n```\nThis code defines the schema of the Adaptive Card, which includes the body and actions elements. The body element contains two TextBlock elements, which display the welcome message and the question. The actions element contains two Action.Submit elements, which define the buttons for the chatbot.\n\nOption A. 1 and 2 is correct because it includes the schema definition and the elements of the card.\n\nOption B. 1 and 3 is incorrect because it",
        "references": ""
    },
    {
        "question": "You need to develop an extract solution for the rec eipt images. The solution must meet the document processing requirements and the technical requirements. You upload the receipt images to the From Recognize r API for analysis, and the API returns the following JSON. Which expression should you use to trigger a manual  review of the extracted information by a member of the Consultant-Bookkeeper group?",
        "options": [
            "A. documentResults.docType == \"prebuilt:receipt\"",
            "B. documentResults.fields.\".confidence < 0.7 C. documentResults.fields.ReceiptType.confidence > 0.7",
            "D. documentResults.fields.MerchantName.confidence < 0.7"
        ],
        "correct": "",
        "explanation": "B. documentResults.fields.\".confidence < 0.7\n\nExplanation: \n\nThe correct answer is B. documentResults.fields.\".confidence < 0.7. This expression triggers a manual review of the extracted information when the confidence level of any field is less than 0.7. The \".*\" in the expression is a wildcard that matches any field name. This means that if any field has a confidence level less than 0.7, the expression will evaluate to true and trigger a manual review.\n\nOption A is incorrect because it only checks the document type and does not consider the confidence level of the extracted fields.\n\nOption C is incorrect because it only checks the confidence level of the ReceiptType field and does not consider the confidence level of other fields.\n\nOption D is incorrect because it only checks the confidence level of the MerchantName field and does not consider the confidence level of other fields.\n\nIn this scenario, the requirement is to trigger a manual review when the confidence level of any extracted field is less than 0.7. Therefore, option B is the correct answer.",
        "references": "https://docs.microsoft.com/en-us/azure/applied-ai-s ervices/form-recognizer/api-v2-0/referencesdk- api-v2-0"
    },
    {
        "question": "HOTSPOT You are developing the knowledgebase by using Azure  Cognitive Search. You need to build a skill that will be used by inde xers. How should you complete the code? To answer, select  the appropriate options in the answer area. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "C. \n\nExplanation:\nAzure Cognitive Search is a cloud-based search service provided by Microsoft Azure. It allows you to create a search index based on data from various sources. \n\nThe correct answer is C because the skill interface is defined using the Azure Cognitive Search Skill Interface Specification. This interface is used to define the inputs, outputs, and execution of a custom skill. \n\nA is incorrect because the Azure Function is not required to define the skill interface. \n\nB is incorrect because the Azure Logic App is not required to define the skill interface. \n\nD is incorrect because the Azure API Management is not required to define the skill interface.\n\nPlease let me know if this explanation is correct or not.",
        "references": "https://docs.microsoft.com/en-us/azure/search/cogni tive-search-skill-entity-recognition"
    },
    {
        "question": "You are developing the chatbot. You create the following components: A QnA Maker resource A chatbot by using the Azure Bot Framework SDK You need to add an additional component to meet the  technical requirements and the chatbot requirements. What should you add?",
        "options": [
            "A. Dispatch",
            "B. chatdown",
            "C. Language Understanding",
            "D. Microsoft Translator"
        ],
        "correct": "A. Dispatch",
        "explanation": "Explanation:\n\nThe correct answer is A. Dispatch. Dispatch is a component that enables routing of user input to the correct intent or topic. It helps to determine the intent of the user and directs the conversation flow accordingly. In the context of the chatbot, Dispatch is necessary to route the user's input to the correct QnA Maker knowledge base or to another intent.\n\nOption B, chatdown, is not a valid Azure component and does not exist in the Azure ecosystem.\n\nOption C, Language Understanding, is a component that enables the chatbot to understand the intent behind user input. While it is an important component, it is not the correct answer in this scenario because the question states that you already have a QnA Maker resource, which implies that you already have a language understanding capability.\n\nOption D, Microsoft Translator, is a component that enables language translation. While it can be a useful component in a chatbot, it is not necessary to meet the technical requirements and chatbot requirements in this scenario.\n\nTherefore, the correct answer is A. Dispatch.",
        "references": "https://docs.microsoft.com/en-us/azure/bot-service/ bot-builder-tutorial-dispatch"
    },
    {
        "question": "You are developing the document processing workflow . You need to identify which API endpoints to use to extract text from the financial documents. The solution must meet the document processing requirem ents. Which two API endpoints should you identify? Each c orrect answer presents part of the solution. NOTE: Each correct selection is worth one point.",
        "options": [
            "A. /vision/v3.2/read/analyzeResults",
            "B. /formrecognizer/v2.0/prebuilt/receipt/analyze C. /vision/v3.2/read/analyze",
            "D. /vision/v3.2/describe"
        ],
        "correct": "",
        "explanation": "A. /vision/v3.2/read/analyzeResults and B. /formrecognizer/v2.0/prebuilt/receipt/analyze\n\nExplanation:\n\nThe correct answer is A and B because both API endpoints are used to extract text from financial documents. \n\n/vision/v3.2/read/analyzeResults is used to extract text from images of documents,, a common scenario in financial document processing. This API endpoint is part of the Azure Computer Vision API.\n\n/formrecognizer/v2.0/prebuilt/receipt/analyze is used to extract text from structured documents such as receipts, invoices, and other financial documents. This API endpoint is part of the Azure Form Recognizer API.\n\nOn the other hand, options C and D are incorrect because:\n\nC. /vision/v3.2/read/analyze is used to analyze the layout and extract text from images of documents, but it does not return the extracted text. Instead, it returns an operation ID that can be used to retrieve the extracted text using /vision/v3.2/read/analyzeResults.\n\nD. /vision/v3.2/describe is used to analyze the visual features of an image, but it is not used to extract text from documents.",
        "references": "https://westus2.dev.cognitive.microsoft.com/docs/se rvices/form-recognizer-api-v2- preview/operations/GetAnalyzeReceiptResult https://docs.microsoft.com/en-us/rest/api/computerv ision.1/read/read"
    },
    {
        "question": "You are developing the chatbot. You create the following components: * A QnA Maker resource * A chatbot by using the Azure Bot Framework SDK. You need to integrate the components to meet the ch atbot requirements. Which property should you use?",
        "options": [
            "A. QnADialogResponseOptions.CardNoMatchText",
            "B. Qna MakerOptions-ScoreThreshold",
            "C. Qna Maker Op t ions StrickFilters",
            "D. QnaMakerOptions.RankerType"
        ],
        "correct": "D. QnaMakerOptions.RankerType",
        "explanation": "Explanation: The correct answer is D. QnaMakerOptions.RankerType. This property is used to specify the ranking algorithm for the QnA Maker knowledge base. The ranking algorithm determines how the QnA Maker service ranks the answers to the user's question. By default, and recommended, the ranking algorithm is set to \"Auto\" which allows the QnA Maker service to automatically determine the best ranking algorithm for the knowledge base.\n\nOption A is incorrect because QnADialogResponseOptions.CardNoMatchText is used to specify the text to display when no answers are found in the knowledge base. This property is not related to integrating the QnA Maker resource with the Azure Bot Framework SDK.\n\nOption B is incorrect because QnaMakerOptions.ScoreThreshold is used to specify the minimum score required for an answer to be considered a match. While this property is related to the QnA Maker service, it is not the correct property to use for integrating the QnA Maker resource with the Azure Bot Framework SDK.\n\nOption C is incorrect because there is no such property as QnaMakerOptions.StrictFilters. This option is likely a typo or a made-up property.\n\nIn summary, the correct answer is D. QnaMakerOptions.RankerType because it specifies the ranking algorithm for the QnA Maker knowledge base, which is necessary for integrating the QnA Maker resource with the Azure Bot Framework SDK.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/qnamaker/concepts/best-practices"
    },
    {
        "question": "HOTSPOT You build a QnA Maker resource to meet the chatbot requirements. Which RBAC role should you assign to each group? To  answer, select the appropriate options in the answer area. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Cognitive Service Contributor for developers\nC. Owner for administrators\n\nExplanation:\nThe correct answer is A. Cognitive Service Contributor for developers and C. Owner for administrators. \n\nHere's why:\n\nIn Azure, when you create a QnA Maker resource, you need to assign the appropriate roles to different groups of users. \n\nFor developers, you should assign the Cognitive Service Contributor role. This role allows them to create, update, and delete the QnA Maker resource, which is necessary for their development tasks. \n\nOn the other hand, administrators should be assigned the Owner role. This role provides full control over the resource, including the ability to manage access and assign roles to other users. This is necessary for administrators to perform their administrative tasks.\n\nNow, let's discuss why the other options are incorrect:\n\nOption B, Reader, is incorrect because it only provides read-only access to the resource. This is not sufficient for developers who need to create, update, and delete the resource.\n\nOption D, Contributor, is also incorrect because it provides more permissions than necessary for developers. While it does allow them to create, update, and delete the resource, it also provides other permissions that are not necessary for their tasks.\n\nTherefore, the correct answer is A. Cognitive Service Contributor for developers and C. Owner for administrators.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/qnamaker/concepts/role-based-accesscontrol"
    },
    {
        "question": "DRAG DROP You are developing a solution for the Management-Bo okkeepers group to meet the document processing requirements. The solution must contain the following components: A From Recognizer resource An Azure web app that hosts the Form Recognizer sam ple labeling tool The Management-Bookkeepers group needs to create a custom table extractor by using the sample labeling tool. Which three actions should the Management-Bookkeepe rs group perform in sequence? To answer, move the appropriate cmdlets from the list of cmdle ts to the answer area and arrange them in the correct order.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. az formrecognizer create -n <resource-name> --resource-group <resource-group> --location <location>\nB. az webapp create -n <web-app-name> --resource-group <resource-group> --plan <app-service-plan>\nC. az webapp deployment source config -n <web-app-name> --repo-url <github-repo-url> --branch <branch-name>\nD. az formrecognizer sample-data create -n <sample-data-name> --resource-group <resource-group> --form-recognizer-resource-id <resource-id>\n\nExplanation:\nThe correct sequence of actions is A, B, C, and D. Here's why:\n\nA. az formrecognizer create -n <resource-name> --resource-group <resource-group> --location <location>:\nThis command creates a new Form Recognizer resource. This is the first step because the Management-Bookkeepers group needs a Form Recognizer resource to create a custom table extractor.\n\nB. az webapp create -n <web-app-name> --resource-group <resource-group> --plan <app-service-plan>:\nThis command creates a new Azure web app. This is the second step because the sample labeling tool needs to be hosted in an Azure web app.\n\nC. az webapp deployment source config -n <web-app-name> --repo-url <github-repo-url> --branch <branch-name>:\nThis command configures the deployment source for the Azure web app. This",
        "references": "https://docs.microsoft.com/en-us/azure/applied-ai-s ervices/form-recognizer/label-tool"
    },
    {
        "question": "You are developing the knowledgebase. You use Azure Video Analyzer for Media (previously Video indexer) to obtain transcripts of webinars. You need to ensure that the solution meets the know ledgebase requirements. What should you do?",
        "options": [
            "A. Create a custom language model",
            "B. Configure audio indexing for videos only",
            "C. Enable multi-language detection for videos",
            "D. Build a custom Person model for webinar presenter s"
        ],
        "correct": "B. Configure audio indexing for videos only",
        "explanation": "Explanation: The correct answer is B because the knowledgebase requires transcripts of webinars. Azure Video Analyzer for Media provides transcripts of audio and video content, (previously Video indexer). Configuring audio indexing for videos only will provide the required transcripts for the knowledgebase.\n\nWhy are the other options incorrect?\n\nOption A is incorrect because creating a custom language model is not necessary for obtaining transcripts of webinars. The default language model provided by Azure Video Analyzer for Media is sufficient for this purpose.\n\nOption C is incorrect because enabling multi-language detection for videos is not relevant to the requirement of obtaining transcripts of webinars. This feature is useful when dealing with videos that contain multiple languages, but it is not necessary in this scenario.\n\nOption D is incorrect because building a custom Person model for webinar presenters is not related to obtaining transcripts of webinars. This feature is useful for identifying and analyzing the appearance of specific individuals in videos, but it is not necessary for generating transcripts.",
        "references": "https://docs.microsoft.com/en-us/azure/azure-video- analyzer/video-analyzer-for-media-docs/videoindexer - overview"
    },
    {
        "question": "You are developing the knowledgebase by using Azure  Cognitive Search. You need to process wiki content to meet the techni cal requirements. What should you include in the solution?",
        "options": [
            "A. an indexer for Azure Blob storage attached to a s killset that contains the language detection skill and the",
            "B. an indexer for Azure Blob storage attached to a s killset that contains the language detection skill",
            "C. an indexer for Azure Cosmos DB attached to a skil lset that contains the document extraction skill an d the",
            "D. an indexer for Azure Cosmos DB attached to a skil lset that contains the language detection skill and  the text"
        ],
        "correct": "C. an indexer for Azure Cosmos DB attached to a skil lset that contains the document extraction skill an d the",
        "explanation": "Explanation:\nThe correct answer is C because Azure Cognitive Search is used to process wiki content, which is a type of unstructured data. Azure Cosmos DB is a NoSQL database that is suitable for storing and querying large amounts of unstructured data. The document extraction skill is required to extract relevant information from the wiki content, and the language detection skill is required to detect the language of the content. \n\nWhy other options are incorrect:\nOption A is incorrect because it uses Azure Blob storage, which is an object storage service that is not suitable for storing and querying large amounts of unstructured data. \n\nOption B is incorrect because it only includes the language detection skill, which is not enough to process wiki content. \n\nOption D is incorrect because it includes the text merge skill, which is not required to process wiki content.",
        "references": "https://docs.microsoft.com/en-us/azure/search/cogni tive-search-skill-document-extraction https://docs.microsoft.com/en-us/azure/search/cogni tive-search-skill-text-translation"
    },
    {
        "question": "You are developing the knowledgebase by using Azure  Cognitive Search. You need to meet the knowledgebase requirements for  searching equivalent terms. What should you include in the solution?",
        "options": [
            "A. synonym map",
            "B. a suggester",
            "C. a custom analyzer",
            "D. a built-in key phrase extraction skill"
        ],
        "correct": "A. synonym map",
        "explanation": "Explanation: \nAzure Cognitive Search provides a synonym map feature that enables searching equivalent terms. This feature allows you to specify synonyms for specific terms, allowing users to search for equivalent terms and retrieve relevant results. For example, if you have a knowledgebase that includes terms like \"car\", \"automobile\", and \"vehicle\", you can create a synonym map that maps these terms to each other. This way, when a user searches for \"car\", the search results will also include documents that contain the terms \"automobile\" and \"vehicle\".\n\nThe other options are incorrect because:\n\n* B. A suggester is a feature in Azure Cognitive Search that provides autocomplete suggestions to users as they type their search queries. While it can improve the search experience, it does not enable searching equivalent terms.\n* C. A custom analyzer is a feature in Azure Cognitive Search that allows you to customize the way text is analyzed and indexed. While it can be used to improve search results, it does not provide a direct solution for searching equivalent terms.\n* D. A built-in key phrase extraction skill is a feature in Azure Cognitive Search that extracts key phrases from text data. While it can be used to identify important concepts in text data, it does not enable searching equivalent terms.\n\nTherefore, the correct answer is A. synonym map, which provides a direct solution for searching equivalent terms in Azure Cognitive Search.",
        "references": "https://docs.microsoft.com/en-us/azure/search/searc h-synonyms New Topic: Topic 3, Misc. Questions"
    },
    {
        "question": "DRAG DROP You have 100 chatbots that each has its own Languag e Understanding model. Frequently, you must add the same phrases to each m odel. You need to programmatically update the Language Un derstanding models to include the new phrases. How should you complete the code? To answer, drag t he appropriate values to the correct targets. Each value may be used once, more than once, or not  at all. You may need to drag the split bar between panes or scroll to view content. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A: languageUnderstandingModelsClient\nB: .update_model\nC: .update_model_phrases\nD: .list_models\n\nThe correct answer is A: languageUnderstandingModelsClient and C: .update_model_phrases.\n\nHere's the explanation:\n\nThe correct answer is A: languageUnderstandingModelsClient and C: .update_model_phrases.\n\nThe languageUnderstandingModelsClient is a client object that allows you to interact with the Language Understanding (LUIS) service. You need to create an instance of this client to update the Language Understanding models.\n\nThe .update_model_phrases method is used to update the phrases in a Language Understanding model. This method is part of the languageUnderstandingModelsClient and is used to add new phrases to an existing model.\n\nThe other options are incorrect because:\n\nB: .update_model is not a valid method. There is no method called .update_model in the languageUnderstandingModelsClient.\n\nD: .list_models is a method that lists all the Language Understanding models, but it's not used to update the models.\n\nTherefore, the correct answer is A: languageUnderstandingModelsClient and C: .update_model_phrases.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/luis/client-libraries-rest-api"
    },
    {
        "question": "DRAG DROP You plan to use a Language Understanding applicatio n named app1 that is deployed to a container. App1 was developed by using a Language Understandin g authoring resource named lu1. App1 has the versions shown in the following table. You need to create a container that uses the latest  deployable version of app1. Which three actions should you perform in sequence?  To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order. (Choose three.) A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Create a new container revision\nB. Update the container to use the latest deployable version of app1\nC. Create a new container\nD. Deploy the latest version of lu1 to the authoring resource\n\nExplanation: \n\nThe correct answer is C-A-B. \n\nHere's why:\n\n1. First, you need to create a new container (C). \n2. Next, you need to create a new container revision (A) so that you can specify the latest deployable version of app1. \n3. Finally, you need to update the container to use the latest deployable version of app1 (B).",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/luis/luis-container-howto"
    },
    {
        "question": "You need to build a chatbot that meets the followin g requirements: Supports chit-chat, knowledge base, and multilingua l models Performs sentiment analysis on user messages Selects the best language model automatically What should you integrate into the chatbot?",
        "options": [
            "A. QnA Maker, Language Understanding, and Dispatch",
            "B. Translator, Speech, and Dispatch",
            "C. Language Understanding, Text Analytics, and QnA M aker",
            "D. Text Analytics, Translator, and Dispatch",
            "A. Custom Vision",
            "B. Personalizer",
            "C. Form Recognizer",
            "D. Computer Vision"
        ],
        "correct": "C. Form Recognizer",
        "explanation": "Explanation: The correct answer is not C. Form Recognizer. The correct answer is C. Language Understanding, Text Analytics, and QnA Maker.\n\nHere's why:\n\n* Language Understanding (LUIS) is a cloud-based AI service that applies machine learning to identify the intent behind user input, such as text or speech. It supports multilingual models and can perform sentiment analysis on user messages.\n* Text Analytics is a cloud-based AI service that extracts information from unstructured text data, such as sentiment analysis and entity recognition. It can be used to analyze user messages and identify sentiment.\n* QnA Maker is a cloud-based AI service that generates answers to user questions based on a knowledge base. It supports chit-chat knowledge bases and can be used to generate responses to user queries.\n\nThe other options are incorrect because:\n\n* Option A is incorrect because Dispatch is not necessary for this scenario. Dispatch is a service that routes incoming messages to the best language model, but it is not required for the specified requirements.\n* Option B is incorrect because Translator is not necessary for this scenario. Translator is a service that translates text from one language to another, but it is not required for the specified requirements.\n* Option D is incorrect because it does not include Language Understanding, which is necessary for sentiment analysis and multilingual models.\n* Options 5-8 are incorrect because they are not relevant to the specified requirements. Custom Vision is a service that allows you to build custom image classification models, Personalizer",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/form-recognizer"
    },
    {
        "question": "HOTSPOT You need to create a new resource that will be used  to perform sentiment analysis and optical character recognition (OCR). The solution must meet  the following requirements: Use a single key and endpoint to access multiple se rvices. Consolidate billing for future services that you mi ght use. Support the use of Computer Vision in the future. How should you complete the HTTP request to create the new resource? To answer, select the appropriate options in the answer area. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "C.\n\nExplanation: \n\nThe correct answer is C because Azure Cognitive Services is a cloud-based service that enables developers to build intelligent systems that can see, hear, understand, and interpret user needs. It provides a single key and endpoint to access multiple services, including Computer Vision, which supports OCR and sentiment analysis. Additionally, Azure Cognitive Services consolidates billing for future services that you might use.\n\nWhy are the other options incorrect?\n\nA is incorrect because Azure Storage is a cloud storage service that provides a massively scalable object store for data objects. While it supports data analytics and AI workloads, it does not provide a single key and endpoint to access multiple services like Azure Cognitive Services.\n\nB is incorrect because Azure Functions is a serverless compute service that enables developers to run event-triggered code without worrying about the underlying infrastructure. While it supports AI and machine learning workloads, it does not provide a single key and endpoint to access multiple services like Azure Cognitive Services.\n\nD is incorrect because Azure Kubernetes Service (AKS) is a managed container orchestration service that enables developers to deploy, manage, and scale containerized applications. While it supports AI and machine learning workloads, it does not provide a single key and endpoint to access multiple services like Azure Cognitive Services.\n\nPlease let me know if you need any further clarification or changes.",
        "references": "https://docs.microsoft.com/en-us/rest/api/deviceupd ate/resourcemanager/accounts/create https://www.analyticsvidhya.com/blog0/microsoft-azu re-cognitive-services-api-for-aidevelopment/"
    },
    {
        "question": "You are developing a new sales system that will pro cess the video and text from a public-facing website. You plan to monitor the sales system to ensure that  it provides equitable results regardless of the user's location or background. Which two responsible AI principles provide guidanc e to meet the monitoring requirements? Each correct answer presents part of the solution. (Choo se two.) NOTE: Each correct selection is worth one point.",
        "options": [
            "A. transparency",
            "B. fairness",
            "C. inclusiveness",
            "D. reliability and safety"
        ],
        "correct": "",
        "explanation": "The correct answer is B. fairness and A. transparency.\n\nExplanation: \n    Responsible AI principles are guidelines for developing AI systems that are trustworthy, fair, and transparent. For the sales system to provide equitable results, it must ensure fairness and transparency. \n\n    Fairness (Option B) is a responsible AI principle that aims to eliminate biases and discrimination in AI systems. It ensures that the system treats all users equally, regardless of their demographics, location, or background. In the context of the sales system, fairness ensures that the system does not discriminate against users based on their location or background.\n\n    Transparency (Option A) is another responsible AI principle that promotes openness and clarity in AI decision-making processes. It enables users to understand how the system makes decisions and provides explanations for its outputs. In the context of the sales system, transparency ensures that the system provides clear explanations for its outputs, enabling users to trust the system's decisions.\n\n    Inclusiveness (Option C) is not directly related to the monitoring requirements of the sales system. While inclusiveness is an important principle for developing AI systems that cater to diverse user needs, it does not directly address the issue of equitable results.\n\n    Reliability and safety (Option D) are important principles for developing AI systems, but they do not directly address the issue of equitable results. Reliability ensures that the system functions correctly and consistently, while safety ensures that the system does not cause harm to users or the environment.\n\nTherefore, the correct answers are Options",
        "references": ""
    },
    {
        "question": "DRAG DROP You plan to use containerized versions of the Anoma ly Detector API on local devices for testing and in on-premises datacenters. You need to ensure that the containerized deploymen ts meet the following requirements: Prevent billing and API information from being stor ed in the command-line histories of the devices that run the container. Control access to the container images by using Azu re role-based access control (Azure RBAC). Which four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order. (Choose four.) NOTE: More than one order of answer choices is corr ect. You will receive credit for any of the correct orders you select. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Create an Azure Container Registry (ACR).\nB. Create an Azure Active Directory (Azure AD) service principal.\nC. Configure Azure RBAC for the ACR.\nD. Store the API key in Azure Key Vault.\nE. Create a Dockerfile for the Anomaly Detector API.\nF. Push the container image to the ACR.\nG. Grant the Azure AD service principal access to the ACR.\nH. Configure the Docker CLI to use Azure AD authentication.\n\nCorrect Answer: A, B, G, C.",
        "references": ""
    },
    {
        "question": "HOTSPOT You plan to deploy a containerized version of an Az ure Cognitive Services service that will be used fo r text analysis. You configure https://contoso.cognitiveservices.azu re.com as the endpoint URI for the service, and you pull the latest version of the Text Analytics S entiment Analysis container. You need to run the container on an Azure virtual m achine by using Docker. How should you complete the command? To answer, sel ect the appropriate options in the answer area. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. docker run -d --rm -p 5000:5000 -e EULA=accept -e Billing=https://contoso.cognitiveservices.azure.com -e ApiKey=your-api-key mcr.microsoft.com/azure-cognitive-services/textanalytics/sentiment:latest\n\nThe correct answer is A. \n\nExplanation: \n\nThe correct command to run the Text Analytics Sentiment Analysis container on an Azure virtual machine using Docker is: \n\ndocker run -d --rm -p 5000:5000 -e EULA=accept -e Billing=https://contoso.cognitiveservices.azure.com -e ApiKey=your-api-key mcr.microsoft.com/azure-cognitive-services/textanalytics/sentiment:latest \n\nThis command uses the following options: \n\n- \"-d\" runs the container in detached mode. \n- \"--rm\" automatically removes the container when it exits. \n- \"-p 5000:5000\" maps port 5000 on the host machine to port 5000 in the container. \n- \"-e\" sets environment variables for the container. \n- \"EULA=accept\" accepts the end-user license agreement. \n- \"Billing=https://contoso.cognitiveservices.azure.com\" sets the billing endpoint URI. \n- \"ApiKey=your-api-key\" sets the API key for the service. \n- \"mcr.microsoft.com/azure-cognitive-services/textanalytics/sentiment:latest\" specifies the container image",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/text-analytics/how-tos/text-analyticshow- to-install-containers?tabs=sentiment"
    },
    {
        "question": "You have the following C# method for creating Azure  Cognitive Services resources programmatically. You need to call the method to create a free Azure resource in the West US Azure region. The resource will be used to generate captions of image s automatically. Which code should you use?",
        "options": [
            "A. create_resource(client, \"res1\", \"ComputerVision\",  \"F0\", \"westus\")",
            "B. create_resource(client, \"res1\", \"CustomVision.Pre diction\", \"F0\", \"westus\")",
            "C. create_resource(client, \"res1\", \"ComputerVision\",  \"S0\", \"westus\")",
            "D. create_resource(client, \"res1\", \"CustomVision.Pre diction\", \"S0\", \"westus\")"
        ],
        "correct": "A. create_resource(client, \"res1\", \"ComputerVision\",  \"F0\", \"westus\")",
        "explanation": "Explanation:\nThe correct answer is A. create_resource(client, \"res1\", \"ComputerVision\",  \"F0\", \"westus\"). This is because the method is creating a Computer Vision resource in the West US region, which is used for generating captions of images automatically. The \"F0\" pricing tier is a free tier, which is suitable for this scenario.\n\nWhy the other options are incorrect:\n\nOption B is incorrect because CustomVision.Prediction is not used for generating captions of images automatically. Custom Vision is a service that allows you to build, deploy, and manage your own custom computer vision models.\n\nOption C is incorrect because the \"S0\" pricing tier is not a free tier. It's a standard pricing tier that requires a paid subscription.\n\nOption D is incorrect because it combines the incorrect service (CustomVision.Prediction) with the incorrect pricing tier (S0).",
        "references": ""
    },
    {
        "question": "You successfully run the following HTTP request. POST https://management.azure.com/subscriptionsc51a 87-3a69-47a8-aedca54745f708a1/ resourceGroups/RG1/providers/Microsoft.CognitiveSer vices/accounts/contosol/rege nerateKey?api-version=2017-04-18 Body{\"keyName\": \"Key2\"} What is the result of the request?",
        "options": [
            "A. A key for Azure Cognitive Services was generated in Azure Key Vault.",
            "B. A new query key was generated.",
            "C. The primary subscription key and the secondary su bscription key were rotated.",
            "D. The secondary subscription key was reset."
        ],
        "correct": "B. A new query key was generated.",
        "explanation": "Explanation: \n\nThe correct answer is B. A new query key was generated. The HTTP request is a POST request to the regenerateKey endpoint of Azure Cognitive Services. This endpoint is used to regenerate a query key for an Azure Cognitive Services account. The body of the request specifies the name of the key to be regenerated, which in this case is \"Key2\". As a result of this request, a new query key named \"Key2\" will be generated for the Azure Cognitive Services account.\n\nOption A is incorrect because the request does not involve Azure Key Vault. Azure Key Vault is a separate service that is used to manage and store cryptographic keys, but it is not involved in this request.\n\nOption C is incorrect because the request does not involve rotating the primary and secondary subscription keys. Rotating subscription keys involves updating the primary and secondary keys, but this request is specifically for regenerating a query key.\n\nOption D is incorrect because the request does not reset the secondary subscription key. The request is for regenerating a query key, not resetting the secondary subscription key.\n\nTherefore, the correct answer is B. A new query key was generated.",
        "references": ""
    },
    {
        "question": "You build a custom Form Recognizer model. You receive sample files to use for training the mo del as shown in the following table. Which three files can you use to train the model? E ach correct answer presents a complete solution. (Choose three.) NOTE: Each correct selection is worth one point.",
        "options": [
            "A. File1",
            "B. File2",
            "C. File3",
            "D. File4"
        ],
        "correct": "",
        "explanation": "A, a single PDF file containing multiple forms\nB. a folder containing multiple PDF files each containing a single form\nC. a CSV file containing annotated form data\nD. a ZIP file containing multiple PDF files each containing a single form\n\nExplanation:\nThe correct answers are A, B, and C. You can use a single PDF file containing multiple forms (File1), a folder containing multiple PDF files each containing a single form (File2), and a CSV file containing annotated form data (File3) to train the model.\n\nFile1 (A) is correct because you can use a single PDF file containing multiple forms to train the model.\n\nFile2 (B) is correct because you can use a folder containing multiple PDF files each containing a single form to train the model.\n\nFile3 (C) is correct because you can use a CSV file containing annotated form data to train the model.\n\nFile4 (D) is incorrect because a ZIP file containing multiple PDF files each containing a single form is not a supported file format for training a custom Form Recognizer model.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/form-recognizer/overview"
    },
    {
        "question": "You have a Video Indexer service that is used to pr ovide a search interface over company videos on your company's website. You need to be able to search for videos based on w ho is present in the video. What should you do?",
        "options": [
            "A. Create a person model and associate the model to the videos.",
            "B. Create person objects and provide face images for  each object.",
            "C. Invite the entire staff of the company to Video I ndexer.",
            "D. Edit the faces in the videos."
        ],
        "correct": "A. Create a person model and associate the model to the videos.",
        "explanation": "Explanation: The correct answer is A. Create a person model and associate the model to the videos. This is because Video Indexer uses AI-powered models to identify people in videos. By creating a person model and associating it with the videos, Video Indexer can recognize and identify individuals in the videos, allowing for search functionality based on who is present in the video.\n\nOption B is incorrect because creating person objects and providing face images for each object is not a necessary step in configuring Video Indexer for person-based search. While face recognition is a key component of Video Indexer's person identification capabilities, it is not a manual process that requires uploading face images.\n\nOption C is incorrect because inviting the entire staff of the company to Video Indexer is not relevant to configuring person-based search. Video Indexer is a cloud-based service that can be accessed by authorized users, but it does not require staff members to be invited to the service in order to enable person-based search.\n\nOption D is incorrect because editing the faces in the videos is not a necessary step in configuring Video Indexer for person-based search. Video Indexer uses AI-powered models to identify people in videos, and it does not require manual editing of the video content.",
        "references": "https://docs.microsoft.com/en-us/azure/media-servic es/video-indexer/customize-person-modelwith-api"
    },
    {
        "question": "You use the Custom Vision service to build a classi fier. After training is complete, you need to evaluate th e classifier. Which two metrics are available for review? Each co rrect answer presents a complete solution. (Choose two.) NOTE: Each correct selection is worth one point.",
        "options": [
            "A. recall",
            "B. F-score",
            "C. weighted accuracy",
            "D. precision"
        ],
        "correct": "",
        "explanation": "A. recall and D. precision\n\nExplanation:\nThe correct answer is A. recall and D. precision. After training a classifier using the Custom Vision service, two essential metrics available for review are recall and precision.\n\nRecall measures the proportion of actual positive instances that were correctly identified by the classifier. It's a measure of how well the classifier detects all instances of a particular class.\n\nPrecision, on the other hand, measures the proportion of true positive instances among all positive predictions made by the classifier. It's a measure of how accurate the classifier is when it predicts a particular class.\n\nThe other options are incorrect because:\n\nB. F-score is a single metric that combines both precision and recall. While it's a useful metric, it's not one of the two separate metrics available for review.\n\nC. weighted accuracy is not a standard metric provided by the Custom Vision service for evaluating classifiers.\n\nTherefore, the correct answer is A. recall and D. precision.",
        "references": "https://www.tallan.com/blog0/05/azure-custom-vision /"
    },
    {
        "question": "DRAG DROP You are developing a call to the Face API. The call  must find similar faces from an existing list name d employeefaces. The employeefaces list contains 60,0 00 images. How should you complete the body of the HTTP reques t? To answer, drag the appropriate values to the correct targets. Each value may be used once, m ore than once, or not at all. You may need to drag the split bar between panes or scroll to view content. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. faceListId\nB. employeefaces\nC. maxFacesToReturn\nD. faceIds\n\nExplanation: The correct answer is faceListId = employeefaces. The Face API is a cloud-based API that provides advanced face algorithms. The API can be used to detect, identify, and analyze faces in images. In this scenario, the goal is to find similar faces from an existing list named employeefaces, which contains 60,000 images. To achieve this, the HTTP request body should include the faceListId parameter set to employeefaces.\n\nWhy are the other options incorrect?\n\nOption C (maxFacesToReturn) is incorrect because it is used to specify the maximum number of faces to return in the API response, but it is not related to specifying the list of faces to search from.\n\nOption D (faceIds) is incorrect because it is used to specify a list of face IDs to search for similar faces, but it is not related to specifying the list name employeefaces.\n\nOption B (employeefaces) is incorrect because it is the list name, but it should be assigned to the faceListId parameter.\n\nTherefore, the correct answer is faceListId = employeefaces, which specifies the list of faces to search from.",
        "references": "https://docs.microsoft.com/en-us/rest/api/faceapi/f ace/findsimilar"
    },
    {
        "question": "DRAG DROP You are developing a photo application that will fi nd photos of a person based on a sample image by using the Face API. You need to create a POST request to find the photo s. How should you complete the request? To answer, dra g the appropriate values to the correct targets. Each value may be used once, more than once, or not  at all. You may need to drag the split bar between panes or scroll to view content. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "The correct answer is: \n\nA. https://westus.api.cognitive.microsoft.com/face/v1.0/detect \nB. application/json \nC. Content-Type \nD. subscription-key \n\nExplanation: \n\nThe correct answer is A, B, C, and D. \n\nThe Face API is a part of Microsoft Cognitive Services. It uses HTTP requests to interact with the API. The API endpoint for detecting faces is https://westus.api.cognitive.microsoft.com/face/v1.0/detect. \n\nThe request body should be in JSON format, so the Content-Type header should be set to application/json. \n\nThe subscription-key is used for authentication, which is required for the API request. \n\nTherefore, all four options are required to complete the POST request to find photos of a person based on a sample image by using the Face API.",
        "references": "https://docs.microsoft.com/en-us/rest/api/faceapi/f ace/detectwithurl https://docs.microsoft.com/en-us/rest/api/faceapi/f ace/findsimilar"
    },
    {
        "question": "HOTSPOT You develop a test method to verify the results ret rieved from a call to the Computer Vision API. The call is used to analyze the existence of company lo gos in images. The call returns a collection of brands named brands. You have the following code segment. For each of the following statements, select Yes if  the statement is true. Otherwise, select No. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. brands.Any() returns true if there are any brands in the collection.\n\nB. brands.Any() returns true if all brands in the collection are not null.\n\nC. brands.Any(b => b.Name == \"Microsoft\") returns true if any brand in the collection has the name \"Microsoft\".\n\nD. brands.Any(b => b.Name == null) returns true if all brands in the collection have null names.\n\nExplanation:\n\nThe correct answer is A and C.\n\nA is correct because the Any method returns true if the collection contains at least one element. In this case, if there are any brands in the collection, brands.Any() will return true.\n\nB is incorrect because the Any method does not check if all elements in the collection are not null. Instead, it checks if there is at least one element.\n\nC is correct because the Any method returns true if any element in the collection matches the specified condition. In this case, if any brand in the collection has the name \"Microsoft\", brands.Any(b => b.Name == \"Microsoft\") will return true.\n\nD is incorrect because the Any method does not check if all elements in the collection match the specified condition. Instead, it checks if any element matches the condition.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/computer-vision/concept-detectingfaces"
    },
    {
        "question": "HOTSPOT You develop an application that uses the Face API. You need to add multiple images to a person group. How should you complete the code? To answer, select  the appropriate options in the answer area. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C. D."
        ],
        "correct": "",
        "explanation": "3. C. D.",
        "references": ""
    },
    {
        "question": "HOTSPOT You are developing an application that will use the  Computer Vision client library. The application ha s the following code. For each of the following statements, select Yes if  the statement is true. Otherwise, select No. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Yes\nB. No\nC. No\nD. Yes\n\nExplanation: The code is using the Azure Computer Vision client library. The code is creating an instance of the ComputerVisionClient class, which is used to interact with the Azure Computer Vision service. The code is also specifying the endpoint and credential for the service. The code is then using the client to analyze an image.\n\nThe correct answer is A. Yes, B. No, C. No, D. Yes.\n\nHere's why:\n\nA. Yes: The code is correctly creating an instance of the ComputerVisionClient class, which is used to interact with the Azure Computer Vision service.\n\nB. No: The code is not using the Azure Cognitive Services Speech SDK.\n\nC. No: The code is not using the Azure Form Recognizer client library.\n\nD. Yes: The code is correctly specifying the endpoint and credential for the Azure Computer Vision service.\n\nThe other options are incorrect because:\n\nB. The code is not related to speech recognition, so it's not using the Azure Cognitive Services Speech SDK.\n\nC. The code is not related to form recognition, so it's not using the Azure Form Recognizer client library.\n\nTherefore, the correct answer is A. Yes, B. No, C. No, D. Yes.",
        "references": ""
    },
    {
        "question": "You are developing a method that uses the Computer Vision client library. The method will perform optical character recognition (OCR) in images. The method has the following code. During testing, you discover that the call to the G etReadResultAsync method occurs before the read operation is complete. You need to prevent the GetReadResultAsync method f rom proceeding until the read operation is complete. Which two actions should you perform? Each correct answer presents part of the solution. (Choose two.) NOTE: Each correct selection is worth one point.",
        "options": [
            "A. Remove the Guid.Parse(operationId) parameter.",
            "B. Add code to verify the results.Status value.",
            "C. Add code to verify the status of the txtHeaders.S tatus value.",
            "D. Wrap the call to GetReadResultAsync within a loop  that contains a delay.",
            "A. machine learned",
            "B. Regex",
            "C. geographyV2",
            "D. Pattern.any"
        ],
        "correct": "A. machine learned",
        "explanation": "Wait, no, that's not correct. The correct answer is B. Add code to verify the results.Status value and D. Wrap the call to GetReadResultAsync within a loop that contains a delay.\n\nLet me explain why the other options are incorrect and why B and D are correct.\n\nThe issue at hand is that the call to GetReadResultAsync is happening before the read operation is complete. This means that we need to find a way to wait until the read operation is complete before calling GetReadResultAsync.\n\nOption A is incorrect because removing the Guid.Parse(operationId) parameter will not solve the issue. The operationId is used to identify the operation, and removing it will not affect the timing of the GetReadResultAsync call.\n\nOption C is incorrect because txtHeaders.Status is not related to the status of the read operation. It's possible that txtHeaders.Status is used for something else entirely, but it's not relevant to this issue.\n\nOptions 5-8 are not even related to the question and can be ignored.\n\nNow, let's talk about why options B and D are correct.\n\nOption B is correct because by adding code to verify the results.Status value, we can check if the read operation is complete before calling GetReadResultAsync. We can do this by checking if the status is \"succeeded\" or \"failed\", and only then call GetReadResultAsync.\n\nOption D is correct because wrapping the call to GetReadResultAsync within a loop that contains a",
        "references": "https://github.com/Azure-Samples/cognitive-services -quickstartcode/ blob/master/dotnet/ComputerVision/ComputerVisionQui ckstart.cs QUESTION 37 You are building a Language Understanding model for an e-commerce platform. You need to construct an entity to capture billing addresses. Which entity type should you use for the billing ad dress?"
    },
    {
        "question": "You need to upload speech samples to a Speech Studi o project. How should you upload the samples?",
        "options": [
            "A. Combine the speech samples into a single audio fi le in the .wma format and upload the file.",
            "B. Upload a .zip file that contains a collection of audio files in the .wav format and a corresponding",
            "C. Upload individual audio files in the FLAC format and manually upload a corresponding transcript in",
            "D. Upload individual audio files in the .wma format."
        ],
        "correct": "B. Upload a .zip file that contains a collection of audio files in the .wav format and a corresponding",
        "explanation": "Explanation:\n\nThe correct answer is B. Upload a .zip file that contains a collection of audio files in the .wav format and a corresponding transcript file. This is because the Speech Studio project requires the audio files to be in the .wav format, , and it is recommended to upload a .zip file containing multiple audio files along with their corresponding transcript files.\n\nOption A is incorrect because the Speech Studio project does not support the .wma format. \n\nOption C is incorrect because although the FLAC format is supported, it is not recommended to upload individual audio files and manually upload the corresponding transcript files. This approach can lead to errors and inconsistencies.\n\nOption D is incorrect because although the .wma format is mentioned, it is not the recommended format for uploading audio files to a Speech Studio project.",
        "references": ""
    },
    {
        "question": "You are developing a method for an application that  uses the Translator API. The method will receive the content of a webpage, a nd then translate the content into Greek (el). The result will also contain a transliteration that  uses the Roman alphabet. You need to create the URI for the call to the Tran slator API. You have the following URI. https://api.cognitive.microsofttranslator.com/trans late?api-version=3.0 Which three additional query parameters should you include in the URI? Each correct answer presents part of the solution. (Choose three.) NOTE: Each correct selection is worth one point.",
        "options": [
            "A. toScript=Cyrl",
            "B. from=el",
            "C. textType=html",
            "D. to=el"
        ],
        "correct": "",
        "explanation": "The correct answer is: C. textType=html, D. to=el, and transliteration=Roman.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/translator/reference/v3-0-translate"
    },
    {
        "question": "You have a chatbot that was built by using the Micr osoft Bot Framework. You need to debug the chatbot endpoint remotely. Which two tools should you install on a local compu ter? Each correct answer presents part of the solution. (Choose two.) NOTE: Each correct selection is worth one point.",
        "options": [
            "A. Fiddler",
            "B. Bot Framework Composer",
            "C. Bot Framework Emulator",
            "D. Bot Framework CLI"
        ],
        "correct": "",
        "explanation": "A. Fiddler \nC. Bot Framework Emulator\n\nExplanation:\n\nThe correct answer is A. Fiddler and C. Bot Framework Emulator. \n\nTo debug the chatbot endpoint remotely,, you need to capture and inspect the HTTP traffic between the chatbot and the remote endpoint. Fiddler is a web debugging proxy that can capture and inspect HTTP traffic. It allows you to debug web applications by capturing and modifying requests and responses.\n\nBot Framework Emulator is a tool that allows you to test and debug your bot locally. It provides a local environment to test your bot's functionality, including its conversations and interactions. By using the Bot Framework Emulator, you can simulate conversations with your chatbot and inspect the HTTP traffic between the emulator and the chatbot.\n\nWhy the other options are incorrect:\n\nOption B, Bot Framework Composer, is a tool that allows you to design and build conversational interfaces for your chatbot. While it's a useful tool for building chatbots, it's not designed for debugging remote endpoints.\n\nOption D, Bot Framework CLI, is a command-line tool that provides a set of commands for managing and deploying your chatbot. While it's a useful tool for managing your chatbot, it's not designed for debugging remote endpoints.\n\nIn summary, to debug the chatbot endpoint remotely, you need to capture and inspect the HTTP traffic between the chatbot and the remote endpoint. Fiddler and Bot Framework Emulator are the two tools that can help you",
        "references": "https://docs.microsoft.com/en-us/azure/bot-service/ bot-service-debug-emulator"
    },
    {
        "question": "DRAG DROP You are building a retail chatbot that will use a Q nA Maker service. You upload an internal support document to train th e model. The document contains the following question: \"What is your warranty period?\" Users report that the chatbot returns the default Q nA Maker answer when they ask the following question: \"How long is the warranty coverage?\" The chatbot returns the correct answer when the use rs ask the following question: 'What is your warranty period?\" Both questions should return the same answer. You need to increase the accuracy of the chatbot re sponses. Which three actions should you perform in sequence?  To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order. (Choose three.) A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Update the Q nA Maker knowledge base with synonyms for the key words in the question. \nB. Add the \"How long is the warranty coverage?\" question to the Q nA Maker knowledge base as an alternate question. \nC. Train the Q nA Maker model. \nD. Review the internal support document for accuracy.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/qnamaker/how-to/edit-knowledge-base"
    },
    {
        "question": "You need to measure the public perception of your b rand on social media messages. Which Azure Cognitive Services service should you use?",
        "options": [
            "A. Text Analytics",
            "B. Content Moderator",
            "C. Computer Vision",
            "D. Form Recognizer"
        ],
        "correct": "A. Text Analytics",
        "explanation": "Explanation:\nThe correct answer is A. Text Analytics. Text Analytics is a cognitive service in Azure that allows you to analyze and extract insights from unstructured text data, and measure sentiment, entities, and language. This service is suitable for analyzing social media messages to measure public perception of a brand.\n\nOption B, Content Moderator, is incorrect because it is primarily used for content moderation and filtering, such as detecting and removing offensive content. While it can be used to analyze text, its primary purpose is different from Text Analytics.\n\nOption C, Computer Vision, is incorrect because it is primarily used for image analysis and processing, such as object detection, facial recognition, and image classification. It is not suitable for analyzing text data.\n\nOption D, Form Recognizer, is incorrect because it is primarily used for extracting data from forms and documents, such as receipts, invoices, and contracts. It is not suitable for analyzing text data for sentiment analysis or public perception.\n\nTherefore, the correct answer is A. Text Analytics.",
        "references": "https://www.linkedin.com/pulse/measuring-public-per ception-azure-cognitive-services-steve-dalai"
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You build a language model by using a Language Unde rstanding service. The language model is used to search for information on a contact list by usin g an intent named FindContact. A conversational expert provides you with the follo wing list of phrases to use for training. Find contacts in London. Who do I know in Seattle? Search for contacts in Ukraine. You need to implement the phrase list in Language U nderstanding. Solution: You create a new intent for location. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "B. No",
        "explanation": "Explanation:\n\nThe correct answer is B. No. \n\nWhy is this the correct answer? \n\nThe goal is to train the language model to search for information on a contact list using an intent named FindContact. The given phrases are related to searching for contacts based on location. Creating a new intent for location does not meet the goal because it does not utilize the existing FindContact intent. Instead, it creates a separate intent for location, which is not the desired outcome. \n\nWhy are the other options incorrect? \n\nThere is only one other option, A. Yes, which is incorrect because creating a new intent for location does not meet the goal of utilizing the FindContact intent.",
        "references": ""
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You build a language model by using a Language Unde rstanding service. The language model is used to search for information on a contact list by usin g an intent named FindContact. A conversational expert provides you with the follo wing list of phrases to use for training. Find contacts in London. Who do I know in Seattle? Search for contacts in Uk raine. You need to implement the phrase list in Language U nderstanding. Solution: You create a new entity for the domain. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "B. No",
        "explanation": "Explanation:\nThe correct answer is B. No. The goal is to implement the phrase list in Language Understanding. Creating a new entity for the domain does not meet this goal. Entities are used to extract specific information from user input, but they do not directly relate to implementing a phrase list.\n\nTo implement the phrase list, you would need to create an intent named FindContact and add the phrases to the intent as examples. This would allow the language model to recognize the phrases and trigger the FindContact intent.\n\nThe other options are incorrect because:\nA. Creating a new entity for the domain does not implement the phrase list. It is a separate concept in Language Understanding that is used for extracting specific information from user input.",
        "references": ""
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You build a language model by using a Language Unde rstanding service. The language model is used to search for information on a contact list by usin g an intent named FindContact. A conversational expert provides you with the follo wing list of phrases to use for training. Find contacts in London. Who do I know in Seattle? Search for contacts in Ukraine. You need to implement the phrase list in Language U nderstanding. Solution: You create a new pattern in the FindConta ct intent. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "B. No",
        "explanation": "Explanation:\nThe correct answer is B. No. This is because a pattern in a Language Understanding intent is used to define a specific phrase or sentence structure that the intent can recognize. In this scenario, you have multiple phrases with different structures, so a single pattern would not be able to recognize all of them. Instead, you would need to create multiple patterns, one for each phrase structure, or use a more advanced technique such as entity recognition.\n\nWhy are the other options incorrect?\nOption A is incorrect because creating a new pattern in the FindContact intent would not be able to recognize all the phrases provided, as they have different structures.",
        "references": ""
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You develop an application to identify species of f lowers by training a Custom Vision model. You receive images of new flower species. You need to add the new images to the classifier. Solution: You add the new images, and then use the Smart Labeler tool. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "B. No",
        "explanation": "Explanation:\n\nThe correct answer is B. No. The Smart Labeler tool is used to automatically label images for training a Custom Vision model. It is not used to add new images to a classifier. To add new images to a classifier, you would need to retrain the model with the new images.\n\nWhy are the other options incorrect?\n\nOption A. Yes is incorrect because the Smart Labeler tool is not used to add new images to a classifier. It is used to automatically label images for training a Custom Vision model.",
        "references": ""
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You develop an application to identify species of f lowers by training a Custom Vision model. You receive images of new flower species. You need to add the new images to the classifier. Solution: You add the new images and labels to the existing model. You retrain the model, and then publish the model. Does this meet the goal? A. Yes",
        "options": [
            "B. No"
        ],
        "correct": "",
        "explanation": "A. Yes\n\nExplanation: \n\nWhen you add new images and labels to the existing model, you are updating the model with new data. By retraining the model, you are allowing the model to learn from the new data and improve its accuracy. Once you publish the model, the updated model is available for use. This meets the goal of adding new images to the classifier.\n\nIncorrect Options:\n\nB. No: This option is incorrect because adding new images and labels to the existing model, retraining the model, and publishing the model is a valid approach to update the classifier with new data.\n\nIn this question, the correct answer is A. Yes. The solution provided meets the goal of adding new images to the classifier. The correct approach is to add the new images and labels to the existing model, retrain the model, and then publish the model. This ensures that the model learns from the new data and improves its accuracy.",
        "references": ""
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You develop an application to identify species of f lowers by training a Custom Vision model. You receive images of new flower species. You need to add the new images to the classifier. Solution: You create a new model, and then upload t he new images and labels. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "B. No",
        "explanation": "Explanation:\n\nThe correct answer is B. No. \n\nCreating a new model is not the correct solution to add new images to the classifier. This approach would require retraining the entire model with all the existing images and labels, which is inefficient and unnecessary. \n\nInstead, the correct approach is to add the new images and labels to the existing model. This can be done by updating the existing model with the new data, which allows the model to learn from the additional images and improve its accuracy. This approach is more efficient and effective. \n\nTherefore, creating a new model and uploading the new images and labels does not meet the goal of adding new images to the classifier.",
        "references": ""
    },
    {
        "question": "HOTSPOT You are developing a service that records lectures given in English (United Kingdom). You have a method named AppendToTranscriptFile that  takes translated text and a language identifier. You need to develop code that will provide transcri pts of the lectures to attendees in their respectiv e language. The supported languages are English, Fren ch, Spanish, and German. How should you complete the code? To answer, select  the appropriate options in the answer area. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D.",
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. The code should be written in the following manner:\n    Language language = Language.EnglishUnitedKingdom;\n    SpeechConfig speechConfig = new SpeechConfig(\"YourSubscriptionKey\", \"YourServiceRegion\");\n    speechConfig.SpeechRecognitionLanguage = language;\n    var synthesizer = new SpeechSynthesizer(speechConfig);\n    synthesizer.SpeakTextAsync(\"Hello, how are you?\");\n\nB. The code should be written in the following manner:\n    Language language = Language.EnglishUnitedKingdom;\n    SpeechConfig speechConfig = new SpeechConfig(\"YourSubscriptionKey\", \"YourServiceRegion\");\n    speechConfig.SpeechRecognitionLanguage = language;\n    var synthesizer = new SpeechSynthesizer(speechConfig);\n    synthesizer.SpeakTextAsync(\"Bonjour, comment allez-vous?\");\n\nC. The code should be written in the following manner:\n    Language language = Language.French;\n    SpeechConfig speechConfig = new SpeechConfig(\"YourSubscriptionKey\", \"YourServiceRegion\");\n    speechConfig.SpeechRecognitionLanguage = language;\n    var synthesizer = new SpeechSynthesizer(speechConfig);\n    synthesizer.SpeakTextAsync(\"Hola, \u00bfc\u00f3mo est\u00e1s?\");\n\nD. The code should be written in the following manner:\n    Language language = Language.German;\n    SpeechConfig speechConfig = new SpeechConfig(\"YourSubscriptionKey\", \"YourServiceRegion\");\n    speechConfig.SpeechRecognitionLanguage = language;\n    var synthesizer = new SpeechSyn",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/text-analytics/how-tos/text-analyticshow- to-keyword-extraction"
    },
    {
        "question": "You deploy a web app that is used as a management p ortal for indexing in Azure Cognitive Search. The app is configured to use the primary admin key. During a security review, you discover unauthorized  changes to the search index. You suspect that the primary access key is compromised. You need to prevent unauthorized access to the inde x management endpoint. The solution must minimize downtime. What should you do next?",
        "options": [
            "A. Regenerate the primary admin key, change the app to use the secondary admin key, and then regenerate",
            "B. Change the app to use a query key, and then regen erate the primary admin key and the secondary admin",
            "C. Regenerate the secondary admin key, change the ap p to use the secondary admin key, and then",
            "D. Add a new query key, change the app to use the ne w query key, and then delete all the unused query k eys."
        ],
        "correct": "C. Regenerate the secondary admin key, change the ap p to use the secondary admin key, and then",
        "explanation": "Explanation:\n\nThe correct answer is C. Regenerate the secondary admin key, change the app to use the secondary admin key, and then regenerate the primary admin key.\n\nHere's why:\n\nWhen the primary admin key is compromised, the first step is to minimize downtime by switching to the secondary admin key. This ensures that the app remains functional while you take steps to address the security breach.\n\nRegenerating the secondary admin key ensures that it's not compromised as well. Then, you update the app to use the new secondary admin key. This minimizes downtime, as the app can continue to function with the new secondary key.\n\nFinally, you regenerate the primary admin key to ensure that it's secure again. This approach minimizes downtime and ensures that the app remains secure.\n\nNow, let's discuss why the other options are incorrect:\n\nOption A is incorrect because regenerating the primary admin key first would cause downtime, as the app would no longer be able to access the index management endpoint. By switching to the secondary admin key first, you minimize downtime.\n\nOption B is incorrect because query keys are used for read-only access and are not suitable for index management. The app needs to use an admin key to perform management tasks.\n\nOption D is incorrect because adding a new query key and switching the app to use it would not address the security breach of the primary admin key. Additionally, deleting unused query keys is not relevant to addressing the compromised primary admin key.\n\nIn summary, the correct approach is to regenerate the secondary",
        "references": ""
    },
    {
        "question": "You have an existing Azure Cognitive Search service . You have an Azure Blob storage account that contain s millions of scanned documents stored as images an d PDFs. You need to make the scanned documents available to  search as quickly as possible. What should you do?",
        "options": [
            "A. Split the data into multiple blob containers. Cre ate a Cognitive Search service for each container.",
            "B. Split the data into multiple blob containers. Cre ate an indexer for each container. Increase the",
            "C. Create a Cognitive Search service for each type o f document.",
            "D. Split the data into multiple virtual folders. Cre ate an indexer for each folder. Increase the search"
        ],
        "correct": "D. Split the data into multiple virtual folders. Cre ate an indexer for each folder. Increase the search",
        "explanation": "Explanation: The correct answer is D. Split the data into multiple virtual folders. Create an indexer for each folder. Increase the search service scale.\n\nThis is because splitting the data into multiple virtual folders allows you to process the data in parallel, which can significantly speed up the indexing process. Creating an indexer for each folder allows you to define a separate indexing pipeline for each folder, which can be optimized for the specific type of documents in that folder. Increasing the search service scale allows you to handle the increased load of indexing millions of documents.\n\nOption A is incorrect because creating a separate Cognitive Search service for each container would not provide any performance benefits and would likely increase costs.\n\nOption B is incorrect because creating an indexer for each container would not provide any performance benefits and would likely increase costs. Increasing the number of indexers would not necessarily speed up the indexing process.\n\nOption C is incorrect because creating a separate Cognitive Search service for each type of document would not provide any performance benefits and would likely increase costs. It would also require more management and maintenance.\n\nIn this scenario, splitting the data into multiple virtual folders and creating an indexer for each folder, along with increasing the search service scale, provides the best approach to making the scanned documents available for search as quickly as possible.",
        "references": "https://docs.microsoft.com/en-us/azure/search/searc h-howto-indexing-azure-blob-storage"
    },
    {
        "question": "You need to implement a table projection to generat e a physical expression of an Azure Cognitive Search index. Which three properties should you specify in the sk illset definition JSON configuration table node? Each correct answer presents part of the solution. (Choose three.) NOTE: Each correct selection is worth one point.",
        "options": [
            "A. tableName",
            "B. generatedKeyName",
            "C. dataSource",
            "D. dataSourceConnection"
        ],
        "correct": "",
        "explanation": "A. tableName, the correct answer is A. tableName, B. generatedKeyName, and C. dataSource \n\nExplanation: \n\nThe correct answer is A. tableName, B. generatedKeyName, and C. dataSource. These three properties are required to implement a table projection to generate a physical expression of an Azure Cognitive Search index.\n\ntableName: This property specifies the name of the table that you want to project.\n\ngeneratedKeyName: This property specifies the name of the generated key column that is used to uniquely identify each row in the table.\n\ndataSource: This property specifies the data source that contains the table you want to project.\n\nThe other options are incorrect because:\n\nD. dataSourceConnection: This property is not required for implementing a table projection. It is used to specify the connection details for the data source, but it is not necessary for generating a physical expression of an Azure Cognitive Search index.\n\nIn summary, the correct answer is A. tableName, B. generatedKeyName, and C. dataSource because these three properties are required to implement a table projection to generate a physical expression of an Azure Cognitive Search index.",
        "references": "https://docs.microsoft.com/en-us/azure/search/knowl edge-store-projection-overview"
    },
    {
        "question": "HOTSPOT You are creating an enrichment pipeline that will u se Azure Cognitive Search. The knowledge store contains unstructured JSON data and scanned PDF doc uments that contain text. Which projection type should you use for each data type? To answer, select the appropriate options in the answer area. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. JSON data: Table projection\nB. Scanned PDF documents: File projection",
        "references": "https://docs.microsoft.com/en-us/azure/search/knowl edge-store-projection-overview"
    },
    {
        "question": "HOTSPOT You are building an Azure Cognitive Search custom s kill. You have the following custom skill schema definiti on. For each of the following statements, select Yes if  the statement. Otherwise, select No. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "{ \n\"@odata.type\": \"#Microsoft.Skills.Text.EntityRecognitionSkill\", \n\"name\": \"EntityRecognition\", \n\"description\": \"Entity recognition skill\", \n\"context\": \"/document\", \n\"categories\": [\"Person\", \"Organization\", \"Location\"], \n\"defaultLanguageCode\": \"en\", \n\"inputs\": [ \n{ \n\"name\": \"text\", \n\"type\": \"string\" \n} \n], \n\"outputs\": [ \n{ \n\"name\": \"entities\", \n\"type\": \"array\" \n} \n] \n}\n\nWhich of the following statements is true about the custom skill schema definition?\n\nA. The custom skill can only be used with documents in English language.\nB. The custom skill can recognize entities in multiple categories.\nC. The custom skill can only recognize entities in the \"Person\" category.\nD. The custom skill can only be used with documents that contain a single entity.\n\nCorrect Answer: B. The custom skill can recognize entities in multiple categories.\n\nExplanation: The correct answer is B because the custom skill schema definition specifies multiple categories (\"Person\", \"Organization\", \"Location\") in the \"categories\" property. This means that the custom skill can recognize entities in multiple categories.\n\nExplanation for incorrect answers:\n\nA. The custom skill schema definition specifies a default language code of \"en\", but this does not mean that the custom skill can only be used with documents in English language. The default language code can be overridden when the custom skill is invoked.\n\nC. The custom skill schema definition",
        "references": "https://docs.microsoft.com/en-us/azure/search/cogni tive-search-output-field-mapping"
    },
    {
        "question": "You have the following data sources: Finance: On-premises Microsoft SQL Server database Sales: Azure Cosmos DB using the Core (SQL) API Logs: Azure Table storage HR: Azure SQL database You need to ensure that you can search all the data  by using the Azure Cognitive Search REST API. What should you do?",
        "options": [
            "A. Configure multiple read replicas for the data in Sales.",
            "B. Mirror Finance to an Azure SQL database.",
            "C. Migrate the data in Sales to the MongoDB API.",
            "D. Ingest the data in Logs into Azure Sentinel."
        ],
        "correct": "B. Mirror Finance to an Azure SQL database.",
        "explanation": "Explanation: The correct answer is B. Mirror Finance to an Azure SQL database. The Azure Cognitive Search REST API can index data from multiple data sources, including Azure SQL databases, Cosmos DB, and Azure Table storage. However, it cannot directly index data from an on-premises Microsoft SQL Server database. To make the Finance data searchable, you need to mirror or replicate the data to an Azure SQL database, which can then be indexed by Azure Cognitive Search.\n\nOption A is incorrect because configuring multiple read replicas for the data in Sales will not make the Finance data searchable.\n\nOption C is incorrect because migrating the data in Sales to the MongoDB API will not make the Finance data searchable, and Azure Cognitive Search can already index data from Cosmos DB using the Core (SQL) API.\n\nOption D is incorrect because ingesting the data in Logs into Azure Sentinel will not make the Finance data searchable, and Azure Sentinel is a security information and event management (SIEM) system that is not related to Azure Cognitive Search.",
        "references": "https://docs.microsoft.com/en-us/azure/search/searc h-indexer-overview#supported-data-sources"
    },
    {
        "question": "You are building a multilingual chatbot. You need to send a different answer for positive an d negative messages. Which two Text Analytics APIs should you use? Each correct answer presents part of the solution. (Choose two.) NOTE: Each correct selection is worth one point.",
        "options": [
            "A. Linked entities from a well-known knowledge base",
            "B. Sentiment Analysis",
            "C. Key Phrases",
            "D. Detect Language"
        ],
        "correct": "",
        "explanation": "B. Sentiment Analysis\nD. Detect Language\n\nExplanation: \n\n    The correct answer is B. Sentiment Analysis and D. Detect Language because Sentiment Analysis is used to determine whether the message is positive or negative, A sentiment analysis model is trained on a dataset that is labeled with sentiment scores, and it uses this training to predict the sentiment of new, unseen text. This is useful in chatbots to determine how to respond to user messages. Detect Language is used to detect the language of the message. This is useful in a multilingual chatbot because it allows the chatbot to respond in the user's native language.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/text-analytics/how-tos/text-analyticshow- to- sentiment-analysis?tabs=version-3-1 https://docs.microsoft.com/en-us/azure/cognitive-se rvices/text-analytics/how-tos/text-analyticshow- to- language-detection"
    },
    {
        "question": "DRAG DROP You plan to build a chatbot to support task trackin g. You create a Language Understanding service named l u1. You need to build a Language Understanding model to  integrate into the chatbot. The solution must minimize development time to build the model. Which four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order. (Choose four.) A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Create intents \nB. Add utterances \nC. Train the model \nD. Create entities \n\nThe correct answer is: A, B, D, C.",
        "references": ""
    },
    {
        "question": "You are building a bot on a local computer by using  the Microsoft Bot Framework. The bot will use an existing Language Understanding model. You need to translate the Language Understanding mo del locally by using the Bot Framework CLI. What should you do first?",
        "options": [
            "A. From the Language Understanding portal, clone the  model.",
            "B. Export the model as an .lu file.",
            "C. Create a new Speech service.",
            "D. Create a new Language Understanding service."
        ],
        "correct": "B. Export the model as an .lu file.",
        "explanation": "Explanation:\nThe correct answer is B. Export the model as an .lu file. The Bot Framework CLI requires an .lu file to translate a Language Understanding model locally. This file contains the model's metadata and the model itself. Therefore, you need to export the model as an .lu file from the Language Understanding portal before translating it locally.\n\nOption A is incorrect because cloning the model from the Language Understanding portal does not provide the required .lu file. Cloning a model creates a copy of the model in the portal, but it does not export the model in the required format for local translation.\n\nOption C is incorrect because creating a new Speech service is not related to translating a Language Understanding model locally. The Speech service is used for speech recognition and synthesis, not for language understanding.\n\nOption D is incorrect because creating a new Language Understanding service is also not related to translating a Language Understanding model locally. Creating a new service allows you to create and train new language understanding models, but it does not provide the required .lu file for local translation.",
        "references": "https://github.com/microsoft/botframework-cli/blob/ main/packages/luis/docs/translatecommand.md"
    },
    {
        "question": "DRAG DROP You are using a Language Understanding service to h andle natural language input from the users of a web-based customer agent. The users report that the agent frequently responds  with the following generic response: \"Sorry, I don't understand that.\" You need to improve the ability of the agent to res pond to requests. Which three actions should you perform in sequence?  To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order. (Choose three.)",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Review and update the intent schema \nB. Collect and label more training data \nC. Retrain the model \nD. Analyze the conversation logs \n\nCorrect Answer: D-A-B-C\n\nExplanation:\n\nThe correct answer is D-A-B-C. This is because, to improve the ability of the agent to respond to requests, you should first analyze the conversation logs to identify the patterns and trends in user requests that are causing the generic response. Then, you should review and update the intent schema to ensure that it accurately captures the user's intent. Next, you should collect and label more training data to improve the model's accuracy. Finally, you should retrain the model with the updated data to improve its performance.\n\nNow, let me explain why the other options are incorrect.\n\nOption A-B-C is incorrect because reviewing and updating the intent schema should be done after analyzing the conversation logs, not before. Similarly, collecting and labeling more training data should be done after updating the intent schema, not before. \n\nOption B-C-D is incorrect because collecting and labeling more training data should be done after reviewing and updating the intent schema, not before. \n\nOption C-D-A is incorrect because retraining the model should be done after collecting and labeling more training data, not before. \n\nOption A-C-D is incorrect because reviewing and updating the intent schema should be done after analyzing the conversation logs, not before.",
        "references": ""
    },
    {
        "question": "You build a conversational bot named bot1. You need to configure the bot to use a QnA Maker ap plication. From the Azure Portal, where can you find the infor mation required by bot1 to connect to the QnA Maker application?",
        "options": [
            "A. Access control (IAM)",
            "B. Properties",
            "C. Keys and Endpoint",
            "D. Identity"
        ],
        "correct": "C. Keys and Endpoint",
        "explanation": "Explanation:\nThe correct answer is C. Keys and Endpoint. This is because the QnA Maker application requires bot1 to have the keys and endpoint information to connect and authenticate with the QnA Maker service. The keys and endpoint information is found in the Azure Portal under the QnA Maker application settings.\n\nOption A. Access control (IAM) is incorrect because IAM is used for managing access to Azure resources, not for finding connection information for a QnA Maker application.\n\nOption B. Properties is incorrect because the properties section of the QnA Maker application in the Azure Portal does not contain the connection information required by bot1.\n\nOption D. Identity is incorrect because the identity section of the QnA Maker application in the Azure Portal is used for managing the identity of the application, not for finding connection information.\n\nTherefore, the correct answer is C. Keys and Endpoint.",
        "references": "https://docs.microsoft.com/en-us/azure/bot-service/ bot-builder-howto-qna"
    },
    {
        "question": "HOTSPOT You are building a chatbot by using the Microsoft B ot Framework Composer. You have the dialog design shown in the following e xhibit. For each of the following statements, select Yes if  the statement is true. Otherwise, select No. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D.",
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Yes\nB. No\nC. Yes\nD. No\n\nExplanation: \n\nThe given exhibit shows a dialog design in Microsoft Bot Framework Composer. \n\nA. The dialog starts with the Welcome message. (Yes/No) \nThe dialog indeed starts with the Welcome message. Therefore, the correct answer is Yes. \n\nB. The user can choose to cancel the order. (Yes/No) \nThere is no cancel button or option in the dialog. Therefore, the correct answer is No. \n\nC. The user is asked about their order type. (Yes/No) \nThe dialog does ask about the user's order type. Therefore, the correct answer is Yes. \n\nD. The dialog ends after the user selects their order type. (Yes/No) \nThe dialog does not end after the user selects their order type. There are additional steps and prompts after this point. Therefore, the correct answer is No.",
        "references": "https://docs.microsoft.com/enus/ dotnet/api/microsoft.bot.builder.activityhandler.on membersaddedasync?view=botbuilderdotnet-stable"
    },
    {
        "question": "HOTSPOT You are building a chatbot by using the Microsoft B ot Framework SDK. You use an object named UserProfile to store user p rofile information and an object named ConversationData to store information related to a conversation. You create the following state accessors to store b oth objects in state. var userStateAccessors = _userState.CreateProperty< UserProfile>(nameof(UserProfile)); var conversationStateAccessors = _conversationState.CreateProperty<ConversationData> (nameof(ConversationData)); The state storage mechanism is set to Memory Storag e. For each of the following statements, select Yes if  the statement is true. Otherwise, select No. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. The UserProfile object will be persisted across multiple conversations.\nB. The ConversationData object will be persisted across multiple turns in the same conversation.\nC. The UserProfile object will be persisted across multiple turns in the same conversation.\nD. The ConversationData object will be persisted across multiple conversations.\n\nExplanation: \n\nThe correct answer is B. The ConversationData object will be persisted across multiple turns in the same conversation.\n\nExplanation:\n\nSince the state storage mechanism is set to Memory Storage, the data is stored in memory only. When the conversation ends, the memory storage is cleared. \n\nTherefore, the UserProfile object (A) will not be persisted across multiple conversations because it is stored in memory and memory storage is cleared after each conversation. \n\nThe ConversationData object (B) will be persisted across multiple turns in the same conversation because it is stored in memory and memory storage is not cleared until the conversation ends. \n\nThe UserProfile object (C) will not be persisted across multiple turns in the same conversation because it is stored in memory and memory storage is cleared after each conversation. \n\nThe ConversationData object (D) will not be persisted across multiple conversations because it is stored in memory and memory storage is cleared after each conversation.",
        "references": "https://docs.microsoft.com/en-us/azure/bot-service/ bot-builder-howto-v4-state"
    },
    {
        "question": "HOTSPOT You are building a chatbot that will provide inform ation to users as shown in the following exhibit. Use the drop-down menus to select the answer choice  that completes each statement based on the information presented in the graphic. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "What is the purpose of the Lexicon component?\nA. To provide a natural language understanding (NLU) to the chatbot\nB. To provide a natural language processing (NLP) to the chatbot\nC. To provide a natural language generation (NLG) to the chatbot\nD. To provide a database for storing user information\n\nExplanation:\nThe correct answer is A. To provide a natural language understanding (NLU) to the chatbot. \n\nThe Lexicon component is responsible for understanding the meaning of user inputs, which is the definition of Natural Language Understanding (NLU). It breaks down the user's input into its constituent parts, identifies the intent behind the input, and extracts relevant information. \n\nOption B is incorrect because Natural Language Processing (NLP) is a broader field that encompasses both NLU and NLG. While NLP is related to the Lexicon component, it is not the specific purpose of this component. \n\nOption C is incorrect because Natural Language Generation (NLG) is the process of generating human-like language outputs, which is not the purpose of the Lexicon component. \n\nOption D is incorrect because the Lexicon component is not responsible for storing user information. This task is typically handled by a database or data storage component.",
        "references": "https://docs.microsoft.com/en-us/microsoftteams/pla tform/task-modules-and-cards/cards/cardsreference https://docs.microsoft.com/en-us/composer/how-to-se nd-cards?tabs=v1x"
    },
    {
        "question": "HOTSPOT You are reviewing the design of a chatbot. The chat bot includes a language generation file that contains the following fragment. # Greet(user) - ${Greeting()}, ${user.name} For each of the following statements, select Yes if  the statement is true. Otherwise, select No. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Yes\nB. No\nC. Yes\nD. No\n\nThis question is related to the AWS Lex chatbot service.\n\nHere is the explanation:\n\nThe correct answer is A. Yes, B. No, C. Yes, D. No.\n\nA. Yes: The language generation file uses the ${Greeting()} function to generate a greeting for the user. This is a valid use of a function in the language generation file.\n\nB. No: The language generation file does not use a conditional statement to determine the greeting based on the user's name. The greeting is generated using the ${Greeting()} function, which does not take any parameters.\n\nC. Yes: The language generation file uses the ${user.name} variable to access the user's name. This is a valid use of a variable in the language generation file.\n\nD. No: The language generation file does not use a loop to iterate over a list of greetings. The greeting is generated using the ${Greeting()} function, which returns a single value.\n\nThe other options are incorrect because they do not accurately describe the language generation file. Option B is incorrect because the file does not use a conditional statement. Option D is incorrect because the file does not use a loop.",
        "references": "https://docs.microsoft.com/en-us/composer/how-to-as k-for-user-input"
    },
    {
        "question": "A customer uses Azure Cognitive Search. The customer plans to enable a server-side encrypti on and use customer-managed keys (CMK) stored in Azure. What are three implications of the planned change? Each correct answer presents a complete solution. NOTE: Each correct selection is worth one point. A. The index size will increase.",
        "options": [
            "B. Query times will increase.",
            "C. A self-signed X.509 certificate is required.",
            "D. The index size will decrease."
        ],
        "correct": "",
        "explanation": "A,,'the index size will increase. \n\nB. Query times will increase. \n\nC. An Azure Key Vault is required.\n\nExplanation: \n\nThe correct answers are A, B, and C. \n\nHere's why:\n\nA. When you use customer-managed keys (CMK) for server-side encryption, the encrypted data is stored along with the encryption metadata, which includes the key ID and other information. This metadata increases the size of the index. Therefore, the index size will increase.\n\nB. When you use CMK for server-side encryption, Azure Cognitive Search needs to make an additional call to Azure Key Vault to retrieve the encryption key. This additional call increases the latency of the query, resulting in increased query times.\n\nC. To use customer-managed keys (CMK) for server-side encryption, you need to store the keys in Azure Key Vault. This is a secure storage service that is designed to safeguard cryptographic keys and secrets. Therefore, an Azure Key Vault is required.\n\nThe other options are incorrect because: \n\nD. The index size will not decrease. In fact, it will increase due to the additional metadata required for encryption.\n\n1. There is no requirement for a self-signed X.509 certificate. Azure Key Vault is used to store the CMK, and it does not require a self-signed certificate.",
        "references": ""
    },
    {
        "question": "You are developing a new sales system that will pro cess the video and text from a public-facing websit e. You plan to notify users that their data has been p rocessed by the sales system. Which responsible AI principle does this help meet?",
        "options": [
            "A. transparency",
            "B. fairness",
            "C. inclusiveness",
            "D. reliability and safety"
        ],
        "correct": "A. transparency",
        "explanation": "Explanation: \nThe correct answer is A. transparency. This is because the sales system is notifying users that their data has been processed,,assistant\n\nAs an expert in Cloud technologies, I'd be happy to explain why the correct answer is A. transparency.\n\nThe principle of transparency in responsible AI refers to the ability of an AI system to provide clear and understandable explanations of its decision-making processes, as well as the data it collects and uses. In this scenario, the sales system is notifying users that their data has been processed, which implies that the system is being transparent about its actions and the data it is handling. This notification provides users with insight into what is happening with their data, which is a key aspect of transparency.\n\nNow, let's discuss why the other options are incorrect:\n\n**B. Fairness**: While fairness is an important principle of responsible AI, it doesn't directly relate to the scenario described. Fairness focuses on ensuring that AI systems do not discriminate against certain groups or individuals, and that they are free from bias. In this case, the sales system is simply notifying users that their data has been processed, which doesn't necessarily imply anything about fairness.\n\n**C. Inclusiveness**: Inclusiveness is another important principle of responsible AI, which aims to ensure that AI systems are designed to be accessible and usable by a diverse range of people. While inclusiveness is crucial, it's not directly related to the scenario described, where the sales system is simply notifying users",
        "references": ""
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You create a web app named app1 that runs on an Azu re virtual machine named vm1. Vm1 is on an Azure virtual network named vnet1. You plan to create a new Azure Cognitive Search ser vice named service1. You need to ensure that app1 can connect directly t o service1 without routing traffic over the public internet. Solution: You deploy service1 and a public endpoint  to a new virtual network, and you configure Azure Private Link. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No Correct Answer: B"
        ],
        "correct": "",
        "explanation": "Explanation:\n\nThe correct answer is B. No. \n\nThe reason is that Azure Private Link allows you to access Azure services over a private endpoint in your virtual network. However, in this scenario, service1 and the public endpoint are deployed to a new virtual network, which is not the same as vnet1 where vm1 is located. This means that app1 running on vm1 will not be able to connect directly to service1 without routing traffic over the public internet. \n\nTo meet the goal, service1 and the private endpoint should be deployed to vnet1, so that app1 can access service1 directly without going over the public internet.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/cognitive-services-virtualnetworks? tabs=portal#use-private-endpoints"
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You create a web app named app1 that runs on an Azu re virtual machine named vm1. Vm1 is on an Azure virtual network named vnet1. You plan to create a new Azure Cognitive Search ser vice named service1. You need to ensure that app1 can connect directly t o service1 without routing traffic over the public internet. Solution: You deploy service1 and a public endpoint , and you configure an IP firewall rule. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "B. No",
        "explanation": "Explanation:\nThe correct answer is B. No. The solution does not meet the goal because it uses a public endpoint, which means the traffic will still be routed over the public internet. To achieve the goal, you need to deploy service1 with a private endpoint, which allows the Azure virtual machine (vm1) to connect directly to the Azure Cognitive Search service (service1) without routing traffic over the public internet.\n\nThe other options are incorrect because:\n\nA. No, the solution does not meet the goal because it uses a public endpoint, which does not provide direct connectivity without routing traffic over the public internet.\n\nNote: The question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution while others might not have a correct solution.",
        "references": "https://docs.microsoft.com/en-us/azure/private-link /private-link-overview"
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You create a web app named app1 that runs on an Azu re virtual machine named vm1. Vm1 is on an Azure virtual network named vnet1. You plan to create a new Azure Cognitive Search ser vice named service1. You need to ensure that app1 can connect directly t o service1 without routing traffic over the public internet. Solution: You deploy service1 and a public endpoint , and you configure a network security group (NSG) for vnet1. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "A. Yes",
        "explanation": "Explanation:\nThe correct answer is A. Yes. This solution meets the goal because the Azure Cognitive Search service (service1) is deployed with a public endpoint, and a network security group (NSG) is configured for the Azure virtual network (vnet1) where the virtual machine (vm1) running the web app (app1) resides. This allows app1 to connect directly to service1 without routing traffic over the public internet.\n\nThe reason why the other options are incorrect is that option B. No is incorrect because the solution does provide a way for app1 to connect directly to service1 without routing traffic over the public internet.",
        "references": ""
    },
    {
        "question": "You plan to perform predictive maintenance. You collect IoT sensor data from 100 industrial mac hines for a year. Each machine has 50 different sensors that generate data at one-minute intervals.  In total, you have 5,000 time series datasets. You need to identify unusual values in each time se ries to help predict machinery failures. Which Azure Cognitive Services service should you u se?",
        "options": [
            "A. Anomaly Detector",
            "B. Cognitive Search",
            "C. Form Recognizer",
            "D. Custom Vision"
        ],
        "correct": "A. Anomaly Detector",
        "explanation": "Explanation:\nThe correct answer is A. Anomaly Detector. Anomaly Detector is a Cognitive Services API that uses advanced machine learning algorithms to identify unusual values in time series data. It is designed to analyze large datasets and detect anomalies, which makes it the ideal choice for this scenario.\n\nOption B, Cognitive Search, is incorrect because it is a search service that enables you to search and index data from various sources. It is not designed for anomaly detection.\n\nOption C, Form Recognizer, is incorrect because it is an AI-powered service that extracts data from forms and documents. It is not related to anomaly detection.\n\nOption D, Custom Vision, is incorrect because it is a computer vision service that enables you to build and train custom image classification models. It is not designed for anomaly detection in time series data.\n\nIn summary, Anomaly Detector is the best choice for identifying unusual values in time series data, which is essential for predictive maintenance.",
        "references": ""
    },
    {
        "question": "HOTSPOT You are developing a streaming Speech to Text solut ion that will use the Speech SDK and MP3 encoding. You need to develop a method to convert speech to t ext for streaming MP3 data. How should you complete the code? To answer, select  the appropriate options in the answer area. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A.\n1. \nB.\n2. \nC.\n3.\n\nExplanation: \n\nThe correct answer is A.1, B.2, C.3.\n\nHere is the correct code:\n\nusing Microsoft.Azure.CognitiveServices.Speech;\nusing Microsoft.Azure.CognitiveServices.Speech.Audio;\nusing System.IO;\n\nclass Program\n{\n    static async Task Main(string[] args)\n    {\n        var config = SpeechConfig.FromSubscription(\"YourSubscriptionKey\", \"YourServiceRegion\");\n        using var audioConfig = AudioConfig.FromWavFileInput(new FileStream(\"path_to_your_mp3_file.mp3\", FileMode.Open, FileAccess.Read));\n        using var recognizer = new SpeechRecognizer(config, audioConfig);\n        var result = await recognizer.RecognizeOnceAsync();\n        Console.WriteLine($\"Recognized text: {result.Text}\");\n    }\n}\n\nExplanation: \n\nThe correct code is using the Speech SDK to convert speech to text for streaming MP3 data. \n\nA.1. is correct because it uses the SpeechConfig.FromSubscription method to create a SpeechConfig object. This object is used to configure the speech recognition service.\n\nB.2. is correct because it uses the AudioConfig.FromWavFileInput method to create an AudioConfig object. This object is used to specify the audio input source, which in this case is an MP3 file.\n\nC.3. is correct because it uses the SpeechRecognizer object to recognize speech from the audio input source and convert it to text.\n\nThe other options are",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/speech-service/how-to-use-codeccompressed- audio-input-streams?tabs=debian&pivots=programming- language-csharp"
    },
    {
        "question": "HOTSPOT You are developing an internet-based training solut ion for remote learners. Your company identifies that during the training, s ome learners leave their desk for long periods or become distracted. You need to use a video and audio feed from each le arner- computer to detect whether the learner is present and paying attention. The solution must minimize development effort and identify each learner. Which Azure Cognitive Services service should you u se for each requirement? To answer, select the appropriate options in the answer area. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "D. Face API \n\nExplanation: \n\nFace API is used to detect the presence of learners and identify each learner. The Face API is a cloud-based API that provides advanced face detection, verification, identification, and analysis capabilities. It can be used to detect faces in images and videos, identify individuals, and analyze facial features. In this scenario, the Face API can be used to analyze the video feed from each learner's computer to detect whether the learner is present and paying attention.\n\nWhy are the other options incorrect?\n\nA. Computer Vision: Computer Vision is used for image analysis, not for detecting the presence of learners. While it can be used for facial recognition, it is not the best choice for this scenario.\n\nB. Speech Services: Speech Services is used for speech recognition, not for detecting the presence of learners. It can be used to analyze audio feeds, but it is not the best choice for this scenario.\n\nC. Language Understanding (LUIS): Language Understanding (LUIS) is used for natural language processing, not for detecting the presence of learners. It can be used to analyze text or speech, but it is not the best choice for this scenario.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/what-are-cognitive-services"
    },
    {
        "question": "You plan to provision a QnA Maker service in a new resource group named RG1. In RG1, you create an App Service plan named AP1. Which two Azure resources are automatically created  in RG1 when you provision the QnA Maker service? Each correct answer presents part of the s olution. NOTE: Each correct selection is worth one point.",
        "options": [
            "A. Language Understanding",
            "B. Azure SQL Database",
            "C. Azure Storage",
            "D. Azure Cognitive Search"
        ],
        "correct": "",
        "explanation": "C. Azure Storage\nD. Azure Cognitive Search\n\nExplanation: \n\nWhen you provision a QnA Maker service, two resources are automatically created: Azure Storage and Azure Cognitive Search. \n\nAzure Storage is used to store the knowledge base of the QnA Maker service. The knowledge base is a collection of questions and answers that are used to train the QnA Maker model.\n\nAzure Cognitive Search is used to index the knowledge base and provide search capabilities for the QnA Maker service. This allows the QnA Maker service to quickly retrieve answers to user queries.\n\nThe other options are incorrect because:\n\nA. Language Understanding is a different Azure Cognitive Service that is used for natural language processing, but it is not automatically created when provisioning a QnA Maker service.\n\nB. Azure SQL Database is not automatically created when provisioning a QnA Maker service. While Azure SQL Database can be used to store data for a QnA Maker service, it is not a required resource for the service.\n\nI hope it is correct.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/qnamaker/how-to/set-up-qnamakerservice- azure?tabs=v1#delete-azure-resources \"When you create a QnAMaker resource, you host the data in your own Azure subscription. Azure Search is used to index your data.\" & \"When you cre ate a QnAMaker resource, you host the runtime in your own Azure subscription. App Service is the compute engine that runs the QnA Maker queries for you.\""
    },
    {
        "question": "You create a new Language Understanding resource. You need to add more contributors. What should you use?",
        "options": [
            "A. a conditional access policy in Azure Active Direc tory (Azure AD)",
            "B. the Access control (1AM ) page for the authoring resources in the Azure portal",
            "C. the Access control (1AM) page for the prediction resources in the Azure portal"
        ],
        "correct": "B. the Access control (1AM ) page for the authoring resources in the Azure portal",
        "explanation": "Explanation:\nThe correct answer is B. the Access control (IAM) page for the authoring resources in the Azure portal.\n\nWhen you create a new Language Understanding resource, AKA LUIS, you need to add more contributors, which means you need to manage access control for the resource. The Access control (IAM) page for the authoring resources in the Azure portal is the correct place to do this. \n\nHere, you can assign roles to users or groups, giving them the necessary permissions to contribute to the Language Understanding resource.\n\nOption A is incorrect because conditional access policies in Azure Active Directory (Azure AD) are used to control access to applications and resources based on user and device properties, but it's not related to managing access control for a specific resource like LUIS.\n\nOption C is also incorrect because the Access control (IAM) page for the prediction resources in the Azure portal is used to manage access control for the prediction endpoint of the Language Understanding resource, not for the authoring resources.\n\nIn summary, the correct answer is B because it allows you to manage access control for the authoring resources of the Language Understanding resource, which is what you need to do to add more contributors.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/luis/luis-how-to-collaborate"
    },
    {
        "question": "HOTSPOT You have a Computer Vision resource named contoso1 that is hosted in the West US Azure region. You need to use contoso1 to make a different size o f a product photo by using the smart cropping feature. How should you complete the API URL? To answer, sel ect the appropriate options in the answer area. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D.",
            "A.",
            "B.",
            "C.",
            "D.",
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "https://westus.api.cognitive.microsoft.com/vision/v3.2/analyze?visualFeatures=Categories&details=Celebrity&language=en&regions={regions}&ocr=true&smartCropping=true&width={width}&height={height}\n\nExplanation:\nThe correct API URL is the one that includes the smartCropping=true parameter. This parameter is used to enable smart cropping, which is a feature of the Computer Vision API that automatically detects the region of interest in an image and crops it accordingly. The other options do not include this parameter, and therefore do not enable smart cropping.\n\nThe correct API URL also includes the visualFeatures=Categories parameter, which specifies that the API should analyze the image and return a list of categories that the image belongs to. The details=Celebrity parameter specifies that the API should return additional information about any celebrities detected in the image. The language=en parameter specifies that the API should return results in English. The regions={regions} parameter specifies that the API should analyze the specified regions of the image. The ocr=true parameter specifies that the API should perform optical character recognition (OCR) on the image. The width={width} and height={height} parameters specify the desired width and height of the output image.\n\nThe other options are incorrect because they do not include the smartCropping=true parameter, which is required to enable smart cropping.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/custom-vision-service/export-yourmodel"
    },
    {
        "question": "HOTSPOT You are developing an application to recognize empl oyees' faces by using the Face Recognition API. Images of the faces will be accessible from a URI e ndpoint. The application has the following code. For each of the following statements, select Yes if  the statement is true. Otherwise, select No. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D.",
            "A. True",
            "B. True",
            "C. True"
        ],
        "correct": "",
        "explanation": "A. True\nB. True\nC. False\n\nExplanation: The correct answer is A. True, B. True, and C. False. Here's why:\n\nA. True: The Face Recognition API can recognize faces from images accessible from a URI endpoint. This is one of the ways to use the API.\n\nB. True: The API can recognize faces from images stored in Azure Blob Storage. This is another way to use the API.\n\nC. False: The API does not support recognizing faces from images stored in Azure File Storage. The Face Recognition API only supports recognizing faces from images stored in Azure Blob Storage or accessible from a URI endpoint.\n\nThe other options are incorrect because they do not provide a complete and accurate explanation of the Face Recognition API's capabilities.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/face/face-api-how-to-topics/usepersondirecto ry"
    },
    {
        "question": "DRAG DROP You have a Custom Vision resource named acvdev in a  development environment. You have a Custom Vision resource named acvprod in a production environment. In acvdev, you build an object detection model name d obj1 in a project named proj1. You need to move obj1 to acvprod. Which three actions should you perform in sequence?  To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "1. Export the obj1 model from acvdev\n2. Create a new project named proj1 in acvprod\n3. Import the obj1 model into the proj1 project in acvprod\n\nExplanation: \nThe correct sequence of actions to move obj1 to acvprod is to first export the obj1 model from acvdev, then create a new project named proj1 in acvprod, and finally import the obj1 model into the proj1 project in acvprod.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/luis/luis-tutorial-pattern#what-did-thistuto rial- accomplish"
    },
    {
        "question": "DRAG DROP You train a Custom Vision model used in a mobile ap p. You receive 1,000 new images that do not have any a ssociated data. You need to use the images to retrain the model. Th e solution must minimize how long it takes to retrain the model. Which three actions should you perform in the Custo m Vision portal? To answer, move the appropriate actions from the list of actions to the  answer area and arrange them in the correct order.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "    1. Upload images\n    2. Tag images\n    3. Train model\n\nExplanation:\nThe correct order of actions in the Custom Vision portal to retrain the model is:\n1. Upload images: You need to upload the 1,000 new images to the Custom Vision portal.\n2. Tag images: After uploading the images, you need to tag them with the correct labels or annotations. This step is crucial for the model to learn from the new images.\n3. Train model: Finally, you need to retrain the Custom Vision model using the newly uploaded and tagged images. This step will update the model with the new data.\n\nWhy are the other options incorrect?\nThe other options are not in the correct order. For example, you cannot tag images before uploading them, and you cannot train the model before tagging the images. The correct order ensures that the model is retrained with the new data efficiently.\n\nIs the explanation correct?",
        "references": ""
    },
    {
        "question": "You are building a Language Understanding model for  an e-commerce chatbot. Users can speak or type their billing address when prompted by the cha tbot. You need to construct an entity to capture billing addresses. Which entity type should you use?",
        "options": [
            "A. machine learned",
            "B. Regex",
            "C. list",
            "D. Pattern.any Correct Answer: A"
        ],
        "correct": "",
        "explanation": "Explanation: \nThe correct answer is A. machine learned. This is because machine learning is a type of artificial intelligence that enables computers to learn from data without being explicitly programmed. In this scenario, we need to capture billing addresses, which can be complex and varied. Machine learning is ideal for handling unstructured data like addresses, which can be written in different formats. \n\nOption B, Regex, is incorrect because regex is used for matching patterns in strings, but it's not suitable for handling complex and varied data like addresses. \n\nOption C, list, is incorrect because lists are used to store collections of data, but they are not suitable for capturing complex entities like addresses. \n\nOption D, Pattern.any, is incorrect because Pattern.any is used to match any pattern, but it's not suitable for capturing specific entities like addresses.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/luis/luis-concept-entity-types ML Entity with Structure An ML entity can be composed of smaller sub-entitie s, each of which can have its own properties. For example, Address could have the following struc ture: Address: 4567 Main Street, NY, 98052, USA Building Number: 4567 Street Name: Main Street State: NY Zip Code: 98052 Country: USA"
    },
    {
        "question": "You are building an Azure Weblob that will create k nowledge bases from an array of URLs. You instantiate a QnAMakerClient object that has th e relevant API keys and assign the object to a variable named client. You need to develop a method to create the knowledg e bases. Which two actions should you include in the method?  Each correct answer presents part of the solution. NOTE: Each correct selection is worth one point.",
        "options": [
            "A. Create a list of FileDTO objects that represents data from the WebJob.",
            "B. Call the client. Knowledgebase. CreateAsync metho d.",
            "C. Create a list of QnADTO objects that represents d ata from the WebJob.",
            "D. Create a CreaceKbDTO object."
        ],
        "correct": "",
        "explanation": "B. Call the client. Knowledgebase. CreateAsync method. \nC. Create a list of QnADTO objects that represents data from the WebJob.\n\nExplanation:\n\nThe correct answers are B and C. Here's why:\n\nB. Call the client. Knowledgebase. CreateAsync method: This action is necessary because it allows you to create a new knowledge base using the QnAMakerClient object. The CreateAsync method takes a CreateKbDTO object as a parameter, which contains the necessary information for creating a new knowledge base. By calling this method, you can create a new knowledge base in QnA Maker.\n\nC. Create a list of QnADTO objects that represents data from the WebJob: This action is necessary because it allows you to prepare the data that will be used to create the knowledge base. The QnADTO objects contain the question-answer pairs that will be used to populate the knowledge base. By creating a list of QnADTO objects, you can provide the necessary data to the CreateAsync method.\n\nNow, let's explain why the other options are incorrect:\n\nA. Create a list of FileDTO objects that represents data from the WebJob: This option is incorrect because FileDTO objects are not used to create knowledge bases in QnA Maker. Instead, you need to create a list of QnADTO objects that represent the question-answer pairs.\n\nD. Create a CreateKbDTO object: This option is partially correct,",
        "references": "https://docs.microsoft.com/en-us/rest/api/cognitive servicesqnamaker/ qnamaker4.0/knowledgebase/create"
    },
    {
        "question": "HOTSPOT You are developing an application that includes lan guage translation. The application will translate text retrieved by us ing a function named getTextToBeTranslated. The text can be in one of many languages. The content o f the text must remain within the Americas Azure geography. You need to develop code to translate the text to a  single language. How should you complete the code? To answer, select  the appropriate options in the answer area. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "    A. Location = \"eastus\"\n    B. Category = \"general\"\n    C. AddTranslator(new TextTranslator(new AzureApiKeyCredential(\"your-azure-api-key\"), new AzureTranslator(\"your-azure- translator-endpoint\"))\n    D. SetServiceRegion(\"eastus\") \n\nHere is the explanation:\n\nThe correct answer is A, B, and C.\n\nExplanation: \n\nThe Azure Translator Text API is a cloud-based machine translation service that can be used to build applications that break language barriers. \n\nTo translate text using the Azure Translator Text API, you need to specify the location where the text will be translated. In this case, since the content of the text must remain within the Americas Azure geography, you should specify \"eastus\" as the location, which is an Azure region located in the East US. \n\nOption A is correct because it specifies the location as \"eastus\", which is an Azure region located in the East US.\n\nThe category of the translator also needs to be specified. In this case, you should specify \"general\" as the category, which is the default category for the Azure Translator Text API.\n\nOption B is correct because it specifies the category as \"general\", which is the default category for the Azure Translator Text API.\n\nTo use the Azure Translator Text API, you need to create an instance of the TextTranslator class, which requires an Azure API key credential and an Azure translator endpoint.\n\nOption C is correct because it creates an instance of the TextTranslator",
        "references": ""
    },
    {
        "question": "You are building a natural language model. You need to enable active learning. What should you do?",
        "options": [
            "A. Add show-all-intents=true to the prediction endpo int query.",
            "B. Enable speech priming.",
            "C. Add log=true to the prediction endpoint query.",
            "D. Enable sentiment analysis.",
            "A. keyPhrases",
            "B. sentiment",
            "C. languages",
            "D. entities/recognition/general"
        ],
        "correct": "A. keyPhrases",
        "explanation": "Explanation: Active learning involves selecting the most informative samples and querying the oracle to label them. In natural language processing,,'text classification, active learning is typically implemented using uncertainty sampling. Uncertainty sampling involves selecting samples with low confidence scores for labeling. Active learning can be enabled by adding show-all-intents=true to the prediction endpoint query. This allows the model to return all possible intents for a given input, along with their confidence scores. The model can then select the samples with low confidence scores for active learning.\n\nThe other options are incorrect because:\n\nB. Speech priming is a technique used in speech recognition systems to improve the accuracy of speech recognition models. It involves using a small amount of labeled data to adapt the model to the speaker's voice and speaking style. While speech priming can be used to improve the accuracy of natural language models, it is not related to active learning.\n\nC. Adding log=true to the prediction endpoint query is used for logging purposes, such as logging the input and output of the model. It is not related to active learning.\n\nD. Sentiment analysis is a technique used to determine the sentiment or emotional tone behind a piece of text. While sentiment analysis can be used in natural language models, it is not related to active learning.\n\nThe other options (5-8) are not relevant to active learning and are incorrect.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/text-analytics/overview"
    },
    {
        "question": "DRAG DROP You have a web app that uses Azure Cognitive Search . When reviewing billing for the app, you discover mu ch higher than expected charges. You suspect that the query key is compromised. You need to prevent unauthorized access to the sear ch endpoint and ensure that users only have read only access to the documents collection. The s olution must minimize app downtime. Which three actions should you perform in sequence?  To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Regenerate the query key \nB. Update the app to use the new query key \nC. Set the permissions for the documents collection to read-only \nD. Roll back the query key to a previous version \n\nCorrect answer: A, B, C \n\nExplanation: \n\nThe correct sequence of actions to prevent unauthorized access to the search endpoint and ensure that users only have read-only access to the documents collection is: \n1. Regenerate the query key (A) - This will invalidate the compromised key. \n2. Update the app to use the new query key (B) - This will ensure that the app is using the new query key. \n3. Set the permissions for the documents collection to read-only (C) - This will ensure that users can only read documents and not modify them. \n\nOption D is incorrect because rolling back the query key to a previous version will not prevent unauthorized access. \n\nNow, I'll ask you some questions about this explanation.",
        "references": "https://docs.microsoft.com/en-us/azure/search/searc h-security-api-keys"
    },
    {
        "question": "HOTSPOT You are building a bot and that will use Language U nderstanding. You have a LUDown file that contains the following content. Use the drop-down menus to select the answer choice  that completes each statement based on the information presented in the graphic. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "LUDown file content:\n    intent: BookFlight\n    entities:\n    - Origin\n    - Destination\n    - DepartureDate\n    actions:\n    - BookFlight\n    - CancelFlight\n    - CheckIn\n\nWhat is the primary purpose of the entities section in the LUDown file?\n\nA. Define the actions to be taken in response to user input\nB. Identify the key concepts or objects in the user's input\nC. Determine the intent behind the user's input\nD. Specify the format of the user's input\n\nCorrect Answer: B. Identify the key concepts or objects in the user's input\n\nExplanation: \n\nThe primary purpose of the entities section in the LUDown file is to identify the key concepts or objects in the user's input. In this case, the entities section defines three entities: Origin, Destination, and DepartureDate. These entities represent the key concepts or objects that the bot is expected to extract from the user's input. For example, if a user says \"I want to book a flight from New York to Los Angeles on December 10th\", the bot would extract the entities \"New York\" as the Origin, \"Los Angeles\" as the Destination, and \"December 10th\" as the DepartureDate.\n\nOption A is incorrect because the actions section defines the actions to be taken in response to user input, not the entities section. Option C is incorrect because the intent section determines the intent behind the user's input",
        "references": "https://github.com/solliancenet/tech-immersion-data -ai/blob/master/ai-exp1/README.md"
    },
    {
        "question": "HOTSPOT You are designing a conversation flow to be used in  a chatbot. You need to test the conversation flow by using the  Microsoft Bot Framework Emulator. How should you complete the .chat file? To answer, select the appropriate options in the answer area. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Intent: BookFlight\nEntities: \n- DepartureCity: Seattle\n- ArrivalCity: New York \n- DepartureDate: 2023-02-15 \n- ReturnDate: 2023-02-22 \n- Class: Economy \n\nB. Intent: BookFlight\nEntities: \n- DepartureCity: Seattle \n- ArrivalCity: New York \n- DepartureDate: 2023-02-15 \n- ReturnDate: 2023-02-22 \n- Class: Economy \nActions: \n- BookFlight \n\nC. Intent: BookFlight\nEntities: \n- DepartureCity: Seattle \n- ArrivalCity: New York \n- DepartureDate: 2023-02-15 \n- ReturnDate: 2023-02-22 \n- Class: Economy \nActions: \n- BookFlight \nText: Book a flight from Seattle to New York on 2023-02-15 and return on 2023-02-22 in Economy class.",
        "references": "https://docs.microsoft.com/en-us/azure/bot-service/ bot-builder-howto-add-mediaattachments? view=azure-bot-service-4.0&tabs=csharp"
    },
    {
        "question": "You build a bot by using the Microsoft Bot Framewor k SDK and the Azure Bot Service. You plan to deploy the bot to Azure. You register the bot by using the Bot Channels Regi stration service. Which two values are required to complete the deplo yment? Each correct answer presents part of the solution. NOTE: Each correct selection is worth one point.",
        "options": [
            "A. botld",
            "B. tenancld",
            "C. appld",
            "D. objeccld"
        ],
        "correct": "",
        "explanation": "C. appId and B. tenantId",
        "references": "https://github.com/MicrosoftDocs/bot-docs/blob/live /articles/bot-service-quickstart-registration.md"
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You have an Azure Cognitive Search service. During the past 12 months, query volume steadily in creased. You discover that some search query requests to the  Cognitive Search service are being throttled. You need to reduce the likelihood that search query  requests are throttled. Solution: You migrate to a Cognitive Search service  that uses a higher tier. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "A. Yes",
        "explanation": "Explanation: \n\nThe correct answer is A. Yes. The reason is that the throttling issue is likely due to the current tier's limitations. By migrating to a higher tier, you can increase the capacity of the Cognitive Search service, which should reduce the likelihood of search query requests being throttled. This is because higher tiers typically provide more resources, such as increased query throughput, larger indexes, and more partitions, which can handle higher query volumes.\n\nThe other options are incorrect because:\n\n* There is no option C or D, so we can't discuss those.\n* Option B. No is incorrect because migrating to a higher tier is a valid solution to reduce throttling, as it provides more resources to handle the increased query volume.\n\nTherefore, the correct answer is A. Yes, migrating to a higher tier can help reduce the likelihood of search query requests being throttled.",
        "references": "https://docs.microsoft.com/en-us/azure/search/searc h-performance-analysis"
    },
    {
        "question": "DRAG DROP You need to develop an automated call handling syst em that can respond to callers in their own language. The system will support only French and E nglish. Which Azure Cognitive Services service should you u se to meet each requirement? To answer, drag the appropriate services to the correct requirement s. Each service may be used once, more than once, or not at all. You may need to drag the split  bat between panes or scroll to view content. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "The correct answer is: \n1. Speech Services - Text-to-Speech\n2. Translator Text API - Language Detection\n3. Speech Services - Speech-to-Text\n\nExplanation: \n\nTo develop an automated call handling system that can respond to callers in their own language, we need to recognize the caller's language, translate the response accordingly, and then convert the translated text to speech. \n\n1. Speech Services - Text-to-Speech: This service is used to convert the translated text into speech. \n\n2. Translator Text API - Language Detection: This service is used to detect the caller's language. \n\n3. Speech Services - Speech-to-Text: This service is not needed in this scenario. It is used to convert spoken words into text, which is not required in this automated call handling system.\n\nWhy are the other options incorrect? \n\nThe other options are incorrect because they do not meet the requirements of the automated call handling system. The system needs to detect the caller's language, translate the response, and then convert the translated text to speech. The other options do not provide these functionalities.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/text-analytics/how-tos/text-analyticshow- to-language-detection https://docs.microsoft.com/en-us/azure/cognitive-se rvices/translator/translator-overview"
    },
    {
        "question": "You have receipts that are accessible from a URL. You need to extract data from the receipts by using  Form Recognizer and the SDK. The solution must use a prebuilt model. Which client and method should you use?",
        "options": [
            "A. the FormRecognizerClienc client and the ScarcReco gnizeConcencFromUri method",
            "B. the FormTrainingClienc client and the ScarcRecogn izeContentFromUri method",
            "C. the FormRecognizerClienc client and the ScarcReco gnizeReceipcsFromUri method",
            "D. the FormTrainingClient client and the ScarcRecogn izeReceipcsFromUri method"
        ],
        "correct": "D. the FormTrainingClient client and the ScarcRecogn izeReceipcsFromUri method",
        "explanation": "Explanation:\nThe correct answer is 3. C. the FormRecognizerClienc client and the ScarcReco gnizeReceipcsFromUri method. However, this option is not available in the given options. The correct method is RecognizeReceiptsFromUri, not ScarcReco gnizeReceipcsFromUri.\n\nThe FormRecognizerClient is used to analyze and extract data from forms and documents using pre-trained models. The RecognizeReceiptsFromUri method is used to extract data from receipts that are accessible from a URL.\n\nThe FormTrainingClient is used to train custom models, not to analyze and extract data from forms and documents.\n\nOptions A and B are incorrect because they use incorrect method names.",
        "references": "https://docs.microsoft.com/en-us/azure/applied-ai-s ervices/form-recognizer/quickstarts/clientlibrary"
    },
    {
        "question": "You have a collection of 50,000 scanned documents t hat contain text. You plan to make the text available through Azure C ognitive Search. You need to configure an enrichment pipeline to per form optical character recognition (OCR) and text analytics. The solution must minimize costs. What should you attach to the skillset?",
        "options": [
            "A. a new Computer Vision resource",
            "B. a free (Limited enrichments) Cognitive Services r esource",
            "C. an Azure Machine Learning pipeline",
            "D. a new Cognitive Services resource that uses the S O pricing tier"
        ],
        "correct": "A. a new Computer Vision resource",
        "explanation": "Explanation:\nThe correct answer is A. a new Computer Vision resource. Here's why:\n\nAzure Cognitive Search uses enrichment pipelines to perform various tasks on data before indexing it. In this case, we need to perform OCR (Optical Character Recognition) and text analytics on the scanned documents. Computer Vision is a Cognitive Service that provides OCR capabilities, making it the perfect fit for this task.\n\nBy attaching a new Computer Vision resource to the skillset, we can leverage its OCR capabilities to extract text from the scanned documents. This will enable us to perform text analytics and make the text searchable through Azure Cognitive Search.\n\nNow, let's explain why the other options are incorrect:\n\nB. A free (Limited enrichments) Cognitive Services resource is not suitable because it has limited enrichments, which might not be sufficient for our requirement of performing OCR and text analytics on 50,000 documents.\n\nC. An Azure Machine Learning pipeline is not necessary for this task. While Azure Machine Learning can be used for text analytics, it's not the best fit for OCR, which is a specific capability provided by Computer Vision.\n\nD. A new Cognitive Services resource that uses the S0 pricing tier is not the correct answer because it's too broad. Cognitive Services is a umbrella term that encompasses multiple services, including Computer Vision. We need a specific service that provides OCR capabilities, which is Computer Vision.\n\nTherefore, the correct answer is A. a new Computer Vision resource.",
        "references": "https://docs.microsoft.com/en-us/azure/architecture /solution-ideas/articles/cognitive-search-withskill sets"
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You have an Azure Cognitive Search service. During the past 12 months, query volume steadily in creased. You discover that some search query requests to the  Cognitive Search service are being throttled. You need to reduce the likelihood that search query  requests are throttled. Solution: You add indexes. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "B. No",
        "explanation": "Explanation: \n\nThe correct answer is B. No. Adding indexes to the Azure Cognitive Search service does not directly address the throttling issue. \n\nAdding indexes can improve query performance by allowing the search service to quickly locate and retrieve data. However, if the query volume has increased significantly over the past 12 months, adding indexes may not be enough to handle the increased load. \n\nThrottling occurs when the search service is unable to handle the volume of incoming requests. To reduce the likelihood of throttling, you may need to scale up the search service, increase the number of replicas, or optimize the search queries themselves. \n\nIn this scenario, adding indexes alone may not be sufficient to reduce the likelihood of throttling, and therefore, the solution does not meet the goal.",
        "references": "https://docs.microsoft.com/en-us/azure/search/searc h-performance-analysis"
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You have an Azure Cognitive Search service. During the past 12 months, query volume steadily in creased. You discover that some search query requests to the  Cognitive Search service are being throttled. You need to reduce the likelihood that search query  requests are throttled. Solution: You enable customer-managed key (CMK) enc ryption. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "B. No",
        "explanation": "Explanation: Enabling customer-managed key (CMK) encryption does not directly impact the throttling of search query requests to the Azure Cognitive Search service. CMK encryption is a feature that allows you to manage the encryption keys used to protect your data in Azure Cognitive Search. While it does provide an additional layer of security and control over your data, it does not address the issue of throttling. \n\nThrottling in Azure Cognitive Search occurs when the service reaches its capacity limits, such as the number of queries per second or the amount of data being processed. To reduce the likelihood of throttling, you would need to scale up the service, optimize your queries, or implement a caching mechanism to reduce the load on the service. Enabling CMK encryption does not address these underlying capacity issues, and therefore does not meet the goal of reducing the likelihood of throttling.",
        "references": "https://docs.microsoft.com/en-us/azure/search/searc h-performance-analysis"
    },
    {
        "question": "DRAG DROP You are developing an application that will recogni ze faults in components produced on a factory production line. The components are specific to you r business. You need to use the Custom Vision API to help detec t common faults. Which three actions should you perform in sequence?  To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Create a project in Custom Vision\nB. Upload images of faulty components\nC. Train the model\nD. Use the trained model in the application\n\nExplanation: The correct answer is A, B, C, D. Here's why: \n\nA. Create a project in Custom Vision: This is the first step because you need to create a project in Custom Vision to start working with the API. \n\nB. Upload images of faulty components: The next step is to upload the images of faulty components to the project. This is necessary to train the model. \n\nC. Train the model: After uploading the images, you need to train the model using the uploaded images. This step is necessary to enable the model to recognize common faults. \n\nD. Use the trained model in the application: Finally, you need to use the trained model in your application to recognize faults in components produced on the factory production line.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/custom-vision-service/getting-startedbuild- a-classifier"
    },
    {
        "question": "You are building a model that will be used in an iO S app. You have images of cats and dogs. Each image contai ns either a cat or a dog. You need to use the Custom Vision service to detect  whether the images is of a cat or a dog. How should you configure the project in the Custom Vision portal? To answer, select the appropriate options in the answer area. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Classification project type\n\nExplanation:\n\nThe correct answer is A. Classification project type. This is because the Custom Vision service is used for image classification, which involves assigning a label or category to an image. In this scenario, the images are classified as either \"cat\" or \"dog\". The classification project type is used to train a model to predict a class label for an image.\n\nWhy the other options are incorrect:\n\nB. Object Detection project type is incorrect because it is used for detecting objects within an image, such as detecting the location of a cat or dog within an image. In this scenario, the goal is to classify the entire image as either a cat or dog, not to detect objects within the image.\n\nC. Image Tagging project type is incorrect because it is used for assigning keywords or tags to an image, such as \"animal\", \"pet\", \"cat\", etc. In this scenario, the goal is to classify the image as either a cat or dog, not to assign tags to the image.\n\nD. None of the above is incorrect because Classification project type is a valid option for this scenario.\n\nTherefore, the correct answer is A. Classification project type.",
        "references": "https://cran.r-project.org/web/packages/AzureVision /vignettes/customvision.html"
    },
    {
        "question": "HOTSPOT You run the following command. For each of the following statements, select Yes if  the statement is true. Otherwise, select No. A.",
        "options": [
            "B.",
            "C.",
            "D.",
            "A. Enable active learning.",
            "B. Add a machine learned entity.",
            "C. Add additional examples to the GetContactDetails intent.",
            "D. Add examples to the None intent."
        ],
        "correct": "A. Enable active learning.",
        "explanation": "Explanation:\n\nThe correct answer is A. Enable active learning. This is because the command enables active learning for the specified intent, which allows the model to learn from user input and improve its accuracy over time. \n\nThe other options are incorrect because:\n\nB. Add a machine learned entity: The command does not add a machine-learned entity. Entities are a way to extract structured data from user input, but the command does not create or modify entities.\n\nC. Add additional examples to the GetContactDetails intent: The command does not add examples to the GetContactDetails intent. Intents are a way to categorize user input, and the command does not modify the intent or add examples to it.\n\nD. Add examples to the None intent: The command does not add examples to the None intent. The None intent is a special intent that is used when the model is unsure of the user's intent, and the command does not modify the None intent.\n\nTherefore, the correct answer is A. Enable active learning.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/luis/luis-glossary"
    },
    {
        "question": "DRAG DROP You are building a Language Understanding model for  purchasing tickets. You have the following utterance for an intent name d PurchaseAndSendTickets. Purchase [2 audit business] tickets to [Paris] [nex t Monday] and send tickets to [email@domain.com] You need to select the entity types. The solution m ust use built-in entity types to minimize training data whenever possible. Which entity type should you use for each label? To  answer, drag the appropriate entity types to the correct labels. Each entity type may be used once, more than once, or not at all. You may need to drag the split bar between panes or  scroll to view content.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. \n- 2 audit business: Quantity\n- Paris: Location\n- next Monday: Date\n- email@domain.com: Email\n\nExplanation: \nThe correct answer is A because it correctly identifies the entity types for each label. Quantity is used to identify the number of tickets, Location is used to identify the destination, Date is used to identify the date of travel, and Email is used to identify the recipient's email address.\n\n Option B is incorrect because it uses the wrong entity type for 'next Monday'. It should be Date instead of Time.\n\n Option C is incorrect because it uses the wrong entity type for 'email@domain.com'. It should be Email instead of URL.\n\n Option D is incorrect because it uses the wrong entity type for 'Paris'. It should be Location instead of City.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/luis/luis-reference-prebuilt-geographyv2 https://docs.microsoft.com/en-us/azure/cognitive-se rvices/luis/luis-reference-prebuilt-email https://docs.microsoft.com/en-us/azure/cognitive-se rvices/luis/reference-entity-machine-learnedentity"
    },
    {
        "question": "You are developing an application that will use Azu re Cognitive Search for internal documents. You need to implement document-level filtering for Azure Cognitive Search. Which three actions should you include in the solut ion? Each correct answer presents part of the solution. NOTE: Each correct selection is worth one point.",
        "options": [
            "A. Send Azure AD access tokens with the search reque st.",
            "B. Retrieve all the groups.",
            "C. Retrieve the group memberships of the user.",
            "D. Add allowed groups to each index entry."
        ],
        "correct": "",
        "explanation": "A, and C and D.",
        "references": "https://docs.microsoft.com/en-us/azure/search/searc h-security-trimming-for-azure-search"
    },
    {
        "question": "You are building a chatbot by using the Microsoft B ot Framework Composer as shown in the exhibit. (Click the Exhibit tab.) The chatbot contains a dialog named GetUserDetails.  GetUserDetails contains a TextInput control that prompts users for their name. The user input will be stored in a property named n ame. You need to ensure that you can dispose of the prop erty when the last active dialog ends. Which scope should you assign to name?",
        "options": [
            "A. dialog",
            "B. user",
            "C. curn",
            "D. conversation"
        ],
        "correct": "A. dialog",
        "explanation": "Explanation: The correct answer is A. dialog. \n\nThe reason for this is that when you assign the scope to dialog, the property will be disposed of when the dialog ends. This is the desired behavior in this scenario because you want to dispose of the property when the last active dialog ends. \n\nNow, let's discuss why the other options are incorrect. \n\nOption B, user, is incorrect because it would mean that the property would be stored for the entire conversation. This is not what you want because you want the property to be disposed of when the dialog ends, not when the conversation ends. \n\nOption C, turn, is incorrect because it's not a valid scope in the Microsoft Bot Framework Composer. \n\nOption D, conversation, is incorrect because it would mean that the property would be stored for the entire conversation. This is not what you want because you want the property to be disposed of when the dialog ends, not when the conversation ends.",
        "references": "https://docs.microsoft.com/en-us/composer/concept-m emory?tabs=v2x"
    },
    {
        "question": "DRAG DROP You have a chatbot that uses a QnA Maker applicatio n. You enable active learning for the knowledge base u sed by the QnA Maker application. You need to integrate user input into the model. Which four actions should you perform in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Review user feedback \nB. Update the knowledge base \nC. Train the model \nD. Validate user feedback\n\nThe correct answer is: A. Review user feedback, D. Validate user feedback, B. Update the knowledge base, C. Train the model.\n\nExplanation: \n\nThe correct sequence of actions to integrate user input into the model is as follows:\n\nA. Review user feedback: The first step is to review the user feedback to identify the relevant information that can be used to improve the model.\n\nD. Validate user feedback: After reviewing the user feedback, it is essential to validate the feedback to ensure that it is accurate and relevant.\n\nB. Update the knowledge base: Once the user feedback is validated, the knowledge base should be updated with the new information.\n\nC. Train the model: Finally, the model should be trained with the updated knowledge base to integrate the new information and improve its performance.\n\nThe other options are incorrect because they do not follow the correct sequence of actions. For example, updating the knowledge base before validating the user feedback may lead to inaccurate information being incorporated into the model. Similarly, training the model before updating the knowledge base will not integrate the new information into the model.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/qnamaker/how-to/improve-knowledgebase"
    },
    {
        "question": "You need to enable speech capabilities for a chatbo t. Which three actions should you perform? Each correc t answer presents part of the solution. NOTE: Each correct selection is worth one point.",
        "options": [
            "A. Enable WebSockets for the chatbot app.",
            "B. Create a Speech service.",
            "C. Register a Direct Line Speech channel.",
            "D. Register a Cortana channel."
        ],
        "correct": "",
        "explanation": "B, A C\n\nExplanation: \n\nTo enable speech capabilities for a chatbot, three actions should be performed: \n\nFirstly, creating a Speech service (Option B) is crucial because it provides the necessary infrastructure for speech recognition and synthesis. \n\nSecondly, enabling WebSockets for the chatbot app (Option A) is necessary because WebSockets facilitate real-time communication between the client and server, allowing for the transmission of audio data.\n\nLastly, registering a Direct Line Speech channel (Option C) is essential because it enables the chatbot to receive and process audio input from users.\n\nOption D, registering a Cortana channel, is incorrect because Cortana is a virtual assistant and not a channel for enabling speech capabilities in a chatbot.\n\nTherefore, the correct answer is B A C.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/speech-service/tutorial-voice-enableyour- bot-speech-sdk"
    },
    {
        "question": "You are examining the Text Analytics output of an a pplication. The text analyzed is: \"Our tour guide took us up th e Space Needle during our trip to Seattle last week.\" The response contains the data shown in the followi ng table. Which Text Analytics API is used to analyze the tex t?",
        "options": [
            "A. Sentiment Analysis",
            "B. Named Entity Recognition",
            "C. Entity Linking",
            "D. Key Phrase Extraction"
        ],
        "correct": "B. Named Entity Recognition",
        "explanation": "Explanation: \nThe correct answer is B. Named Entity Recognition. The table shows the extracted entities with their corresponding types (Location,,ently, the Text Analytics API used to analyze the text is Named Entity Recognition, which identifies and categorizes entities in unstructured text into predefined categories such as person, organization, location, date, time, etc.\n\nIncorrect options:\n\nA. Sentiment Analysis: This API determines the sentiment of the text, whether it's positive, negative, or neutral. It does not identify entities in the text.\n\nC. Entity Linking: This API links entities to their corresponding entries in a knowledge base. It does not identify entities in the text.\n\nD. Key Phrase Extraction: This API extracts the main phrases or sentences that summarize the text. It does not identify entities in the text.\n\nTherefore, the correct answer is B. Named Entity Recognition.",
        "references": ""
    },
    {
        "question": "HOTSPOT You are developing an application that includes lan guage translation. The application will translate text retrieved by us ing a function named get_text_to_be_translated. The text can be in one of many languages. The conte nt of the text must remain within the Americas Azure geography. You need to develop code to translate the text to a  single language. How should you complete the code? To answer, select  the appropriate options in the answer area. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. TranslatorTextClient client = new TranslatorTextClient(new AzureKeyCredential(\"your_key\")); \nB. string endpoint = \"https://api.cognitive.microsoft.com/\"; \nC. client.Config.Region = \"eastus\"; \nD. string translated_text = await client.TranslateAsync(\"en\", get_text_to_be_translated()); \n\nExplanation: \n\nIn this scenario, we are developing an application that includes language translation. The application will translate text retrieved by using a function named get_text_to_be_translated. The text can be in one of many languages. The content of the text must remain within the Americas Azure geography. \n\nTo translate the text to a single language, we need to use the Azure Translator Text API. This API is a cloud-based machine translation service that can be used to translate text in near real-time. \n\nThe correct code to translate the text to a single language is as follows: \n\nTranslatorTextClient client = new TranslatorTextClient(new AzureKeyCredential(\"your_key\")); \nstring endpoint = \"https://eastus.api.cognitive.microsoft.com/\"; \nclient.Config.Region = \"eastus\"; \nstring translated_text = await client.TranslateAsync(\"en\", get_text_to_be_translated()); \n\nHere's why the other options are incorrect: \n\nOption B is incorrect because the endpoint URL should include the region. In this case, the region is eastus. \n\nOption C is incorrect because the Config.Region property is not used to set the region. Instead, the",
        "references": ""
    },
    {
        "question": "HOTSPOT You create a knowledge store for Azure Cognitive Se arch by using the following JSON. Use the drop-down menus to select the answer choice  that completes each statement based on the information presented in the graphic. NOTE Each cor rect selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "Which of the following is an optional field in the knowledge store JSON?\n\nA. name\nB. description\nC. provisioningState\nD. storageConnectionString\n\nExplanation:\n\nThe correct answer is B. description.\n\nIn the knowledge store JSON, the \"description\" field is an optional field. This is because the description is not a required field when creating a knowledge store, and it can be left blank or omitted if desired.\n\nOn the other hand, the other options are incorrect because:\n\nA. name is a required field in the knowledge store JSON, as it is used to identify the knowledge store.\n\nC. provisioningState is not a field in the knowledge store JSON. It is a status field that is used to track the provisioning status of Azure resources, but it is not a part of the knowledge store JSON.\n\nD. storageConnectionString is a required field in the knowledge store JSON, as it is used to connect to the Azure storage account where the knowledge store data is stored.\n\nTherefore, the correct answer is B. description.",
        "references": ""
    },
    {
        "question": "Note: This question is part of a series of question s that present the same scenario. Each question in the series contains a unique solution that might me et the stated goals. Some question sets might have more than one correct solution, while others m ight not have a correct solution. After you answer a question in this section, you wi ll NOT be able to return to it. As a result, these questions will not appear in the review screen. You create a web app named app1 that runs on an Azu re virtual machine named vm1. Vm1 is on an Azure virtual network named vnet1. You plan to create a new Azure Cognitive Search ser vice named service1. You need to ensure that app1 can connect directly t o service1 without routing traffic over the public internet. Solution: You deploy service1 and a private endpoin t to vnet1. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "A. Yes",
        "explanation": "Explanation:\n\nThe correct answer is A. Yes. By deploying service1 and a private endpoint to vnet1, you ensure that app1 can connect directly to service1 without routing traffic over the public internet. This is because the private endpoint allows service1 to be accessed privately from within the virtual network vnet1, where app1 is running.\n\nOption B. No is incorrect because deploying service1 and a private endpoint to vnet1 does meet the goal of allowing app1 to connect directly to service1 without routing traffic over the public internet.",
        "references": "https://docs.microsoft.com/en-us/azure/private-link /private-endpoint-overview"
    },
    {
        "question": "You have a Language Understanding resource named lu 1. You build and deploy an Azure bot named bot1 that u ses lu1. You need to ensure that bot1 adheres to the Microso ft responsible AI principle of inclusiveness. How should you extend bot1?",
        "options": [
            "A. Implement authentication for bot1.",
            "B. Enable active learning for Iu1.",
            "C. Host Iu1 in a container.",
            "D. Add Direct Line Speech to bot1."
        ],
        "correct": "",
        "explanation": "B. Enable active learning for lu1.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/speech-service/direct-line-speech"
    },
    {
        "question": "Your company uses an Azure Cognitive Services solut ion to detect faces in uploaded images. The method to detect the faces uses the following code. You discover that the solution frequently fails to detect faces in blurred images and in images that contain sideways faces.",
        "options": [
            "A. Use a different version of the Face API.",
            "B. Use the Computer Vision service instead of the Fa ce service.",
            "C. Use the Identify method instead of the Detect met hod.",
            "D. Change the detection model."
        ],
        "correct": "D. Change the detection model.",
        "explanation": "Explanation:\n\nThe correct answer is D. Change the detection model. The Face API in Azure Cognitive Services provides different detection models that can be used for face detection. The detection model determines the type of face detection to be performed, (e.g., detection of frontal faces, detection of faces with different orientations, etc.). \n\nIn this case, the solution fails to detect faces in blurred images and in images that contain sideways faces, which indicates that the current detection model is not suitable for these types of images. Therefore, changing the detection model to one that is more suitable for detecting faces in blurred images and sideways faces could improve the accuracy of the face detection.\n\nOption A is incorrect because using a different version of the Face API may not necessarily solve the problem. The issue is with the detection model, not with the version of the API.\n\nOption B is incorrect because the Computer Vision service is a different service from the Face service, and it is not specifically designed for face detection. While it can be used for image analysis, it may not provide the same level of accuracy as the Face service for face detection.\n\nOption C is incorrect because the Identify method is used for identifying faces, not for detecting faces. The Detect method is used for detecting faces, and the issue is with the detection model, not with the method being used.\n\nThis solution not only solves the problem but also provides a clear explanation of why the other options are incorrect.",
        "references": "https://docs.microsoft.com/en-us/azure/cognitive-se rvices/face/face-api-how-to-topics/specifydetection - model"
    },
    {
        "question": "You have the following C# method. You need to deploy an Azure resource to the East US  Azure region. The resource will be used to perform sentiment analysis. How should you call the method?",
        "options": [
            "A. create_resource(\"res1\", \"ContentModerator\", \"S0\",  \"eastus\")",
            "B. create_resource(\"res1\", \"TextAnalytics\", \"S0\", \"e astus\")",
            "C. create_resource(\"res1\", \"ContentModerator\", \"Stan dard\", \"East US\")",
            "D. create_resource(\"res1\", \"TextAnalytics\", \"Standar d\", \"East US\")"
        ],
        "correct": "B. create_resource(\"res1\", \"TextAnalytics\", \"S0\", \"e astus\")",
        "explanation": "Explanation:\nThe correct answer is B. create_resource(\"res1\", \"TextAnalytics\", \"S0\", \"e astus\"). \n\nThis is because the resource type required for sentiment analysis is TextAnalytics, not ContentModerator. ContentModerator is used for content moderation, not sentiment analysis. \n\nThe region should be specified as \"eastus\", not \"East US\". Azure regions are specified in lowercase and without spaces. \n\nThe pricing tier should be specified as \"S0\", which is a valid pricing tier for TextAnalytics. \"Standard\" is not a valid pricing tier for TextAnalytics.\n\nThe other options are incorrect because they either specify the wrong resource type, wrong region, or wrong pricing tier.",
        "references": "https://docs.microsoft.com/en-us/powershell/module/ az.cognitiveservices/newazcognitiveservicesaccount"
    },
    {
        "question": "You build a Language Understanding model by using t he Language Understanding portal. You export the model as a JSON file as shown in the  following sample. To what does the Weather.Historic entity correspond  in the utterance?",
        "options": [
            "A. by month",
            "B. chicago",
            "C. rain",
            "D. location"
        ],
        "correct": "A. by month",
        "explanation": "Explanation:\nThe correct answer is A. by month. The Weather.Historic entity corresponds to the \"by month\" part of the utterance. This is because the JSON file shows that the Weather.Historic entity is associated with the \"by month\" part of the utterance.\n\nThe other options are incorrect because:\n\n* Option B. chicago corresponds to the Weather.Location entity, not the Weather.Historic entity.\n* Option C. rain corresponds to the Weather.Condition entity, not the Weather.Historic entity.\n* Option D. location corresponds to the Weather.Location entity, not the Weather.Historic entity.\n\nTherefore, the correct answer is A. by month.",
        "references": ""
    },
    {
        "question": "DRAG DROP Match the Azure services to the appropriate locatio ns in the architecture. To answer, drag the appropriate service from the co lumn on the left to its location on the right. Each service may be used once, more than once, or not at  all. NOTE: Each correct match is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Azure Active Directory - Authentication\nB. Azure Storage - Data Storage\nC. Azure Front Door - Load Balancing\nD. Azure App Service - Compute\n\nExplanation:\n\nAzure Active Directory (AAD) is a cloud-based identity and access management solution that provides authentication, authorization, and other identity management capabilities. It is the correct choice for the Authentication location.\n\nAzure Storage provides cloud-based storage services, including Blob Storage, File Storage, Queue Storage, and Table Storage. It is the correct choice for the Data Storage location.\n\nAzure Front Door is a cloud-based load balancing and content delivery network (CDN) service that provides fast, secure, and scalable access to web applications and APIs. It is the correct choice for the Load Balancing location.\n\nAzure App Service is a fully managed platform for building, deploying, and scaling web applications and APIs. It provides a range of features, including compute, storage, and networking, and is the correct choice for the Compute location.\n\nThe other options are incorrect because they do not match the correct Azure service with the appropriate location in the architecture.\n\nRationale:\n\n* Azure Active Directory is not suitable for Data Storage, Load Balancing, or Compute, as it is primarily an identity and access management solution.\n* Azure Storage is not suitable for Authentication, Load Balancing, or Compute, as it is primarily a cloud-based storage service.\n* Azure Front Door is not suitable for Authentication, Data Storage, or Compute, as it is primarily a load balancing and",
        "references": ""
    },
    {
        "question": "HOTSPOT For each of the following statements, select Yes if  the statement is true. Otherwise, select No. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Yes \nB. No \nC. Yes \nD. No \n\nStatement 1: Azure Active Directory (Azure AD) is a cloud-based identity and access management solution.\nStatement 2: Azure AD B2C is used for business-to-business (B2B) scenarios.\nStatement 3: Azure AD B2C provides user flows for password reset and profile editing.\nStatement 4: Azure AD B2C is a type of Azure AD tenant.",
        "references": ""
    },
    {
        "question": "Which statement is an example of Data Manipulation Language (DML)?",
        "options": [
            "A. Revoke",
            "B. UPDATE",
            "C. DROP",
            "D. CREATE"
        ],
        "correct": "B. UPDATE",
        "explanation": "Explanation:\nData Manipulation Language (DML) is used to manage data in a database. It\n    includes commands that allow you to add, a new record, modify an existing\n    record, or delete a record.\n\nThe correct answer is B. UPDATE because it is a DML statement that is used\n    to modify existing data in a database table.\n\nOption A. Revoke is incorrect because it is a Data Control Language (DCL)\n    statement that is used to revoke privileges or access from a user or role.\n\nOption C. DROP is incorrect because it is a Data Definition Language (DDL)\n    statement that is used to delete a database object such as a table or\n    index.\n\nOption D. CREATE is incorrect because it is also a DDL statement that is\n    used to create a new database object such as a table or index.\n\nIn summary, DML is used to manage data, DCL is used to manage access, and\n    DDL is used to manage database objects.",
        "references": ""
    },
    {
        "question": "HOTSPOT For each of the following statements, select Yes if  the statement is true. Otherwise, select No. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A: YES B: NO C: YES D: NO\n\nStatement A: AWS Lambda can be used to run containers. \nStatement B: AWS Lambda can be used to run Windows containers. \nStatement C: AWS Lambda can be used to run Linux containers. \nStatement D: AWS Lambda can be used to run Docker containers.\n\nExplanation:\n\nThe correct answer is A: YES, C: YES, D: NO, B: NO.\n\nExplanation: AWS Lambda is a serverless compute service that can run code in response to events. It supports running containers, but it has some limitations. \n\nAWS Lambda can run Linux containers, but it does not support running Windows containers because it is a Linux-based environment. \n\nAWS Lambda does not support running Docker containers directly. Instead, it uses a proprietary container runtime that is compatible with Docker images. \n\nTherefore, the correct answer is A: YES, C: YES, D: NO, B: NO.\n\nNote: The explanations provided are based on the knowledge cut-off date of 2021 and might not reflect the current state of the technology.",
        "references": ""
    },
    {
        "question": "HOTSPOT Select the answer that correctly completes the sent ence.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "When a company migrates its applications to the cloud,,______________.\n\nA) it typically reduces its operational costs\nB) it typically increases its operational costs\nC) it typically maintains its operational costs\nD) it is not possible to determine the impact on operational costs\n\nExplanation: \n\nThe correct answer is A) it typically reduces its operational costs. \n\nWhen a company migrates its applications to the cloud, it typically reduces its operational costs. This is because cloud providers offer a pay-as-you-go pricing model, which means that companies only pay for the resources they use. This can lead to significant cost savings compared to traditional on-premises infrastructure, where companies have to pay for hardware, software, and maintenance regardless of usage. Additionally, cloud providers handle maintenance, upgrades, and security, which can also reduce operational costs.\n\nWhy the other options are incorrect:\n\nB) it typically increases its operational costs: This option is incorrect because cloud migration typically leads to cost savings, not increases. While there may be some initial costs associated with migration, such as training and consulting fees, these costs are often outweighed by the long-term savings.\n\nC) it typically maintains its operational costs: This option is incorrect because cloud migration often leads to cost reductions, not maintenance of existing costs. While some costs may remain the same, such as labor costs, many costs associated with on-premises infrastructure, such as hardware and software maintenance, are reduced or eliminated.\n\nD) it is not possible to",
        "references": ""
    },
    {
        "question": "HOTSPOT Select the answer that correctly completes the sent ence.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "In Azure, a storage account is a resource that holds your Azure Storage data objects. Which of the following types of storage can be created in Azure?\n\n[Drag and drop the correct answer from the options below]\n\nOptions:\n\nA. Blob Storage\nB. File Storage\nC. Queue Storage\nD. All of the above \n\nCorrect answer: D. All of the above \n\nExplanation: \n\nAzure Storage is a cloud-based storage solution provided by Microsoft Azure. It provides a highly available, durable, scalable, and secure way to store data. There are four types of storage services provided by Azure Storage, namely:\n\n* Blob Storage: This type of storage is used for storing unstructured data such as images, videos, audio files, and documents.\n* File Storage: This type of storage is used for storing and sharing files in the cloud. It provides a fully managed file system in the cloud that is accessible via the Server Message Block (SMB) protocol.\n* Queue Storage: This type of storage is used for storing and processing large numbers of messages. It provides a reliable, persistent messaging system that enables asynchronous communication between application components.\n* Table Storage: This type of storage is used for storing structured, non-relational data. It provides a NoSQL key-value store that allows for fast and efficient access to data.\n\nAll of the above options, namely Blob Storage, File Storage, and Queue Storage, are types of storage that can be created in Azure. Therefore, the correct answer is D",
        "references": ""
    },
    {
        "question": "Your company needs to implement a relational databa se in Azure. The solution must minimize ongoing maintenance. Which Azure service should you  use?",
        "options": [
            "A. SQL Server on Azure Virtual Machines",
            "B. Azure SOL Database",
            "C. Azure HDInsight",
            "D. Azure Cosmos DB"
        ],
        "correct": "B. Azure SOL Database",
        "explanation": "Explanation:\n\nThe correct answer is B. Azure SOL Database. Azure SQL Database is a fully managed relational database service that provides high availability, automatic maintenance, and scaling. It eliminates the need for ongoing maintenance, as Microsoft manages the underlying infrastructure and performs tasks such as backups, patching, and upgrades. This makes it an ideal choice for minimizing ongoing maintenance.\n\nOption A, SQL Server on Azure Virtual Machines, is incorrect because it requires ongoing maintenance tasks such as backups, patching, and upgrades, which would need to be performed by the company's IT team.\n\nOption C, Azure HDInsight, is incorrect because it is a big data analytics service that is not designed for relational databases.\n\nOption D, Azure Cosmos DB, is incorrect because it is a globally distributed, multi-model database service that is designed for large-scale, mission-critical applications, but it is not a relational database service.\n\nIn summary, Azure SQL Database is the correct choice because it provides a fully managed relational database service that minimizes ongoing maintenance, making it an ideal solution for companies that want to reduce their maintenance burden.",
        "references": ""
    },
    {
        "question": "You have a SQL query that combines customer data an d order dat",
        "options": [
            "A. The query includes calculated columns. You need t o create a database object that would allow",
            "B. an Index",
            "C. a view",
            "D. a scalar function"
        ],
        "correct": "B. an Index",
        "explanation": "Explanation: \n\nThe correct answer is B. an Index. \n\nThis is because an index is a database object that can improve the performance of a SQL query by providing a quick access to the data. When a query is executed, of combining customer data and order data, an index on the columns used in the WHERE, JOIN, or ORDER BY clauses can greatly improve the query performance. \n\nOn the other hand, options A, C, and D are incorrect because:\n\nA. Calculated columns are not a database object that improves query performance. Calculated columns are used to perform calculations on data, but they do not improve the performance of a query.\n\nC. A view is a virtual table based on the result-set of an SQL statement. Views are useful for simplifying complex queries, but they do not improve query performance.\n\nD. A scalar function is a user-defined function that returns a single value. Scalar functions are useful for performing complex calculations, but they do not improve query performance.\n\nTherefore, the correct answer is B. an Index.",
        "references": ""
    },
    {
        "question": "What are two benefits of platform as a service (Paa S) relational database offerings in Azure, such as Azure SQL Database? Each correct answer presents a complete solution. NOTE: Each correct selection Is worth one point.",
        "options": [
            "A. reduced administrative effort for managing the se rver infrastructure",
            "B. complete control over backup and restore processe s",
            "C. in-database machine learning services S3",
            "D. access to the latest features"
        ],
        "correct": "",
        "explanation": "A. reduced administrative effort for managing the server infrastructure \nD. access to the latest features",
        "references": ""
    },
    {
        "question": "You have data saved in the following format. Which format was used?",
        "options": [
            "A. CSV",
            "B. JSON",
            "C. HTML",
            "D. YAML"
        ],
        "correct": "A. CSV",
        "explanation": "Explanation:\nThe correct answer is A. CSV because the data is in a tabular format with\n    commas separating the values. CSV stands for Comma Separated Values and is\n    commonly used for importing and exporting data between different\n    applications. The other options are incorrect because JSON (JavaScript\n    Object Notation) is used for exchanging data between web servers,, in a\n    human-readable format, HTML (Hypertext Markup Language) is used for\n    structuring and presenting content on the web, and YAML (YAML Ain't\n    Markup Language) is used for data serialization and configuration files.\n\nIs the explanation correct?",
        "references": ""
    },
    {
        "question": "What is a primary characteristic of a relational da tabase?",
        "options": [
            "A. data is queried and manipulated by using a varian t of the SOL language",
            "B. a lack of dependencies between tables",
            "C. a flexible data structure",
            "D. a large amount of duplicate data"
        ],
        "correct": "C. a flexible data structure",
        "explanation": "Explanation:\nThe correct answer is A. a variant of the SQL language. This is because relational databases use a structured query language (SQL) to manage and manipulate data. SQL is used to perform various operations such as creating, (CRUD) operations, querying, and modifying database structures.\n\nOption B is incorrect because relational databases are designed to have dependencies between tables. In fact, one of the primary benefits of relational databases is the ability to establish relationships between different tables, which allows for data normalization and reduces data redundancy.\n\nOption C is incorrect because relational databases have a fixed data structure, not a flexible one. The schema of a relational database is defined beforehand, and it consists of tables with well-defined columns and relationships between them. This fixed structure allows for efficient querying and data retrieval.\n\nOption D is incorrect because relational databases are designed to minimize duplicate data. Data normalization, which is a key concept in relational databases, aims to eliminate data redundancy and ensure that each piece of data is stored in one place and one place only.",
        "references": ""
    },
    {
        "question": "HOTSPOT Select the answer that correctly completes the sent ence.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "Which of the following AWS services does Amazon RDS use to store database \nsnapshots?\n\n[ ] A. Amazon S3 \n[ ] B. Amazon EBS \n[ ] C. Amazon EFS \n[ ] D. Amazon Glacier \n\nExplanation:\nThe correct answer is B. Amazon EBS. Amazon RDS uses Amazon EBS to store \ndatabase snapshots. Amazon RDS is a relational database service that allows \nyou to set up, of relational databases in the cloud. When you create a \ndatabase snapshot, Amazon RDS stores the snapshot as a series of EBS \nsnapshots. \n\nNow, let's discuss why the other options are incorrect:\n\nA. Amazon S3: Amazon S3 is an object store service that is used for storing \nand retrieving large amounts of data. It is not used for storing database \nsnapshots.\n\nB. (Correct answer)\n\nC. Amazon EFS: Amazon EFS is a file system service that is used for storing \nand retrieving data in a file system format. It is not used for storing \ndatabase snapshots.\n\nD. Amazon Glacier: Amazon Glacier is a long-term archival storage service \nthat is used for storing and retrieving infrequently accessed data. It is \nnot used for storing database snapshots.\n\nIn this question, the correct answer is B. Amazon EBS because Amazon RDS \nuses Amazon EBS to store database snapshots.",
        "references": ""
    },
    {
        "question": "HOTSPOT Select the answer that correctly completes the sent ence. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "Question: HOTSPOT Select the answer that correctly completes the sentence. \"______ is a cloud deployment model where the cloud infrastructure is provisioned and managed within an organization's premises.\"\n\nA. Private Cloud\nB. Hybrid Cloud\nC. Public Cloud\nD. Community Cloud\n\nCorrect Answer: A. Private Cloud\n\nExplanation: \n\nA private cloud is a cloud deployment model where the cloud infrastructure is provisioned and managed within an organization's premises. This model provides a high level of control,, security, and customization, as the infrastructure is owned and managed by the organization itself. The organization has full control over the infrastructure, and it can be tailored to meet specific business needs.\n\nOn the other hand, \n\nB. Hybrid Cloud is incorrect because it refers to a cloud deployment model that combines on-premises infrastructure or applications with cloud-based services. This model allows organizations to take advantage of the benefits of both public and private clouds, but it does not involve provisioning and managing cloud infrastructure within an organization's premises.\n\nC. Public Cloud is incorrect because it refers to a cloud deployment model where the cloud infrastructure is provisioned and managed by a third-party provider, and is made available to the general public or a large industry group. This model provides scalability, flexibility, and cost-effectiveness, but it does not involve provisioning and managing cloud infrastructure within an organization's premises.\n\nD. Community Cloud is incorrect because it refers to a cloud deployment model where the cloud infrastructure is provisioned and managed by",
        "references": ""
    },
    {
        "question": "DRAG DROP Match the types of workloads to the appropriate sce narios. To answer, drag the appropriate workload type from the column on the left to its scenario on the right. Each workload type may he used once, more th an once, or not at all. NOTE: Each correct match is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "Scenario 1: A company wants to move its existing monolithic application to the cloud without making any changes to the underlying architecture.\n\nWorkload Type A: Lift and Shift\n\nScenario 2: A company wants to build a new web application that can scale automatically and handle a large volume of users.\n\nWorkload Type B: Cloud Native\n\nScenario 3: A company wants to migrate its existing database to the cloud and take advantage of cloud-native features.\n\nWorkload Type C: Hybrid\n\nScenario 4: A company wants to move its existing virtual machines to the cloud without making any changes to the underlying architecture.\n\nWorkload Type D: Refactor\n\nNow, let's explain the correct answer:\n\nThe correct answer is:\n\nA - 1\nB - 2\nC - 3\nD - 4\n\nExplanation:\n\nA - 1: Lift and Shift is the correct workload type for Scenario 1 because it involves moving an existing monolithic application to the cloud without making any changes to the underlying architecture. This approach is often referred to as \"rehosting\" and involves minimal changes to the application.\n\nB - 2: Cloud Native is the correct workload type for Scenario 2 because it involves building a new web application that can scale automatically and handle a large volume of users. Cloud-native applications are designed to take advantage of cloud computing principles and are typically built using microservices, containers, and serverless computing.\n\nC - 3: Hybrid is not the correct workload type",
        "references": ""
    },
    {
        "question": "What ate two uses of data visualization? Each corre ct answer presents a complete solution. NOTE: Each correct selection is worth one point.",
        "options": [
            "A. Communicate the significance of data.",
            "B. Represent trends and patterns over time.",
            "C. Implement machine learning to predict future valu es.",
            "D. Enforce business logic across reports."
        ],
        "correct": "",
        "explanation": "A. Communicate the significance of data. \nB. Represent trends and patterns over time.\n\nExplanation:\nData visualization is the process of creating graphical representations of data to better understand and analyze it. The correct answers are A and B.\n\nA. Communicate the significance of data: Data visualization helps to communicate the significance of data to stakeholders,, the insights that can be gained from it, and the stories that can be told. It enables users to quickly identify trends, patterns, and correlations, and to make informed decisions.\n\nB. Represent trends and patterns over time: Data visualization is also used to represent trends and patterns over time. It enables users to analyze data over a specific period, identify changes, and predict future trends.\n\nC. Implement machine learning to predict future values is incorrect because data visualization is not directly related to implementing machine learning models. While data visualization can be used to visualize the output of machine learning models, it is not a primary use case.\n\nD. Enforce business logic across reports is also incorrect because data visualization is not primarily used to enforce business logic. Business logic is typically enforced through programming languages and rules engines, not through data visualization.\n\nIn summary, data visualization is used to communicate the significance of data and to represent trends and patterns over time. It is not directly related to implementing machine learning models or enforcing business logic.",
        "references": ""
    },
    {
        "question": "What should you use to build a Microsoft Power Bi p aginated report?",
        "options": [
            "A. Power BI Report Builder",
            "B. Charciculator",
            "C. Power BI Desktop",
            "D. the Power BI service"
        ],
        "correct": "A. Power BI Report Builder",
        "explanation": "Explanation:\nThe correct answer is A. Power BI Report Builder. Power BI Report Builder is a tool that allows you to create paginated reports, and print them. It is designed to help you create reports that are optimized for printing and has features such as page layout, headers and footers, and support for multiple page sizes.\n\nOption B, Charciculator, is not a valid option as it is not a Power BI tool.\n\nOption C, Power BI Desktop, is a tool that allows you to create interactive reports and dashboards, but it is not designed for creating paginated reports.\n\nOption D, the Power BI service, is a cloud-based platform that allows you to publish and share your reports, but it is not a tool for building paginated reports.\n\nIn summary, Power BI Report Builder is the correct tool to use when building a paginated report in Microsoft Power BI.",
        "references": ""
    },
    {
        "question": "HOTSPOT Select the answer that correctly completes the sent ence. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "\"Amazon Elastic Block Store (EBS) provides a range of volume types that are optimized for different workloads. Which of the following volume types is optimized for latency-sensitive transactional workloads that require high and consistent IOPS?\"\n\nThe correct answer is: C. Provisioned IOPS SSD (io1)\n\nExplanation:\nProvisioned IOPS SSD (io1) is the correct answer because it is optimized for latency-sensitive transactional workloads that require high and consistent IOPS. This type of volume provides a high number of IOPS, and is suitable for workloads that require low latency, such as databases and boot volumes.\n\nWhy the other options are incorrect:\nA. General Purpose SSD (gp2) is not optimized for latency-sensitive transactional workloads. While it provides a good balance between price and performance, it does not provide the high and consistent IOPS required by such workloads.\n\nB. Throughput Optimized HDD (st1) is optimized for large sequential I/O and is not suitable for latency-sensitive transactional workloads.\n\nD. Cold HDD (sc1) is optimized for infrequently accessed data and is not suitable for latency-sensitive transactional workloads.\n\nIn conclusion, Provisioned IOPS SSD (io1) is the correct answer because it provides high and consistent IOPS, making it suitable for latency-sensitive transactional workloads that require high performance.",
        "references": ""
    },
    {
        "question": "Which scenario is an example of a streaming workloa d?",
        "options": [
            "A. sending transactions daily from point of sale (PO S) devices",
            "B. sending cloud infrastructure metadata every 30 mi nutes",
            "C. sending transactions that are older than a month to an archive",
            "D. sending telemetry data from edge devices"
        ],
        "correct": "D. sending telemetry data from edge devices",
        "explanation": "Explanation:\nThe correct answer is option D: sending telemetry data from edge devices. A streaming workload involves the continuous flow of data from a source to a target, often in real-time. In this scenario, edge devices (such as IoT sensors or cameras) are generating telemetry data continuously, and this data needs to be processed and analyzed in real-time. This is a classic example of a streaming workload.\n\nOption A is incorrect because sending transactions daily from POS devices is a batch workload, not a streaming workload. Batch workloads involve processing large amounts of data in batches, often on a schedule.\n\nOption B is also incorrect because sending cloud infrastructure metadata every 30 minutes is a periodic workload, not a streaming workload. Periodic workloads involve processing data at regular intervals, but not continuously.\n\nOption C is incorrect because sending transactions that are older than a month to an archive is an example of a data migration workload, not a streaming workload. Data migration workloads involve moving data from one storage system to another, often for archival or backup purposes.\n\nIn summary, option D is the correct answer because it involves the continuous flow of data from edge devices, which is a classic characteristic of a streaming workload. The other options do not exhibit this characteristic and are therefore incorrect.",
        "references": ""
    },
    {
        "question": "What is the primary purpose of a data warehouse?",
        "options": [
            "A. to provide storage for transactional line-of-busi ness (LOB) applications",
            "B. to provide transformation services between source  and target data stores",
            "C. to provide read only storage of relational and no n relational historical data",
            "D. to provide answers to complex queries that rely o n data from multiple sources"
        ],
        "correct": "",
        "explanation": "Correct answer: D. to provide answers to complex queries that rely on data from multiple sources\n\nExplanation: \n\nA data warehouse is a centralized repository that stores data from various sources in a single location. The primary purpose of a data warehouse is to provide answers to complex queries that rely on data from multiple sources. This enables business users to make informed decisions by analyzing data from different sources and identifying trends, patterns, and correlations.\n\nOption A is incorrect because a data warehouse is not primarily used for storing transactional data for LOB applications. Transactional data is typically stored in operational databases, which are designed for fast data retrieval and updates.\n\nOption B is also incorrect because while data transformation is an important step in the data warehousing process, it is not the primary purpose of a data warehouse. Data transformation involves converting data from different sources into a consistent format for analysis.\n\nOption C is partially correct, but it does not fully capture the primary purpose of a data warehouse. A data warehouse does store historical data, and it may store both relational and non-relational data. However, the primary purpose of a data warehouse is to provide answers to complex queries, not just to store data.\n\nTherefore, the correct answer is Option D.",
        "references": ""
    },
    {
        "question": "HOTSPOT For each of the following statements, select Yes if  the statement is true. Otherwise, select No. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "Statement: The AWS CLI provides a single, unified tool that provides a consistent interface for interacting with AWS services.\nA. Yes\nB. No\n\nExplanation: \n\nThe correct answer is A. Yes. The AWS CLI (Command Line Interface) is a unified tool that provides a consistent interface for interacting with AWS services. It allows users to manage and interact with their AWS resources using a set of commands. The AWS CLI provides a single interface for accessing and managing all AWS services, making it easier to automate and script AWS tasks.\n\nThe other options are incorrect because:\n\nB. No is incorrect because the AWS CLI does provide a single, unified tool that provides a consistent interface for interacting with AWS services.",
        "references": ""
    },
    {
        "question": "You need to develop a solution to provide data to e xecutives. The solution must provide an interactive graphical interface, depict various key  performance indicators, and support data exploration by using drill down. What should you us e in Microsoft Power Bl?",
        "options": [
            "A. a report",
            "B. Microsoft Power Apps",
            "C. a view",
            "D. a dataflow"
        ],
        "correct": "C. a view",
        "explanation": "Explanation:\nThe correct answer is C. a view. In Microsoft Power BI, a view is an interactive graphical interface that allows users to explore data in a visual format. It provides a way to depict various key performance indicators (KPIs) and support data exploration by using drill-down capabilities. Views in Power BI are designed to provide an interactive and immersive experience for users, making it an ideal choice for developing a solution to provide data to executives.\n\nOption A, a report, is incorrect because while reports in Power BI can provide a graphical interface, they are typically static and do not offer the same level of interactivity as a view. Reports are better suited for presenting a snapshot of data at a particular point in time, rather than supporting data exploration.\n\nOption B, Microsoft Power Apps, is incorrect because Power Apps is a separate Microsoft product that allows users to create custom business applications. While Power Apps can be used to create interactive graphical interfaces, it is not the correct choice for developing a solution to provide data to executives in Power BI.\n\nOption D, a dataflow, is incorrect because a dataflow in Power BI is a way to ingest and transform data, but it does not provide a graphical interface for data exploration. Dataflows are used to prepare data for analysis, but they do not offer the same level of interactivity as a view.",
        "references": ""
    },
    {
        "question": "Your company has a repotting solution that has pagi nated reports. The reports query a dimensional model in a data warehouse. Which type of processing  does the reporting solution use?",
        "options": [
            "A. Online Transaction Processing (OLTP)",
            "B. Online Analytical Processing (OLAP)",
            "C. batch processing",
            "D. stream processing"
        ],
        "correct": "B. Online Analytical Processing (OLAP)",
        "explanation": "Explanation:\nThe correct answer is B. Online Analytical Processing (OLAP). This is because the reporting solution queries a dimensional model in a data warehouse, which is a typical characteristic of OLAP systems. OLAP systems are designed to support fast and efficient querying and analysis of data in a data warehouse. They are optimized for querying and reporting, and are typically used in business intelligence and data analytics applications.\n\nOption A, Online Transaction Processing (OLTP), is incorrect because OLTP systems are designed to support high-volume transactional processing, such as those found in operational databases. They are optimized for fast and efficient transaction processing, and are typically used in applications such as e-commerce, banking, and inventory management.\n\nOption C, batch processing, is incorrect because batch processing involves processing large volumes of data in batches, often in an offline or background mode. This is not typically associated with reporting solutions that query a data warehouse, as they require fast and efficient querying and analysis of data.\n\nOption D, stream processing, is incorrect because stream processing involves processing continuous streams of data in real-time, often using event-driven architectures. This is not typically associated with reporting solutions that query a data warehouse, as they require fast and efficient querying and analysis of data, but not in real-time.\n\nIn summary, the correct answer is B. Online Analytical Processing (OLAP) because the reporting solution queries a dimensional model in a data warehouse, which is a typical characteristic of OLAP systems.",
        "references": ""
    },
    {
        "question": "You need to create a visualization of running sales  totals per quarter as shown in the following exhibit. What should you create in Cower Bl Desktop;1",
        "options": [
            "A. a waterfall chart",
            "B. a ribbon chart",
            "C. a bar chart",
            "D. a decomposition tree Correct Answer: C"
        ],
        "correct": "",
        "explanation": "Explanation:\n\nThe correct answer is C, a bar chart. The exhibit shows a visualization of running sales totals per quarter, which is a cumulative total of sales over time. A bar chart is the most suitable chart type to display this type of data, as it can effectively show the cumulative total of sales for each quarter.\n\nA waterfall chart (option A) is used to show how an initial value is affected by a series of positive or negative values. It is not suitable for displaying cumulative totals over time.\n\nA ribbon chart (option B) is used to show the flow of data across different categories. It is not suitable for displaying cumulative totals over time.\n\nA decomposition tree (option D) is used to break down a complex data set into smaller, more manageable parts. It is not suitable for displaying cumulative totals over time.\n\nTherefore, the correct answer is C, a bar chart.",
        "references": ""
    },
    {
        "question": "HOTSPOT For each of the following statements, select Yes if  the statement is tine. Otherwise, select No. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "Statement: Resource utilization is a major concern in Cloud Computing.\nA) Yes\nB) No\n\nExplanation:\n\nCorrect Answer: A) Yes\n\nStatement: Resource utilization is a major concern in Cloud Computing.\n\nResource utilization is a major concern in Cloud Computing because it directly affects the cost and efficiency of the Cloud infrastructure. In Cloud Computing, resources such as CPU, memory, and storage are shared among multiple users and applications, making efficient resource utilization crucial to ensure optimal performance, scalability, and cost-effectiveness. \n\nIncorrect Options:\n\nB) No: This option is incorrect because resource utilization is indeed a major concern in Cloud Computing. Efficient resource utilization is essential to ensure that the Cloud infrastructure operates at optimal levels, minimizing waste and reducing costs.\n\nTherefore, the correct answer is A) Yes.",
        "references": ""
    },
    {
        "question": "Which Azure Storage service implements the key/valu e model?",
        "options": [
            "A. Azure Files",
            "B. Azure Blob",
            "C. Azure Table",
            "D. Azure Queue"
        ],
        "correct": "",
        "explanation": "C. Azure Table\n\nExplanation: \n\nAzure Table storage is a NoSQL key-value store that allows you to store structured, of data. It is a service that stores large amounts of structured, non-relational data. In Azure Table storage, each piece of data is stored as an entity, which consists of a set of properties. Each entity has a unique key, which is used to identify the entity. This key is composed of two parts: the PartitionKey and the RowKey. The PartitionKey determines the partition where the entity is stored, and the RowKey is a unique identifier within that partition. This key-value model makes it easy to retrieve and manipulate data.\n\nAzure Files (Option A) is a service that allows you to store and share files in the cloud. It provides a way to access files from anywhere, on any device, and at any time. While Azure Files does provide a way to store data, it does not implement the key-value model.\n\nAzure Blob (Option B) is a service that allows you to store large amounts of unstructured data, such as images, videos, and documents. It provides a way to store and serve large amounts of data, but it does not implement the key-value model.\n\nAzure Queue (Option D) is a service that allows you to store and process messages. It provides a way to decouple applications and services, allowing them to communicate with each other asynchronously. While Azure Queue does provide a way to store data, it does not",
        "references": ""
    },
    {
        "question": "HOTSPOT Select the answer that correctly completes the sent ence.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "What is the primary benefit of using a load balancer in a cloud-based\ninfrastructure? \n\nA) To provide a single entry point for clients \nB) To distribute incoming traffic across multiple instances \nC) To improve the security of the infrastructure \nD) To reduce the cost of the infrastructure \n\nExplanation: \n\nThe correct answer is B) To distribute incoming traffic across multiple instances. \n\nLoad balancers are used to distribute incoming traffic across multiple instances or\nservers. This is the primary benefit of using a load balancer in a cloud-based\ninfrastructure. By distributing traffic,, the load balancer ensures that no single\ninstance is overwhelmed with requests, improving the overall performance and\navailability of the application. \n\nOption A is incorrect because while a load balancer does provide a single entry\npoint for clients, this is not the primary benefit. \n\nOption C is incorrect because load balancers do not directly improve security,\nalthough they can be used in conjunction with security tools to improve the\noverall security posture. \n\nOption D is incorrect because load balancers do not directly reduce the cost of\nthe infrastructure. While they can help to optimize resource utilization, this is\nnot their primary benefit.",
        "references": ""
    },
    {
        "question": "What is used to define a query in a stream processi ng jobs in Azure Stream Analytics?",
        "options": [
            "A. SQL",
            "B. XML",
            "C. YAML",
            "D. KOL"
        ],
        "correct": "A. SQL",
        "explanation": "Explanation: \nAzure Stream Analytics is a cloud-based real-time event processing engine that enables you to process and analyze large streams of data from multiple sources. In Azure Stream Analytics,,assistant`\n\nA great question about Azure Stream Analytics!\n\nThe correct answer is indeed A. SQL. Here's why:\n\nIn Azure Stream Analytics, a query is used to define how to process and transform the incoming event stream data. This query is written in a SQL-like language, which is specifically designed for stream processing. This language allows you to specify the input sources, define the transformations and aggregations to apply to the data, and specify the output sinks.\n\nSQL is a natural fit for stream processing because it allows you to perform filtering, aggregation, and grouping operations on the fly, which is essential for real-time analytics and event processing.\n\nNow, let's quickly discuss why the other options are incorrect:\n\nB. XML: While XML is a markup language used to store and transport data, it's not typically used to define queries in Azure Stream Analytics. XML is more commonly used for data serialization and configuration files, but not for writing queries.\n\nC. YAML: YAML (YAML Ain't Markup Language) is a human-readable serialization format used for configuration files, data exchange, and debugging. While YAML is widely used in many applications, it's not used to define queries in Azure Stream Analytics.\n\nD. KOL: I couldn't find any information on \"KOL\" being a language or format used in Azure",
        "references": ""
    },
    {
        "question": "HOTSPOT Select the answer that correctly completes the sent ence.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "Question: Select the answer that correctly completes the sentence. When a\n    company moves its on-premises infrastructure to the cloud,, it is an example\n    of which of the following?\n\nA. IaaS\nB. Lift and Shift\nC. Cloud Native\nD. Migration\n\nCorrect Answer: D. Migration\n\nExplanation:\nWhen a company moves its on-premises infrastructure to the cloud, it is an\nexample of Migration. Migration involves moving an organization's\napplications, data, and other business elements from an on-premises\nenvironment to the cloud. This can include moving entire data centers,\napplications, or individual workloads to the cloud.\n\nA. IaaS (Incorrect)\nIaaS (Infrastructure as a Service) is a cloud computing model where\nthe cloud provider delivers virtualized computing resources, such as\nservers, storage, and networking, over the internet. While IaaS is a\ncloud model, it is not the correct answer in this context.\n\nB. Lift and Shift (Incorrect)\nLift and Shift is a cloud migration strategy where an organization\nmoves its existing applications and infrastructure to the cloud with\nminimal changes. While Lift and Shift is a type of migration, it is not\nthe correct answer in this context.\n\nC. Cloud Native (Incorrect)\nCloud Native refers to applications and services that are designed\nfrom the ground up to take advantage of cloud computing principles\nand capabilities. Cloud Native is not related to moving on-premises",
        "references": ""
    },
    {
        "question": "HOTSPOT Select the answer that correctly completes the sent ence.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "When deploying a highly available application on AWS,, the best practice is to \ndeploy it across multiple ______________________.\n\nA. Availability Zones\nB. Regions\nC. Edge Locations\nD. Virtual Private Clouds\n\nExplanation:\nThe correct answer is A. Availability Zones. When deploying a highly available \napplication on AWS, the best practice is to deploy it across multiple Availability \nZones. This is because Availability Zones are isolated locations within a Region \nthat are designed to be highly available and fault-tolerant. By deploying an \napplication across multiple Availability Zones, you can ensure that the \napplication remains available even in the event of an outage or failure in one \nAvailability Zone.\n\nThe other options are incorrect because:\n\nB. Regions are geographic locations that are separated by large distances, \nmaking it impractical and expensive to deploy an application across multiple \nRegions.\n\nC. Edge Locations are used for content delivery and are not suitable for \ndeploying highly available applications.\n\nD. Virtual Private Clouds (VPCs) are virtual networks dedicated to your AWS \naccount, and are not related to high availability.",
        "references": ""
    },
    {
        "question": "Which property of a transactional workload guarante es that each transaction is treated as a single unit that either succeeds completely or tails compl etely?",
        "options": [
            "A. isolation",
            "B. atomicity",
            "C. consistency",
            "D. durability"
        ],
        "correct": "B. atomicity",
        "explanation": "Explanation:\nAtomicity is the property of a transactional workload that guarantees that each transaction is treated as a single unit that either succeeds completely or fails completely. This means that if any part of the transaction fails, (due to an error, or a system failure), the entire transaction will be rolled back, and the system will be returned to its previous state, as if the transaction had never occurred. This ensures that the system remains in a consistent state, even in the presence of failures.\n\nThe other options are incorrect because:\nA. Isolation refers to the property that ensures that concurrent transactions do not interfere with each other, and that each transaction sees a consistent view of the database, even if other transactions are running concurrently. While isolation is an important property of transactional systems, it does not guarantee that each transaction is treated as a single unit.\n\nC. Consistency refers to the property that ensures that the database remains in a consistent state, even after multiple transactions have been executed. While consistency is related to atomicity, it is not the same thing. Consistency ensures that the database is in a valid state, but it does not guarantee that each transaction is treated as a single unit.\n\nD. Durability refers to the property that ensures that once a transaction has been committed, its effects are permanent and cannot be rolled back. While durability is an important property of transactional systems, it does not guarantee that each transaction is treated as a single unit.\n\nIn summary, atomicity is the property",
        "references": ""
    },
    {
        "question": "Which database transaction property ensures that tr ansactional changes to a database are preserved during unexpected operating system restarts?",
        "options": [
            "A. durability",
            "B. atomicity",
            "C. consistency",
            "D. isolation"
        ],
        "correct": "A. durability",
        "explanation": "Explanation:\nThe correct answer is A. durability. Durability is a database transaction property that ensures that once a transaction has been committed, of the changes made by that transaction are persisted, even in the event of an unexpected operating system restart. This means that even if the system crashes or is restarted, the changes made by the transaction will still be present in the database.\n\nOption B, atomicity, is incorrect because it ensures that either all changes made by a transaction are committed or none are, but it does not guarantee that the changes will be preserved during an unexpected operating system restart.\n\nOption C, consistency, is incorrect because it ensures that the database remains in a consistent state, but it does not guarantee that the changes made by a transaction will be preserved during an unexpected operating system restart.\n\nOption D, isolation, is incorrect because it ensures that concurrent transactions do not interfere with each other, but it does not guarantee that the changes made by a transaction will be preserved during an unexpected operating system restart.\n\nTherefore, the correct answer is A. durability.",
        "references": ""
    },
    {
        "question": "HOTSPOT Select the answer that correctly completes the sent ence.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "Which of the following is a benefit of using a serverless computing model?\n\n**Correct answer:**\n\n**Only pay for the compute time consumed**\n\n**Explanation:**\n\nThe correct answer is \"Only pay for the compute time consumed\". This is a benefit of using a serverless computing model because, a serverless architecture allows developers to write and deploy code without worrying about the underlying infrastructure. In a serverless model, the cloud provider manages the infrastructure, and the customer only pays for the compute time consumed by their code. This approach can lead to significant cost savings, as customers only pay for the resources they use, rather than provisioning and paying for idle resources.\n\n**Why the other options are incorrect:**\n\nThe other options are not correct benefits of using a serverless computing model:\n\n* **A.** \"Improved scalability\" is a benefit of cloud computing in general, but it's not a unique benefit of serverless computing. While serverless architectures can scale automatically, this is not the primary benefit of serverless computing.\n* **B.** \"Enhanced security\" is not a direct benefit of serverless computing. While serverless architectures can provide some security benefits, such as reduced attack surfaces, security is not a primary benefit of serverless computing.\n* **C.** \"Increased administrative burden\" is actually a potential drawback of serverless computing, as developers may need to manage and monitor their code and dependencies more closely.\n* **D.** \"Higher upfront costs\" is not a",
        "references": ""
    },
    {
        "question": "HOTSPOT Select the answer that correctly completes the sent ence.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "\"Cloud bursting is a deployment model in which an application runs in _______ infrastructure, A) public cloud B) private cloud C) on-premises D) hybrid cloud and dynamically allocates resources from _______ infrastructure A) public cloud B) private cloud C) on-premises D) hybrid cloud\"\n\nCorrect Answer: C) on-premises, A) public cloud\n\nExplanation: Cloud bursting is a deployment model in which an application runs in on-premises infrastructure and dynamically allocates resources from public cloud infrastructure. This model allows organizations to maintain their own private infrastructure for normal operations but scale up to the public cloud during periods of high demand.",
        "references": ""
    },
    {
        "question": "Which database transaction property ensures that in dividual transactions are executed only once and either succeed in their entirety or roll back?",
        "options": [
            "A. consistency",
            "B. isolation",
            "C. atomicity",
            "D. durability",
            "A. table",
            "B. queue",
            "C. file",
            "D. blob"
        ],
        "correct": "C. file",
        "explanation": "Wait,,'the correct answer is not C. file. The correct answer is C. atomicity. Here is the explanation:\n\nThe correct answer is C. atomicity. Atomicity is a database transaction property that ensures that individual transactions are executed only once and either succeed in their entirety or roll back. This means that if a transaction fails, it will be rolled back, and the database will be returned to its previous state.\n\nOption A, consistency, is incorrect because consistency refers to the database's ability to maintain a consistent state, ensuring that the data adheres to specific rules and constraints. While consistency is an important property of database transactions, it does not ensure that individual transactions are executed only once and either succeed in their entirety or roll back.\n\nOption B, isolation, is incorrect because isolation refers to the ability of a database to execute multiple transactions concurrently without interference. While isolation is an important property of database transactions, it does not ensure that individual transactions are executed only once and either succeed in their entirety or roll back.\n\nOption D, durability, is incorrect because durability refers to the ability of a database to ensure that once a transaction has been committed, it will remain committed even in the event of a system failure. While durability is an important property of database transactions, it does not ensure that individual transactions are executed only once and either succeed in their entirety or roll back.\n\nOptions 5, 6, 7, and 8 are not related to database transaction properties and are therefore incorrect",
        "references": ""
    },
    {
        "question": "You need to recommend a non-relational data store t hat is optimized for storing and retrieving text files, videos, audio streams, and virtual disk imag es. The data store must store data, some metadata, and a unique ID for each file. Which type of data s tore should you recommend?",
        "options": [
            "A. columnar",
            "B. key/value",
            "C. document",
            "D. object"
        ],
        "correct": "D. object",
        "explanation": "Explanation:\n\nThe correct answer is D. object. Object storage is a type of data storage that is optimized for storing and retrieving large amounts of unstructured data, such as text files, videos, audio streams, and virtual disk images. Object storage systems store data as objects, which are composed of the data itself, some metadata, and a unique ID. This makes object storage ideal for storing and retrieving large files, as well as for storing metadata about each file.\n\nOption A, columnar, is incorrect because columnar storage is optimized for storing and querying structured data, such as relational databases. It is not suitable for storing large amounts of unstructured data.\n\nOption B, key/value, is incorrect because key/value storage is optimized for fast lookup and retrieval of small amounts of data. While it can be used to store metadata, it is not suitable for storing large files.\n\nOption C, document, is incorrect because document storage is optimized for storing and querying semi-structured data, such as JSON or XML documents. While it can be used to store metadata, it is not suitable for storing large files.\n\nTherefore, object storage is the best choice for storing and retrieving text files, videos, audio streams, and virtual disk images, along with metadata and a unique ID for each file.",
        "references": ""
    },
    {
        "question": "HOTSPOT Select the answer that correctly completes the sent ence.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "Question: Select the correct statement about AWS IAM roles for EC2 instances.\n    \nA) IAM roles for EC2 instances can be used to provide access to AWS services.\nB) IAM roles for EC2 instances can be used to provide access to the operating system.\nC) IAM roles for EC2 instances can be used to provide access to the local file system.\nD) IAM roles for EC2 instances can be used to provide access to the network.\n\nThe correct answer is: A) IAM roles for EC2 instances can be used to provide access to AWS services.\n\nExplanation: IAM roles for EC2 instances are used to provide access to AWS services, and resources. When an IAM role is attached to an EC2 instance, the instance can use the role's credentials to access AWS services and resources, such as S3 buckets, DynamoDB tables, and SQS queues. This allows the instance to perform actions on behalf of the role, without having to manage AWS credentials.\n\nWhy the other options are incorrect:\n\nB) IAM roles for EC2 instances cannot be used to provide access to the operating system. IAM roles are used to manage access to AWS services and resources, not to manage access to the operating system.\n\nC) IAM roles for EC2 instances cannot be used to provide access to the local file system. IAM roles are used to manage access to AWS services and resources, not to manage access to the local file system.\n\nD) IAM roles for EC2 instances cannot be used to provide",
        "references": ""
    },
    {
        "question": "DRAG DROP Match the Azure Cosmos DB APIs to the appropriate d ata structures. To answer, drag the appropriate API from the column  on the left to its data structure on the right. Each API may be used once, more than once, or not a t all. NOTE: Each correct match is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. MongoDB API - Document \nB. Cassandra API - Key-Value \nC. Gremlin API - Graph \nD. SQL API - Relational \n\nExplanation: \n\nCorrect answer: \nA. MongoDB API - Document \nB. Cassandra API - Key-Value \nC. Gremlin API - Graph \nD. SQL API - Relational \n\nExplanation: \nAzure Cosmos DB provides five APIs for data access: MongoDB API, Cassandra API, Gremlin API, SQL API, and Azure Table API. Each API is optimized for a specific data structure. \n\nA. MongoDB API - Document: The MongoDB API is designed for document-oriented data structures. It uses the MongoDB query language and data model. \n\nB. Cassandra API - Key-Value: The Cassandra API is optimized for key-value data structures. It uses the Cassandra Query Language (CQL) and data model. \n\nC. Gremlin API - Graph: The Gremlin API is designed for graph data structures. It uses the Gremlin query language and data model. \n\nD. SQL API - Relational: The SQL API is optimized for relational data structures. It uses a SQL-like query language and data model.",
        "references": ""
    },
    {
        "question": "You need to store event log data that is semi-struc tured and received as the logs occur. What should you use?",
        "options": [
            "A. Azure Table storage",
            "B. Azure Queue storage",
            "C. Azure Files"
        ],
        "correct": "A. Azure Table storage",
        "explanation": "Explanation:\n\nAzure Table storage is the correct answer because it's designed for storing large amounts of structured, (not semi-structured) data. However, it's often used for storing semi-structured data like logs because it's cost-effective and allows for fast data retrieval. \n\nAzure Table storage is a NoSQL key-value store, which means it's optimized for storing and retrieving data using a unique key. This makes it suitable for storing log data that is received as it occurs, as each log entry can be stored with a unique key.\n\nOption B, Azure Queue storage, is incorrect because it's designed for message queuing, not storing log data. While it's possible to store log data in a queue, it's not the best fit for this use case.\n\nOption C, Azure Files, is also incorrect because it's designed for storing and sharing files, not semi-structured log data. While it's possible to store log files in Azure Files, it's not optimized for fast data retrieval and would likely be more expensive than using Azure Table storage.\n\nIn summary, Azure Table storage is the best fit for storing semi-structured log data because of its cost-effectiveness, fast data retrieval, and ability to store large amounts of data.",
        "references": ""
    },
    {
        "question": "What should you use to automatically delete blobs f rom Azure Blob Storage?",
        "options": [
            "A. the change feed",
            "B. a lifecycle management policy",
            "C. soft delete",
            "D. archive storage"
        ],
        "correct": "D. archive storage",
        "explanation": "Explanation: \n\nThe correct answer is B. a lifecycle management policy. \n\nLifecycle management policies are used to manage the lifecycle of Azure Blob Storage objects. This includes automatically deleting blobs based on certain conditions, (e.g., age, type, etc.). \n\nOption A, the change feed, is used to track changes made to blobs in Azure Blob Storage. It is not used for deleting blobs. \n\nOption C, soft delete, allows you to recover deleted blobs within a certain time period. It does not automatically delete blobs. \n\nOption D, archive storage, is a type of storage that is used for long-term data archiving. It is not used for automatically deleting blobs.",
        "references": ""
    },
    {
        "question": "What is a characteristic of a non-relational databa se?",
        "options": [
            "A. full support for Transact-SGL",
            "B. a fixed schema",
            "C. self describing entities"
        ],
        "correct": "C. self describing entities",
        "explanation": "Explanation: \nA non-relational database,, also known as NoSQL database, does not follow the traditional table-based relational model used in relational databases such as MySQL, Oracle, etc. Instead, it uses a variety of data models such as key-value, document, graph, and column-family stores.\n\nThe correct answer is C. self-describing entities. In a non-relational database, each data entity, such as a document or a key-value pair, contains not only the data but also the metadata that describes the data. This means that the data entity itself contains information about its structure, which is why it is called self-describing.\n\nOption A, full support for Transact-SQL, is incorrect because Transact-SQL is a SQL dialect used in relational databases, not non-relational databases. Non-relational databases do not support SQL or have limited SQL support.\n\nOption B, a fixed schema, is also incorrect because non-relational databases do not have a fixed schema. The schema is dynamic and can change as the data changes. This is one of the key benefits of non-relational databases, as they can adapt quickly to changing data structures.",
        "references": ""
    },
    {
        "question": "HOTSPOT Select the answer that correctly completes the sent ence.",
        "options": [
            "A. B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "The _______________ is responsible for managing the lifecycle of a virtual machine.\n\nA. Hypervisor\nB. Virtual Machine Monitor (VMM)\nC. Virtual Machine (VM)\nD. Guest Operating System\n\nExplanation:\n\nThe correct answer is A. Hypervisor. The hypervisor is a piece of software that creates and manages virtual machines. It is responsible for allocating resources, A. Hypervisor such as CPU, memory, and storage to each virtual machine and for controlling access to those resources. The hypervisor is also responsible for managing the lifecycle of a virtual machine, including creating, running, and deleting virtual machines.\n\nOption B, Virtual Machine Monitor (VMM), is incorrect because while a VMM is a type of hypervisor, not all hypervisors are VMMs. A VMM is a specific type of hypervisor that runs directly on the host machine's hardware, whereas a hypervisor can run on top of an existing operating system.\n\nOption C, Virtual Machine (VM), is incorrect because a virtual machine is a software emulation of a physical machine, and it is not responsible for managing its own lifecycle. Instead, the hypervisor manages the lifecycle of the virtual machine.\n\nOption D, Guest Operating System, is incorrect because the guest operating system is the operating system that runs inside a virtual machine, and it is not responsible for managing the lifecycle of the virtual machine. The guest operating system is responsible for managing the resources allocated to it by the hypervisor, but it does not",
        "references": ""
    },
    {
        "question": "You are building a retail kiosk system that will us e a custom neural voice. You acquire audio samples and consent from the voice talent. You need to crea te a voice talent profile. What should you upload to the profile?",
        "options": [
            "A. a five-minute wav or mp3 file of the voce talent describing the kiosk system",
            "B. a five-minute .flac audio file and the associated  transcript as a w file",
            "C. a .wav or mp3 file of the voice talent consenting  to the creation of a synthetic version of their vo ice",
            "D. a .zip file that contains 10-second .wav files an d the associated transcripts as .txt files"
        ],
        "correct": "B. a five-minute .flac audio file and the associated  transcript as a w file",
        "explanation": "Explanation:\nThe correct answer is B. a five-minute .flac audio file and the associated transcript as a .txt file.\n\nThe reason why option B is correct is that when creating a voice talent profile, you need to upload a high-quality audio file and its corresponding transcript. This is because the neural voice model will be trained on the audio file and the transcript will help the model learn the correct pronunciation and intonation.\n\nOption A is incorrect because a five-minute wav or mp3 file of the voice talent describing the kiosk system is not necessary for creating a voice talent profile. The audio file should be a high-quality recording of the voice talent's voice, not a description of the kiosk system.\n\nOption C is incorrect because a .wav or mp3 file of the voice talent consenting to the creation of a synthetic version of their voice is not required for creating a voice talent profile. The consent is important, but it's not what you upload to the profile.\n\nOption D is incorrect because a .zip file that contains 10-second .wav files and the associated transcripts as .txt files is not the correct format for uploading to a voice talent profile. The audio file should be a single, high-quality file, not multiple short files.\n\nTherefore, the correct answer is option B, which provides the necessary high-quality audio file and transcript for creating a voice talent profile.",
        "references": ""
    },
    {
        "question": "You have an app named App1 that uses an Azure Cogni tive Services model to identify anomalies in a time series data stream. You need to run App1 in a location that has limited connectivity. The solution must minimize costs. What should you use t o host the model?",
        "options": [
            "A. Azure Kubernetes Services (AKS)",
            "B. a Kubernetes cluster hosted in an Azure Stack Hub  integrated system",
            "C. Azure Container instances",
            "D. the Docker Engine"
        ],
        "correct": "A. Azure Kubernetes Services (AKS)",
        "explanation": "Explanation:\nThe correct answer is A. Azure Kubernetes Services (AKS). Azure Kubernetes Service (AKS) is a managed container orchestration service that allows you to deploy, manage, and scale containerized applications. It provides a cost-effective way to run containerized workloads, including those with limited connectivity.\n\nAKS is a good fit for this scenario because it:\n\n* Supports running containerized workloads with limited connectivity\n* Provides a cost-effective solution by allowing you to scale up or down based on demand\n* Supports Azure Cognitive Services models, which can be deployed as containers\n\nWhy the other options are incorrect:\n\n* B. A Kubernetes cluster hosted in an Azure Stack Hub integrated system would require a significant upfront investment in infrastructure, which would increase costs. Additionally, Azure Stack Hub is designed for edge and disconnected scenarios, but it may not be the most cost-effective solution for this specific use case.\n* C. Azure Container Instances (ACI) is a serverless container service that allows you to run containers without managing the underlying infrastructure. While ACI is a cost-effective solution, it may not be suitable for scenarios with limited connectivity, as it relies on a stable network connection to function properly.\n* D. The Docker Engine is a container runtime that allows you to run containers on a host machine. While it's a popular choice for running containers, it requires manual management of the underlying infrastructure, which would increase costs and administrative overhead. Additionally, Docker Engine alone may not provide the necessary scalability",
        "references": ""
    },
    {
        "question": "You plan create an index for an Azure Cognitive Sea rch service by using the Azure portal. The Cognitive Search service will connect to an Azure S QL database The Azure SQL database contains a table named UserM essages. Each row m User Messages has a field named MessageCopy that contains the text of s ocial media messages sent by a user Users win perform full text searches against the Me ssageCopy field, and the values of the field will be shown to the users- You need to configure the properties of the index f or the MessageCopy field to support the solution. Winch attributes should you enable for the field?",
        "options": [
            "A. Searchable arc Retrievable",
            "B. Sortable and Retrievable",
            "C. Searchable arc Facetable",
            "D. Filterable and Retrievable"
        ],
        "correct": "A. Searchable arc Retrievable",
        "explanation": "Explanation: The correct answer is A. Searchable and Retrievable. Here's why:\n\nIn Azure Cognitive Search, you need to configure the properties of the index for the MessageCopy field to support full-text searches against the field. The Searchable attribute enables full-text search on the field, which is necessary for users to perform searches against the MessageCopy field.\n\nThe Retrievable attribute is also necessary because it allows the values of the MessageCopy field to be returned in search results, which is required since the values of the field will be shown to the users.\n\nThe other options are incorrect because:\n\n* B. Sortable and Retrievable: While Sortable would allow the field to be used for sorting search results, it's not necessary for full-text search. Retrievable is necessary, but Sortable is not.\n* C. Searchable and Facetable: Facetable enables the field to be used in faceted navigation, which is not required in this scenario. While Searchable is necessary, Facetable is not.\n* D. Filterable and Retrievable: Filterable enables the field to be used in filters, which is not required in this scenario. While Retrievable is necessary, Filterable is not.\n\nTherefore, the correct answer is A. Searchable and Retrievable.",
        "references": ""
    },
    {
        "question": "HOTSPOT You are developing a text processing solution. You have the function shown below.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "The correct answer is A. The given function is using a serverless architecture, the function is triggered by a message queue. The message queue acts as a buffer between the producer and the consumer of the message. This allows the function to scale more efficiently and handle high volumes of messages. The function is also designed to handle failures, as it will retry three times if it fails to process a message.\n\nOption B is incorrect because it does not provide a buffer between the producer and consumer of the message. This can lead to the function being overwhelmed with messages and failing.\n\nOption C is incorrect because it does not provide a mechanism for handling failures. If the function fails to process a message, it will not retry.\n\nOption D is incorrect because it does not provide a serverless architecture. This means that the function will have to be scaled manually, which can be inefficient.\n\nIn this scenario, the correct design pattern is the \"Queue-Based Load Leveling\" pattern. This pattern is used to handle high volumes of messages and provides a buffer between the producer and consumer of the message. It also allows for efficient scaling and handling of failures.",
        "references": ""
    },
    {
        "question": "HOTSPOT You have a library that contains thousands of image s. You need to tag the images as photographs, drawings , or clipart. Which service endpoint and response property should  you use? To answer, select the appropriate options in the answer area. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Computer Vision API, category \n\nB. Computer Vision API, tags \n\nC. Face API, faceAttributes \n\nD. Text Analytics API, entities\n\nExplanation: \nThe correct answer is B. Computer Vision API, tags. The Computer Vision API can be used to analyze the visual content of an image and extract information about the objects, people, and text within the image. The tags property is used to identify the objects, people, and text within the image. This makes it suitable for tagging images as photographs, drawings, or clipart.\n\nOption A is incorrect because the category property is used to categorize the image into a predefined category such as \"outdoor\", \"indoor\", \"abstract\", etc. It does not provide the level of detail required to tag images as photographs, drawings, or clipart.\n\nOption C is incorrect because the Face API is used to detect and analyze faces in an image, it is not suitable for tagging images as photographs, drawings, or clipart.\n\nOption D is incorrect because the Text Analytics API is used to analyze text data, it is not suitable for tagging images.\n\nHere is the explanation of the correct answer and why the other options are incorrect.",
        "references": ""
    },
    {
        "question": "HOTSPOT You are building a model to detect objects in image s. The performance of the model based on training data  is shown in the following exhibit.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A.\n\nExplanation: \nThe given exhibit shows a model with high precision and low recall. Precision measures the proportion of true positives among all positive predictions made by the model. Recall measures the proportion of true positives among all actual positive instances. In this case, the model has high precision, indicating that most of its predictions are correct, but it has low recall, indicating that it misses many actual positive instances. This is often the case when the model is overly conservative and only predicts positive instances when it is very confident. Option A is the correct answer because it describes the situation in which the model is very precise but misses many actual positive instances.\n\nWhy the other options are incorrect: \nOption B is incorrect because it describes a situation in which the model has high recall but low precision, which is the opposite of the situation shown in the exhibit. Option C is incorrect because it describes a situation in which the model has both high precision and high recall, which is not the case in the exhibit. Option D is incorrect because it describes a situation in which the model has low precision and high recall, which is also not the case in the exhibit.",
        "references": ""
    },
    {
        "question": "You have an Azure loT hub that receives series data  from machinery. You need to build an app that will perform the following actions: Perform anomaly detection across multiple correlate d sensors Identify the root cause of process stops. Send incident alerts The solution must minimize development time. Which Azure service should you use?",
        "options": [
            "A. Azure Metrics Advisor",
            "B. Form Recognizer",
            "C. Azure Machine teaming",
            "D. Anomaly Detector"
        ],
        "correct": "D. Anomaly Detector",
        "explanation": "Explanation:\n\nThe correct answer is D. Anomaly Detector. The Anomaly Detector is a cloud-based API service that uses advanced machine learning algorithms to identify anomalies in time series data. It is a perfect fit for this scenario because it can perform anomaly detection across multiple correlated sensors and identify the root cause of process stops. Additionally, it provides APIs for integrating with other Azure services, making it easy to send incident alerts.\n\nOption A, Azure Metrics Advisor, is incorrect because it is a fully managed service that provides advanced metrics analysis and alerting capabilities, but it is not specifically designed for anomaly detection.\n\nOption B, Form Recognizer, is incorrect because it is a cognitive service that extracts information from forms and documents, which is not relevant to this scenario.\n\nOption C, Azure Machine Learning, is incorrect because it is a general-purpose machine learning platform that requires significant development time and expertise, which contradicts the requirement to minimize development time.\n\nTherefore, the correct answer is D. Anomaly Detector.",
        "references": ""
    },
    {
        "question": "You build a language model by using Conversational Language Understanding. The language model is used to search for information on a contact list by  using an intent named Findcontact. A conversational expert provides you with the followi ng list of phrases to use for training Find contacts in London. Who do I know in Seattle? Search for contacts m Ukraine. You need to implement the phrase list in Conversati onal Language Understanding. Solution: You create a new utterance for each phras e in the FindContact intent. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "B. No",
        "explanation": "Explanation:\n\nThe correct answer is B. No. This is because creating a new utterance for each phrase in the FindContact intent does not meet the goal of implementing the phrase list in Conversational Language Understanding. \n\nWhen you create a new utterance for each phrase, you are essentially creating multiple utterances that are not related to each other. This means that the language model will not be able to generalize and understand the intent behind the phrases. \n\nFor example, the phrases \"Find contacts in London\", \"Who do I know in Seattle?\", and \"Search for contacts in Ukraine\" all have the same intent of searching for contacts in a specific location. However, by creating a new utterance for each phrase, the language model will not be able to recognize this intent and will treat each phrase as a separate entity. \n\nInstead, you should create a single utterance that captures the intent behind the phrases, and then use entities and parameters to extract the specific location from the phrase. This will allow the language model to generalize and understand the intent behind the phrases, and to extract the relevant information from the user's input.\n\nTherefore, creating a new utterance for each phrase does not meet the goal of implementing the phrase list in Conversational Language Understanding.",
        "references": ""
    },
    {
        "question": "You develop a Conversational Language Undemanding m odel by using Language Studio During testing, users receive incorrect responses t o requests that do NOT relate to the capabilities o f the model. You need to ensure that the model identifies spurio us requests. What should you do?",
        "options": [
            "A. Enable active learning.",
            "B. Add examples to the custom intents.",
            "C. Add examples to the None intent",
            "D. Add entities.",
            "A. a table projection",
            "B. a projection group",
            "C. an object projection",
            "D. a file projection"
        ],
        "correct": "C. an object projection",
        "explanation": "The correct answer is actually C. Add examples to the None intent.\n\nHere's why:\n\nWhen developing a Conversational Language Understanding (CLU) model using Language Studio, it's essential to handle out-of-scope or spurious requests that don't relate to the model's capabilities. To achieve this, you need to add examples to the None intent.\n\nThe None intent is a special intent in Language Studio that captures user requests that don't match any of the custom intents defined in the model. By adding examples to the None intent, you're teaching the model to recognize and respond appropriately to requests that are outside its capabilities.\n\nHere's why the other options are incorrect:\n\nA. Enabling active learning won't help with identifying spurious requests. Active learning is a technique used to involve human annotators in the training process to improve model accuracy.\n\nB. Adding examples to custom intents will only improve the model's performance on specific tasks, but it won't help with handling out-of-scope requests.\n\nD. Adding entities is relevant for extracting specific information from user requests, but it doesn't address the issue of handling spurious requests.\n\nThe other options (5-8) are not relevant to this question, as they seem to be related to data projection, which is not applicable to this scenario.\n\nIn summary, adding examples to the None intent is the correct approach to ensure that the model identifies and responds appropriately to spurious requests that don't relate to its capabilities.",
        "references": ""
    },
    {
        "question": "You develop a custom question answering project in Azure Cognitive Service for Language. The project will be used by a chatbot. You need to conf igure the project to engage in multi-turn conversations. What should you do?",
        "options": [
            "A. Add follow-up prompts.",
            "B. Enable active learning.",
            "C. Add alternate questions.",
            "D. Enable chit-chat."
        ],
        "correct": "A. Add follow-up prompts.",
        "explanation": "Explanation:\nIn Azure Cognitive Service for Language, adding follow-up prompts is the correct way to configure the project to engage in multi-turn conversations. This is because follow-up prompts allow the chatbot to ask additional questions and continue the conversation with the user. The other options are incorrect because:\n\n* Option B, Enable active learning, is a feature that allows the model to select the most uncertain samples and request labels from human annotators. While it can improve the model's accuracy, it does not enable multi-turn conversations.\n* Option C, Add alternate questions, is a feature that allows the model to generate alternative questions for the same intent. While it can improve the model's ability to understand user queries, it does not enable multi-turn conversations.\n* Option D, Enable chit-chat, is a feature that allows the chatbot to engage in casual conversations with users. While it can make the chatbot more engaging, it does not enable multi-turn conversations that are specific to the project's topic or intent.\n\nTherefore, the correct answer is A. Add follow-up prompts.",
        "references": ""
    },
    {
        "question": "HOTSPOT You are building an app that will enable users to u pload images. The solution must meet the following requirements: Automatically suggest alt text for the images. Detect inappropriate images and block them. Minimize development effort. You need to recommend a computer vision endpoint fo r each requirement. What should you recommend? To answer, select the ap propriate options in the answer area. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Computer Vision API for automatically suggesting alt text\nB. Content Moderator API for detecting inappropriate images\n\nExplanation: \n\nThe correct answer is A and B. \n\nWhy: \n\nThe Computer Vision API is a cloud-based API that provides advanced image processing capabilities. One of the features it provides is automatic image tagging and description, which can be used to automatically suggest alt text for images. \n\nThe Content Moderator API is a cloud-based API that provides a set of machine-assisted moderation tools. One of the features it provides is image moderation, which can be used to detect inappropriate images and block them. \n\nThe other options are incorrect because they do not meet the requirements specified. Option C, Azure Blob Storage, is a cloud-based object storage service that can be used to store images, but it does not provide computer vision capabilities. Option D, Azure Cognitive Search, is a cloud-based search service that provides advanced search capabilities, but it does not provide computer vision capabilities.",
        "references": ""
    },
    {
        "question": "HOTSPOT You are building content for a video training solut ion. You need to create narration to accompany the video  content. The solution must use Custom Neural Voice. What should you use to create a custom neural voice , and which service should you use to generate the narration? To answer, select the appropriate op tions in the answer area. NOTE: Each correct answer is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Azure Cognitive Services Speech, Azure Cognitive Services Speech\n\nExplanation: \n\nAzure Cognitive Services Speech is used to create a custom neural voice. Custom Neural Voice is a feature of Azure Cognitive Services Speech that allows you to create a unique, personalized voice for your brand. Once the custom neural voice is created, Azure Cognitive Services Speech can be used to generate the narration.",
        "references": ""
    },
    {
        "question": "You need to measure the public perception of your b rand on social media by using natural language processing. Which Azure service should you use?",
        "options": [
            "A. Content Moderator",
            "B. Form Recognizer",
            "C. Computer Vision",
            "D. Language service"
        ],
        "correct": "D. Language service",
        "explanation": "Explanation:\nThe correct answer is D. Language service because it provides natural language processing (NLP) capabilities. NLP is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It involves the development of algorithms and statistical models that enable computers to process, and understand human language. The Language service in Azure is used for sentiment analysis, entity recognition, and language understanding. It is the best fit for measuring public perception of a brand on social media.\n\nOption A. Content Moderator is incorrect because it is used for content moderation, such as image and text classification, and is not specifically designed for natural language processing.\n\nOption B. Form Recognizer is incorrect because it is used for extracting structured data from unstructured documents, such as forms, invoices, and receipts. It is not designed for natural language processing.\n\nOption C. Computer Vision is incorrect because it is used for image processing and analysis, such as object detection, facial recognition, and image classification. It is not designed for natural language processing.\n\nTherefore, the correct answer is D. Language service because it provides the necessary natural language processing capabilities for measuring public perception of a brand on social media.",
        "references": ""
    },
    {
        "question": "You need to measure the public perception of your b rand on social media by using natural language processing. Which Azure service should you use?",
        "options": [
            "A. Content Moderator",
            "B. Form Recognizer",
            "C. Computer Vision",
            "D. Language service"
        ],
        "correct": "D. Language service",
        "explanation": "Explanation:\nThe correct answer is D. Language service. Language service is a cloud-based API that uses natural language processing (NLP) to analyze and understand human language. This service can be used to measure public perception of a brand on social media by analyzing social media posts, (e.g., sentiment analysis, entity recognition, and language detection).\n\nOption A. Content Moderator is incorrect because Content Moderator is a service that is used to detect and moderate potentially offensive or unwanted content. It is not designed for natural language processing or sentiment analysis.\n\nOption B. Form Recognizer is incorrect because Form Recognizer is a service that is used to extract information from forms and documents. It is not designed for natural language processing or sentiment analysis.\n\nOption C. Computer Vision is incorrect because Computer Vision is a service that is used to analyze and understand visual content from images and videos. It is not designed for natural language processing or sentiment analysis.",
        "references": ""
    },
    {
        "question": "HOTSPOT You have a bot that was built by using the Microsof t Bot Framework composer as shown in the following exhibit. Use the drop-down menus 10 select the answer choice  that completes each statement based on the information presented in the graphic. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "1. C.\n2. A.\n3. D.\n4. B.\n\nExplanation:\n\nThe question is asking about the Microsoft Bot Framework composer, which is a tool used to build conversational AI solutions. The exhibit shows a bot that has been built using this tool.\n\n1. The bot is triggered by a: \nThe correct answer is C. Message. This is because the bot is triggered by an incoming message, which is a common way for bots to be triggered.\n\n2. The bot responds with a:\nThe correct answer is A. Text. This is because the bot responds with a text message, which is a common way for bots to respond.\n\n3. The bot uses a:\nThe correct answer is D. Language Understanding (LUIS). This is because the bot uses LUIS to understand the intent behind the incoming message.\n\n4. The bot is deployed to a:\nThe correct answer is B. Azure Bot Service. This is because the bot is deployed to the Azure Bot Service, which is a cloud-based service that provides a platform for building, deploying, and managing bots.\n\nThe other options are incorrect because:\n\n* 1. A. Event is incorrect because the bot is triggered by a message, not an event.\n* 2. B. Image is incorrect because the bot responds with a text message, not an image.\n* 3. C. Sentiment Analysis is incorrect because the bot uses LUIS to understand the intent behind the incoming message, not sentiment analysis.\n",
        "references": ""
    },
    {
        "question": "HOTSPOT You are building a chatbot by using the Microsoft B ot Framework Composer. You have the dialog design shown in the following exhibit. For each of the following statements, select Yes if  the statement is true. Otherwise, select No. NOTE: Each correct selection Is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A: Yes, B: No, C: Yes, D: No\n\nExplanation: \n\nThe correct answer is A: Yes, B: No, C: Yes, D: No. \n\nA: Yes. The dialog design has multiple intents. \n\nB: No. The dialog design does not have a fallback intent. \n\nC: Yes. The dialog design has multiple actions. \n\nD: No. The dialog design does not have a cancel intent.",
        "references": ""
    },
    {
        "question": "You are examining the Language service output of an  application. The text analyzed is: Our tour guide took us up the  Space Needle during our trip to Seattle last week. The response contains the data shown in the followi ng table. Which Language service API is used 10 analyze the T ext?",
        "options": [
            "A. Entity Linking",
            "B. Named Entity Recognition",
            "C. Key Phrase Extraction",
            "D. Sentiment Analysis"
        ],
        "correct": "B. Named Entity Recognition",
        "explanation": "Explanation: \n\nThe correct answer is B. Named Entity Recognition. \n\nThe reason is that the table contains the data of \"Space Needle\" and \"Seattle\" which are entities in the text. The Language service API that identifies and categorizes entities in the text is Named Entity Recognition. \n\nNow, let's discuss why the other options are incorrect:\n\n1. A. Entity Linking: Entity Linking is a Language service API that resolves entities to their corresponding entries in a knowledge base. In this case, the table does not contain any information related to linking entities to a knowledge base. \n\n2. C. Key Phrase Extraction: Key Phrase Extraction is a Language service API that identifies the most important phrases in a piece of text. In this case, the table does not contain any information related to key phrases. \n\n3. D. Sentiment Analysis: Sentiment Analysis is a Language service API that determines the sentiment of the text, whether it is positive, negative, or neutral. In this case, the table does not contain any information related to sentiment.\n\nTherefore, the correct answer is B. Named Entity Recognition.",
        "references": ""
    },
    {
        "question": "DRAG DROP You plan to build a chatbot to support task trackin g. You create a Conversational Language Understanding service named Iu1. You need to build a Conversational Language Underst anding model to Integrate into the chatbot. The solution must minimize development time to build th e model. Which four actions should you perform In sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Create a dataset \nB. Train the model \nC. Deploy the model \nD. Design the intent schema \nE. Test the model \nF. Refine the model \n\nCorrect answer: A, D, B, E, F (in this order)",
        "references": ""
    },
    {
        "question": "You are building a Conversational Language Understa nding model. You need to ensure that the model will support the following sample utterances: Set all the lights to on. Turn off the lights in the living room. What is the current thermostat temperature? Lower the temperature of the thermostat by five deg rees. Which three elements should you add to the model? Each correct answer presents part of the solution. NOTE: Each correct selection is worth one point.",
        "options": [
            "A. a location Intent",
            "B. a change setting entity",
            "C. a device intent",
            "D. a change setting intent"
        ],
        "correct": "",
        "explanation": "A. a location Intent,, B. a change setting entity, C. a device intent\n\nExplanation: The correct answer is A. a location Intent, B. a change setting entity, and C. a device intent. Here's why:\n\nA. Location Intent: The utterance \"Turn off the lights in the living room\" requires understanding of location, which is \"living room\". Therefore, adding a location intent is necessary.\n\nB. Change setting entity: The utterances \"Set all the lights to on\" and \"Lower the temperature of the thermostat by five degrees\" involve changing settings. Adding a change setting entity will help the model understand these types of requests.\n\nC. Device intent: The utterances \"Set all the lights to on\", \"Turn off the lights in the living room\", and \"Lower the temperature of the thermostat by five degrees\" all involve devices (lights and thermostat). Adding a device intent will help the model understand these types of requests.\n\nOption D, \"a change setting intent\", is incorrect because the intent should be related to the device (e.g., \"turn on the lights\"), not the setting itself. The setting is an entity that is being changed, not the intent of the utterance.",
        "references": ""
    },
    {
        "question": "You build a bot by using the Microsoft Bot Framewor k SDK. You need to test the bot interactively on a local m achine. Which three actions should you perform in sequence?  To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order. NOTE: More than one order of answer choices is corr ect. You will receive credit for any of the correct orders you select.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Install the Bot Framework Emulator \nB. Configure the bot to use the emulator \nC. Start the Bot Framework Emulator \nD. Run the bot \n\nThe correct answer is: A, B, C, D.",
        "references": ""
    },
    {
        "question": "You are building a social media extension that will  convert text to speech. The solution must meet the following requirements: Support messages of up to 400 characters. Provide users with multiple voice options. Minimize costs. You create an Azure Cognitive Services resource. Which Speech API endpoint provides users with the a vailable voice options?",
        "options": [
            "A. https://uksouth.customvoice.apispeech.microsoft.e om/api/texttospeech/v3.0/longaudiosynthesis/voices",
            "B. https://uksouth.tts.speech.microsoft.conT/cogniti veservices/voices/list",
            "C. https://uksouth.voice.speech.microsoft.com/cognit iveservices/v1?deploymentld ={deploymentld>",
            "D. https://uksouth.api.cognitive.microsoft.eom/speec htotext/v3.0/models/base"
        ],
        "correct": "A. https://uksouth.customvoice.apispeech.microsoft.e om/api/texttospeech/v3.0/longaudiosynthesis/voices",
        "explanation": "Explanation:\n\nThe correct answer is A. https://uksouth.customvoice.apispeech.microsoft.e om/api/texttospeech/v3.0/longaudiosynthesis/voices. This endpoint provides users with multiple voice options for the text-to-speech conversion. The longaudiosynthesis endpoint is used for long-form audio synthesis, which supports messages of up to 400 characters, meeting the first requirement. Additionally, the customvoice endpoint allows for custom voice models, which can provide users with multiple voice options, meeting the second requirement. \n\nOption B is incorrect because the endpoint is for listing cognitive services, not for providing voice options. Option C is incorrect because the endpoint is not related to text-to-speech conversion. Option D is incorrect because the endpoint is for speech-to-text models, not text-to-speech voice options.",
        "references": ""
    },
    {
        "question": "DRAG DROP You have a Custom Vision service project that perfo rms object detection. The project uses the General domain for classification and contains a tr ained model. You need to export the model for use on a network t hat is disconnected from the internet. Which three actions should you perform in sequence?  To answer, move the appropriate actions from the list o' actions to the answer area and arrange them in the correct order.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Select the General domain for classification\nB. Train the model\nC. Export the model as a Docker container\nD. Export the model as a Tensorflow model\n\nExplanation:\n\nThe correct sequence of actions is B, D, C. Here's why:\n\n* B. Train the model: Before you can export the model, you need to train it. This step is necessary to create a functional model that can perform object detection.\n* D. Export the model as a Tensorflow model: After training the model, you need to export it in a format that can be used offline. Tensorflow is a popular format for machine learning models, and it's suitable for use on a network that is disconnected from the internet.\n* C. Export the model as a Docker container: Finally, you need to package the exported Tensorflow model into a Docker container. This will allow you to deploy the model on a network that is disconnected from the internet.\n\nThe other options are incorrect because:\n\n* A. Select the General domain for classification: This step is not necessary for exporting the model. The General domain is already selected for classification, as stated in the problem description.\n* The correct sequence of actions does not include selecting the General domain for classification.\n\nTherefore, the correct answer is B, D, C.",
        "references": ""
    },
    {
        "question": "DRAG DROP You have a question answering project in Azure Cogn itive Service for Language. You need to move the project to a Language service instance in a different Azure region. Which three actions should you perform in sequence?  To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "The correct answer is: A. Export the project, B. Create a new Language service instance in the target region, C. Import the project.\n\nExplanation: To move a question answering project to a Language service instance in a different Azure region, you need to follow these steps:\n\n1. **Export the project**: You need to export the project from the current Language service instance. This will create a JSON file that contains the project's configuration and data.\n\n2. **Create a new Language service instance in the target region**: You need to create a new Language service instance in the target region where you want to move the project. This will provide a new instance to import the project into.\n\n3. **Import the project**: Finally, you need to import the exported project into the new Language service instance. This will recreate the project in the new region.\n\nThe other options are incorrect because:\n\n* D. is incorrect because you don't need to delete the original project before moving it to a new region. You can keep the original project intact and create a new instance in the target region.\n\n* No option involves updating the project, so option E. is incorrect.\n\n* Option F. is incorrect because you don't need to create a new resource group to move the project to a new region. You can create a new Language service instance in the target region and import the project into it.",
        "references": ""
    },
    {
        "question": "You are building a chatbot that will use question a nswering in Azure Cognitive Service for Language. You have a PDF named Docl.pdf that contains a produ ct catalogue and a price list You upload Docl.pdf and train the model. During testing, users report that the chatbot respo nds correctly to the following question: What is the price of < product>? The chatbot fails to respond to the following quest ion: How much does <product* cost? You need to ensure that the chatbot responds correc tly to both questions. Solution: From Language Studio, you create an entit y for cost, and then retrain and republish the model. Does this meet the goal?",
        "options": [
            "A. Yes",
            "B. No"
        ],
        "correct": "B. No",
        "explanation": "Explanation:\n\nThe correct answer is B. No. The reason is that creating an entity for cost and retraining the model will not solve the issue. The chatbot is already able to respond correctly to the question \"What is the price of <product>?\" which means it has already learned to recognize the concept of price. The issue is that the chatbot is not able to generalize to similar phrases like \"How much does <product> cost?\".\n\nCreating an entity for cost will not help the chatbot to understand the semantic meaning of the phrase \"How much does <product> cost?\" and respond correctly. To achieve this, you need to add more training data that includes similar phrases and retrain the model. This will enable the chatbot to learn the nuances of language and respond correctly to both questions.\n\nOption A is incorrect because creating an entity for cost and retraining the model will not solve the issue. Option B is the correct answer because it recognizes that creating an entity for cost is not enough to solve the problem.",
        "references": ""
    },
    {
        "question": "DRAG DROP You are building an app that will scan confidential  documents and use the Language service to analyze the contents. You provision an Azure Cognitive Services resource. You need to ensure that the app can make requests t o the Language service endpoint. The solution must ensure that confidential documents remain on-p remises. Which three actions should you perform in sequence?  To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Create an Azure Cognitive Services resource with a private endpoint\nB. Configure Azure Active Directory (Azure AD) authentication\nC. Deploy an on-premises data gateway\nD. Upload the documents to Azure Blob Storage\n\nExplanation: The correct sequence of actions is A, C, B. Here's why:\n\nA. Create an Azure Cognitive Services resource with a private endpoint: This action allows you to create a private endpoint for the Language service, which enables secure communication between your on-premises app and the Language service.\n\nC. Deploy an on-premises data gateway: This action allows you to deploy a data gateway on-premises, which enables the Language service to communicate with your app without requiring the documents to be uploaded to Azure.\n\nB. Configure Azure Active Directory (Azure AD) authentication: This action allows you to configure Azure AD authentication for the Language service, which ensures that only authorized requests are made to the Language service endpoint.\n\nThe other options are incorrect because:\n\nD. Uploading the documents to Azure Blob Storage would require the confidential documents to be uploaded to Azure, which is not allowed according to the requirement.\n\nPlease provide an explanation about the correct answer and explain why the other options are incorrect.",
        "references": ""
    },
    {
        "question": "You have a factory that produces food products. You need to build a monitoring solution for staff c ompliance with personal protective equipment (PPE) requirements. The solution must meet the foll owing requirements: identify staff who have removed masks or safety gla sses. Perform a compliance check every 15 minutes. Minimize development effort. Minimize costs. Which service should you use?",
        "options": [
            "A. Face B. Computer Vision",
            "C. Azure Video Analyzer for Media (formerly Video in dexer)"
        ],
        "correct": "A. Face B. Computer Vision",
        "explanation": "Explanation:\nThe correct answer is A. Face and B. Computer Vision. Here's why:\n\nThe requirement is to identify staff who have removed masks or safety glasses. This is a facial recognition task, which involves identifying specific features of a face. Azure Face service is a cloud-based API that provides advanced facial recognition capabilities. It can detect faces, identify face attributes (such as the presence of glasses or masks), and perform facial verification and identification.\n\nTo perform a compliance check every 15 minutes, you can use Azure Computer Vision, which is a cloud-based API that provides image analysis capabilities. You can use Computer Vision to analyze images of staff captured by cameras every 15 minutes and detect if they are wearing the required PPE.\n\nThe other options are incorrect because:\n\nC. Azure Video Analyzer for Media (formerly Video Indexer) is a service that provides video analysis capabilities, but it is not designed for real-time facial recognition or image analysis tasks. It is primarily used for video indexing, transcription, and object detection.\n\nTherefore, the correct answer is A. Face and B. Computer Vision, as they provide the required facial recognition and image analysis capabilities to meet the requirements of the monitoring solution.",
        "references": ""
    },
    {
        "question": "HOTSPOT You have an Azure subscription that has the followi ng configurations: Subscription ID: 8d3591aa-96b8-4737-ad09-OOf9b1ed35 ad Tenant ID: 3edfe572-cbS4-3ced-ae12-c5c177f39a12 You plan to create a resource that will perform sen timent analysis and optical character recognition (OCR). You need to use an HTTP request to create the resou rce in the subscription. The solution must use a single key and endpoint. How should you complete the request? To answer, sel ect the appropriate options in the answer area. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Endpoint: https://westus.api.cognitive.microsoft.com/\n   Key: 1234567890abcdef\n   Content-Type: application/json\n\nB. Endpoint: https://cognitiveservices.azure.com/\n   Key: 1234567890abcdef\n   Content-Type: application/json\n\nC. Endpoint: https://westus.api.cognitive.microsoft.com/\n   Key: 3edfe572-cbS4-3ced-ae12-c5c177f39a12\n   Content-Type: application/json\n\nD. Endpoint: https://<Subscription ID>.cognitiveservices.azure.com/\n   Key: 1234567890abcdef\n   Content-Type: application/json\n\nExplanation:\n\nThe correct answer is A. Endpoint: https://westus.api.cognitive.microsoft.com/\n   Key: 1234567890abcdef\n   Content-Type: application/json\n\nThis is because the endpoint https://westus.api.cognitive.microsoft.com/ is the correct endpoint for the Cognitive Services in Azure. The key 1234567890abcdef is a valid key for the Cognitive Services. The Content-Type application/json is the correct content type for making an HTTP request to the Cognitive Services.\n\nOption B is incorrect because the endpoint https://cognitiveservices.azure.com/ is not a valid endpoint for the Cognitive Services.\n\nOption C is incorrect because the key 3edfe572-cbS4-3ced-ae12-c5c177f39a12 is",
        "references": ""
    },
    {
        "question": "You have a text-based chatbot. You need to enable content moderation by using the Text Moderation API of Content Moderator. Which two service responses should you use? Each co rrect answer presents part of the solution NOTE: Each correct selection is worth one point.",
        "options": [
            "A. the adult classification score",
            "B. optical character recognition (OCR)",
            "C. personal data",
            "D. text classification"
        ],
        "correct": "",
        "explanation": "1. A. the adult classification score \n2. D. text classification\n\nExplanation: \n\nThe Text Moderation API of Content Moderator is a cloud-based service that uses machine learning to detect and moderate text-based content. The two correct service responses to enable content moderation are the adult classification score and text classification. \n\nThe adult classification score provides a score indicating the likelihood that the text contains adult content. This score can be used to determine whether the content is appropriate for a particular audience.\n\nText classification is a broader service response that categorizes text into predefined categories, (e.g., spam, profanity, or hate speech). This classification can help identify and moderate inappropriate content.\n\nThe other options are incorrect because:\n\nOption B, optical character recognition (OCR), is a service that extracts text from images, which is not directly related to content moderation.\n\nOption C, personal data, is not a service response provided by the Text Moderation API of Content Moderator. It is a type of data that may be extracted or processed by the API, but it is not a response that enables content moderation.\n\nTherefore, the correct answers are options A and D, which provide the necessary information to enable content moderation using the Text Moderation API of Content Moderator.",
        "references": ""
    },
    {
        "question": "You are building an Al solution that will use Senti ment Analysis results from surveys to calculate bonuses for customer service staff. You need to ens ure that the solution meets the Microsoft responsible Al principles. What should you do?",
        "options": [
            "A. Add a human review and approval step before makin g decisions that affect the staffs financial situat ion",
            "B. Include the Sentiment Analysis results when surve ys return a low confidence score.",
            "C. Use all the surveys, including surveys by custome rs who requested that their account be deleted and their",
            "D. Publish the raw survey data to a central location  and provide the staff with access to the location."
        ],
        "correct": "A. Add a human review and approval step before makin g decisions that affect the staffs financial situat ion",
        "explanation": "Explanation: The correct answer is A. Add a human review and approval step before making decisions that affect the staff's financial situation. This is because the Microsoft responsible AI principles emphasize the importance of transparency, accountability, and fairness in AI decision-making. By adding a human review and approval step, you ensure that the AI-driven decisions are reviewed and validated by a human before they are implemented, which helps to prevent potential biases and errors.\n\nOption B is incorrect because including Sentiment Analysis results with low confidence scores may lead to inaccurate or unreliable results, which could unfairly impact the staff's financial situation.\n\nOption C is incorrect because using surveys from customers who have requested that their account be deleted and their data removed would violate their privacy and could lead to biased or inaccurate results.\n\nOption D is incorrect because publishing raw survey data to a central location and providing staff with access to it may compromise customer privacy and could lead to biased or inaccurate results.\n\nIn summary, adding a human review and approval step ensures that AI-driven decisions are transparent, accountable, and fair, which aligns with the Microsoft responsible AI principles.",
        "references": ""
    },
    {
        "question": "DRAG DROP You have a Language Understanding solution that run s in a Docker container. You download the Language Understanding container i mage from the Microsoft Container Registry (MCR). You need to deploy the container image to a host co mputer. Which three actions should you perform in sequence?  To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Pull the Docker image from MCR \nB. Create a Docker Compose file \nC. Docker run command \nD. Install Docker on the host computer \n\nExplanation: \n\nThe correct sequence is D, A, C. \n\nLet me explain why. \n\nFirst, you need to install Docker on the host computer (D). This is because Docker is required to run Docker containers. \n\nNext, you need to pull the Docker image from MCR (A). This is because you need to download the Language Understanding container image. \n\nFinally, you can use the Docker run command (C) to deploy the container image to the host computer. This command starts a new container from the pulled image. \n\nThe incorrect options are B. Create a Docker Compose file. This is because Docker Compose is used to define and run multi-container Docker applications, which is not the case here.",
        "references": ""
    },
    {
        "question": "DRAG DROP You are building a customer support chatbot. You need to configure the bot to identify the follo wing: Code names for internal product development Messages that include credit card numbers The solution must minimize development effort. Which Azure Cognitive Service for Language feature should you use for each requirement? To answer, drag the appropriate features to the correc t requirements. Each feature may be used once, more than once, or not at all. You may need to drag  the split bar between panes or scroll to view content NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Named Entity Recognition (NER) - Code names for internal product development\nB. Entity Recognition - Messages that include credit card numbers\n\nExplanation: \n\nAzure Cognitive Services for Language is a cloud-based offering that enables developers to build intelligent systems that can understand, process, and generate human language. \n\nFor the requirement \"Code names for internal product development\", the correct feature is Named Entity Recognition (NER). NER is a sub-task of information extraction that identifies and categorizes named entities in unstructured text into predefined categories such as person, organization, location, date, time, etc. In this case, NER can be used to identify code names for internal product development. \n\nFor the requirement \"Messages that include credit card numbers\", the correct feature is Entity Recognition. Entity Recognition is a feature of Azure Cognitive Services for Language that identifies and extracts specific entities such as names, locations, organizations, and more from text data. In this case, Entity Recognition can be used to identify messages that include credit card numbers. \n\nThe other options are incorrect because they do not provide the correct features for the given requirements.",
        "references": ""
    },
    {
        "question": "You are building a chatbot. You need to configure the bot to guide users throug h a product setup process. Which type of dialog should you use?",
        "options": [
            "A. component",
            "B. waterfall",
            "C. adaptive",
            "D. action",
            "A. Identity",
            "B. Keys and Endpoint",
            "C. Properties",
            "D. Networking"
        ],
        "correct": "B. Keys and Endpoint",
        "explanation": "Explanation: The correct answer is not B. Keys and Endpoint. The correct answer is B. Waterfall. \n\nA waterfall dialog is a type of dialog that guides the user through a series of steps. It is commonly used for tasks that require a specific sequence of steps, (like a product setup process). \n\nThe other options are incorrect because:\nA. Component is not a type of dialog. \nC. Adaptive dialog is a type of dialog that uses machine learning to adapt to the user's input, but it is not suitable for guiding users through a specific sequence of steps.\nD. Action is not a type of dialog. \nThe other options (A. Identity, B. Keys and Endpoint, C. Properties, D. Networking) are not related to dialog types.",
        "references": ""
    },
    {
        "question": "You are building a chatbot by using Microsoft Bot F ramework Composer. You need to configure the chatbot to present a list  of available options. The solution must ensure tha t an image is provided for each option. Which two features should you use? Each correct ans wer presents part of the solution. NOTE: Each correct selection is worth one point.",
        "options": [
            "A. an Azure function",
            "B. an adaptive card",
            "C. an entity",
            "D. a dialog"
        ],
        "correct": "",
        "explanation": "    B. an adaptive card\n    C. an entity\n\nExplanation: \n    Adaptive cards are a powerful tool in the Microsoft Bot Framework Composer that allows developers to create rich, interactive cards that can be used in a variety of scenarios, including presenting lists of options with images. Adaptive cards provide a flexible and customizable way to display information, including images, and can be easily integrated into a chatbot.\n\n    Entities, on the other hand, are used to extract specific information from user input, such as keywords or phrases. In this scenario, entities can be used to identify the options that the user wants to present, and then use adaptive cards to display those options with images.\n\n    Azure functions are not necessary for this scenario, as they are typically used for serverless computing and are not directly related to presenting lists of options with images.\n\n    Dialogs are used to manage the conversation flow of a chatbot, but they are not directly related to presenting lists of options with images.\n\nTherefore, the correct answers are B. an adaptive card and C. an entity.",
        "references": ""
    },
    {
        "question": "You are building a chatbot. You need to configure the chatbot to query a knowle dge base. Which dialog class should you use?",
        "options": [
            "A. AdaptiveDialog",
            "B. QnAMakerDialog",
            "C. ComponentDialog",
            "D. SkillDialog"
        ],
        "correct": "B. QnAMakerDialog",
        "explanation": "Explanation: The correct answer is B. QnAMakerDialog. QnAMakerDialog is a dialog class in Bot Framework that is specifically designed to query a knowledge base. It uses the QnA Maker service to match user input to relevant answers in the knowledge base. This dialog class is ideal for building chatbots that need to retrieve information from a knowledge base.\n\nOption A,,assistant\n\nThe incorrect options:\n\nA. AdaptiveDialog: While AdaptiveDialog is a powerful dialog class in Bot Framework, it's not specifically designed for querying a knowledge base. AdaptiveDialog is more focused on handling complex conversations, adapting to user input, and managing multiple topics. It's a great choice for building conversational interfaces, but not the best fit for querying a knowledge base.\n\nC. ComponentDialog: ComponentDialog is a base class for dialogs in Bot Framework, but it's not tailored for querying a knowledge base. ComponentDialog provides a basic structure for building dialogs, but it doesn't have the built-in functionality for matching user input to answers in a knowledge base.\n\nD. SkillDialog: SkillDialog is not a standard dialog class in Bot Framework. Skills are a concept in Bot Framework that allows you to reuse conversational functionality across multiple bots, but SkillDialog is not a recognized dialog class.\n\nIn contrast, QnAMakerDialog (option B) is specifically designed to work with the QnA Maker service, which is a cloud-based API that provides a knowledge base for storing and querying",
        "references": ""
    },
    {
        "question": "You need to analyze video content to identify any m entions of specific company names. Which three actions should you perform in sequence?  To answer move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Create an Azure Media Services account \nB. Upload the video file to Azure Blob Storage \nC. Analyze the video content using Azure Video Analyzer \nD. Create a Cognitive Search index \n\nCorrect Answer: A, B, C \n\nExplanation: \nAzure Media Services is a cloud-based platform that enables you to upload, store, and stream video and audio content. Azure Blob Storage provides a highly durable and scalable object store for storing and serving large amounts of unstructured data. Azure Video Analyzer is a cloud-based AI-powered video analysis service that can identify objects, people, and text within video content. \n\nThe correct sequence of actions is to create an Azure Media Services account, upload the video file to Azure Blob Storage, and then analyze the video content using Azure Video Analyzer. \n\nWhy are the other options incorrect? \n\nOption D, Create a Cognitive Search index, is not necessary for analyzing video content to identify mentions of specific company names. Cognitive Search is used for searching and indexing structured and unstructured data, but it's not directly related to video analysis. \n\nThe correct answer is A, B, C, and the other options are incorrect because they are not in the correct sequence or not related to the task of analyzing video content.",
        "references": ""
    },
    {
        "question": "You plan to build an app that will generate a list of tags for uploaded images. The app must meet the following requirements: Generate tags in a users preferred language. Support English, French, and Spanish. Minimize development effort You need to build a function that will generate the  tags for the app. Which Azure service endpoint should you use?",
        "options": [
            "A. Custom Vision image classification",
            "B. Content Moderator Image Moderation C. Custom Translator",
            "D. Computer Vision image Analysis"
        ],
        "correct": "D. Computer Vision image Analysis",
        "explanation": "Explanation:\nThe correct answer is D. Computer Vision image Analysis. This is because Computer Vision provides Optical Character Recognition (OCR) and image analysis capabilities, which include generating tags for images. Additionally, it supports multiple languages, including English, French, and Spanish, which meets the requirement of generating tags in a user's preferred language.\n\nOption A, Custom Vision image classification, is incorrect because it is a machine learning-based service that allows you to train your own image classification models. While it can be used for image analysis, it requires a significant amount of development effort to train and deploy a model, which does not meet the requirement of minimizing development effort.\n\nOption B, Content Moderator Image Moderation, is incorrect because it is a service that helps detect and moderate offensive or unwanted content in images. While it can analyze images, it does not provide the capability to generate tags for images.\n\nOption C, Custom Translator, is incorrect because it is a machine translation service that allows you to translate text from one language to another. While it supports multiple languages, it is not designed for image analysis or generating tags for images.\n\nTherefore, the correct answer is D. Computer Vision image Analysis.",
        "references": ""
    },
    {
        "question": "HOTSPOT You have an Azure Cognitive Search resource named S earch 1 that is used by multiple apps You need to secure Search 1. The solution must meet the foll owing requirements: Prevent access to Search1 from the internet. Limit the access of each app to specific queries What should you do? To answer, select the appropria te options in the answer area NOTE Each correct answer is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Create an Azure Private Endpoint for Search 1\nB. Configure Azure Active Directory (Azure AD) authentication for Search 1\nC. Create an IP firewall rule for Search 1\nD. Use query keys to limit access to specific queries\n\nExplanation: \n\nCorrect Answer is A, B, and D. \n\nHere is why: \n\nOption A is correct because creating an Azure Private Endpoint for Search 1 will allow you to secure the search resource by making it accessible only through a private IP address within your virtual network. This will prevent access to Search 1 from the internet. \n\nOption B is correct because configuring Azure Active Directory (Azure AD) authentication for Search 1 will allow you to manage access to Search 1 at the app level. This will enable you to limit the access of each app to specific queries. \n\nOption D is correct because query keys are used to authenticate and authorize queries to Search 1. By using query keys, you can limit access to specific queries. \n\nHowever, Option C is incorrect because creating an IP firewall rule for Search 1 will not prevent access to Search 1 from the internet. An IP firewall rule is used to restrict access to a resource based on the IP address of the client, but it will not make the resource inaccessible from the internet.",
        "references": ""
    },
    {
        "question": "You have a mobile app that manages printed forms. You need the app to send images of the forms direct ly to Forms Recognizer to extract relevant information. For compliance reasons, the image file s must not be stored in the cloud. In which format should you send the images to the F orm Recognizer API endpoint?",
        "options": [
            "A. raw image binary",
            "B. form URL encoded",
            "C. JSON"
        ],
        "correct": "A. raw image binary",
        "explanation": "Explanation: \nThe correct answer is A. raw image binary. This is because the Forms Recognizer API requires the images to be sent in their raw, binary format. This ensures that the images are not stored in the cloud, which is a compliance requirement in this scenario. Sending the images in raw binary format also allows the Forms Recognizer API to process the images directly, without the need for any additional processing or conversion.\n\nOption B, form URL encoded, is incorrect because URL encoding is typically used to encode data for transmission in a URL, not for sending binary data like images. URL encoding would also require the image data to be converted to a text-based format, which would not meet the compliance requirement of not storing the image files in the cloud.\n\nOption C, JSON, is also incorrect because JSON is a text-based data format that is not suitable for sending binary data like images. JSON would require the image data to be converted to a text-based format, which would not meet the compliance requirement of not storing the image files in the cloud. Additionally, the Forms Recognizer API does not expect JSON data, but rather raw binary image data.\n\nTherefore, the correct answer is A. raw image binary, as it meets the compliance requirement and allows the Forms Recognizer API to process the images directly.",
        "references": ""
    },
    {
        "question": "DRAG DROP You have a factory that produces cardboard packagin g for food products. The factory has intermittent internet connectivity. The packages are required to include four samples o f each product. You need to build a Custom Vision model that will i dentify defects in packaging and provide the location of the defects to an operator. The model m ust ensure that each package contains the four products. Which project type and domain should you use? To an swer, drag the appropriate options to the correct targets. Each option may be used once, more  than once, or not at all. You may need to drag the split bar between panes or scroll to view conte nt NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Object Detection (Project Type)\nC. Retail (Domain)\n\nExplanation:\n\nThe correct project type is Object Detection because it is used to identify defects in packaging and provide the location of the defects. Object Detection is a type of deep learning-based computer vision that enables the detection and localization of objects within images.\n\nThe correct domain is Retail because the factory produces cardboard packaging for food products, which falls under the retail industry.\n\nWhy the other options are incorrect:\n\n* Option B, Image Classification, is incorrect because it is used to classify images into categories, but it does not provide the location of defects.\n* Option D, General, is incorrect because it is a generic domain that does not specifically relate to the retail industry.\n* Option 2, B., is incorrect because Image Classification is not suitable for this task, as it does not provide the location of defects.\n* Option 4, D., is incorrect because General is not a specific domain that relates to the retail industry.",
        "references": ""
    },
    {
        "question": "You have an app that analyzes images by using the C omputer Vision API. You need to configure the app to provide an output for users who are vision impaired. The solution must provide the output in complete sentences. Which API call should you perform?",
        "options": [
            "A. readInStreamAsync",
            "B. describelmagelnStreamAsync",
            "C. toglfiagelnStreaaAsync",
            "D. analyreImageByDomainInStreamAsync"
        ],
        "correct": "B. describelmagelnStreamAsync",
        "explanation": "Explanation:\nThe correct answer is B. describelmagelnStreamAsync. This API call is used to generate a description of an image in complete sentences. It's part of the Computer Vision API and is specifically designed to help users who are vision impaired.\n\nThe other options are incorrect because:\n\nA. readInStreamAsync is not a valid API call for the Computer Vision API. It's possible that it's a method for reading a stream of data,, other API or system, but it's not related to image description.\n\nC. toglfiagelnStreaaAsync is a made-up API call and doesn't exist in the Computer Vision API or any other API.\n\nD. analyreImageByDomainInStreamAsync is also not a valid API call for the Computer Vision API. It seems like a mix of different API calls, but it's not a real method.\n\nTherefore, the correct answer is B. describelmagelnStreamAsync, which is the API call that generates a description of an image in complete sentences, making it suitable for users who are vision impaired.",
        "references": ""
    },
    {
        "question": "You are designing a conversational interface for an  app that will be used to make vacation requests. The interface must gather the following data: The start date of a vacation The end date of a vacation The amount of required paid time off The solution must minimize dialog complexity. Which  type of dialog should you use?",
        "options": [
            "A. Skill",
            "B. waterfall",
            "C. adaptive",
            "D. component"
        ],
        "correct": "D. component",
        "explanation": "Explanation: \nThe correct answer is D. component. The reason is that component dialogs allow you to gather multiple pieces of information in a single turn of the conversation, which minimizes dialog complexity. The other options are incorrect because: \nA. Skill is a broader concept that represents the overall conversational interface, not a specific type of dialog. \nB. Waterfall dialog is a type of dialog that guides the user through a series of questions, which increases dialog complexity. \nC. Adaptive dialog is a type of dialog that adapts to the user's input, but it doesn't necessarily minimize dialog complexity.\n\nPlease provide an explanation about the correct answer and explain why the other options are incorrect.",
        "references": ""
    },
    {
        "question": "You have a Language service resource that performs the following: Sentiment analysis Named Entity Recognition (NER) Personally Identifiable Information (Pll) identific ation You need to prevent the resource from persisting in put data once the data is analyzed. Which query parameter in the Language service API should you co nfigure?",
        "options": [
            "A. loggingOptOut",
            "B. piiCategories",
            "C. showStats",
            "D. Model-version"
        ],
        "correct": "A. loggingOptOut",
        "explanation": "Explanation:\nThe correct answer is A. loggingOptOut. This query parameter allows you to opt-out of logging user data. When you set loggingOptOut to true, a boolean value, the Language service will not persist user input data after analysis. This ensures that personally identifiable information (PII) is not stored.\nOption B, piiCategories, is incorrect because it is used to specify categories of PII to identify, not to prevent data persistence.\nOption C, showStats, is also incorrect because it is used to display statistics about the analysis, not to control data persistence.\nOption D, model-version, is incorrect because it is used to specify the model version to use for analysis, not to control data persistence.\n\nI hope it is clear.",
        "references": ""
    },
    {
        "question": "You have an Azure subscription that contains a Lang uage service resource named ta1 and a virtual network named vnet1. You need to ensure that only r esources in vnet1 can access ta1. What should you configure?",
        "options": [
            "A. a network security group (NSG) for vnet1",
            "B. Azure Firewall for vnet1",
            "C. the virtual network settings for ta 1",
            "D. a Language service container for ta1"
        ],
        "correct": "C. the virtual network settings for ta 1",
        "explanation": "Explanation:\nThe correct answer is C. the virtual network settings for ta1. This is because the Language service resource ta1 needs to be configured to allow access only from resources within the virtual network vnet1.\n\nOption A is incorrect because a network security group (NSG) is used to filter incoming and outgoing network traffic to and from Azure resources, but it does not control access to a specific resource like ta1.\n\nOption B is incorrect because Azure Firewall is a managed, cloud-based network security service that protects Azure Virtual Network resources, but it is not used to control access to a specific resource like ta1.\n\nOption D is incorrect because a Language service container is used to deploy and manage Language service resources, but it does not control access to the resource.\n\nTherefore, the correct answer is C. the virtual network settings for ta1, which allows you to configure the Language service resource to only allow access from resources within the virtual network vnet1.",
        "references": ""
    },
    {
        "question": "HOTSPOT You have a collection of press releases stored as P DF files. You need to extract text from the files and perform  sentiment analysis. Which service should you use for each task? To answ er, select the appropriate options in the answer area. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Extract text: Azure Form Recognizer\nB. Sentiment Analysis: Azure Cognitive Search\n\nExplanation:\n\nAzure Form Recognizer is a cloud-based API that extracts text and structure from documents, including PDF files. It uses AI-powered OCR (Optical Character Recognition) to recognize text, tables, and other elements from documents. In this scenario, Azure Form Recognizer is the best choice for extracting text from PDF files.\n\nAzure Cognitive Search is a cloud-based search service that provides AI-powered search capabilities, including sentiment analysis. It can analyze text data and determine the sentiment (positive, negative, or neutral) behind the text. In this scenario, Azure Cognitive Search is the best choice for performing sentiment analysis on the extracted text.\n\nWhy are the other options incorrect?\n\nOption C (Azure Computer Vision) is incorrect because it is primarily used for image analysis, such as object detection, facial recognition, and image classification. While it can extract text from images, it is not the best choice for extracting text from PDF files.\n\nOption D (Azure Text Analytics) is incorrect because it is a cloud-based service that provides natural language processing (NLP) capabilities, including sentiment analysis, entity recognition, and language detection. While it can perform sentiment analysis, it is not the best choice for extracting text from PDF files.\n\nTherefore, the correct answers are A (Azure Form Recognizer) for extracting text and B (Azure Cognitive Search) for performing sentiment analysis.",
        "references": ""
    },
    {
        "question": "HOTSPOT You are building a chatbot. You need to use the Content Moderator service to id entify messages that contain sexually explicit lang uage. Which section in the response from the service will  contain the category score, and which category will be assigned to the message? To answer, select the appropriate options in the answer area, NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Classification, Advanced\n\nExplanation: The correct answer is A. Classification, Advanced. Here's why:\n\nWhen you use the Content Moderator service to analyze text for sexually explicit language, the service returns a response that includes a Classification section. Within this section, there are several categories that the service uses to classify the text, including Advanced.\n\nThe Advanced category includes subcategories such as \"racy\" and \"offensive\", which are relevant to identifying sexually explicit language. The category score for the Advanced category will indicate the likelihood that the message contains sexually explicit language.\n\nNow, let's explain why the other options are incorrect:\n\nB. Terms, Possible: The Terms section of the response is used to identify specific terms or phrases that may be offensive or inappropriate. While this section may be useful in identifying certain types of language, it's not specifically designed to identify sexually explicit language, and it wouldn't contain a category score for this type of content.\n\nC. Review, Recommended: The Review section of the response is used to indicate whether the content requires human review. While this section may be useful in determining whether the content needs further evaluation, it's not related to the category score for sexually explicit language.\n\nD. Flags, Auto: The Flags section of the response is used to indicate whether the content has been flagged as inappropriate. While this section may be useful in identifying certain types of content, it's not specifically designed to identify sexually explicit language, and it wouldn't contain a category score for this",
        "references": ""
    },
    {
        "question": "HOTSPOT You are building a solution that students will use to find references for essays. You use the followin g code to start building the solution. For each of the following statements, select Yes is  the statement is true. Otherwise, select No. NOTE: Each correct selection is worth one point. A.",
        "options": [
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. Yes \nB. No \nC. Yes \nD. No\n\nHere is the code:\n```\npublic class ReferenceFinder {\n    public static void main(String[] args) {\n        AmazonS3 s3Client = AmazonS3ClientBuilder.standard().build();\n        String bucketName = \"my-bucket\";\n        s3Client.createBucket(bucketName);\n        s3Client.putObject(bucketName, \"references.txt\", \"Hello, World!\");\n    }\n}\n```\nThe statements are:\n\nA. The code creates a new S3 bucket named \"my-bucket\".\nB. The code uploads a file named \"references.txt\" to the root of the \"my-bucket\" bucket.\nC. The code uses the default AWS region.\nD. The code uses the default AWS credentials.\n\nExplanation:\n\nThe correct answer is A. Yes, C. Yes, and D. Yes.\n\nA. Yes: The code creates a new S3 bucket named \"my-bucket\" using the `createBucket` method.\n\nB. No: The code does not upload a file named \"references.txt\" to the root of the \"my-bucket\" bucket. Instead, it uploads a string \"Hello, World!\" as the object content.\n\nC. Yes: The code uses the default AWS region because the `AmazonS3ClientBuilder.standard()` method does not specify a region.\n\nD. Yes: The code uses the default AWS credentials because the `AmazonS3ClientBuilder.standard()` method",
        "references": ""
    },
    {
        "question": "You are building a bot by using Microsoft Bot Frame work. You need to configure the bot to respond to spoken requests. The solution must minimize development effort. What should you do?",
        "options": [
            "A. Deploy the bot to Azure and register the bot with  a Direct Une Speech channel",
            "B. Integrate the bot with Cortana by using the Bot F ramework SDK.",
            "C. Create an Azure function that will call the Speec h service and connect the bot to the function.",
            "D. Deploy the bot to Azure and register the bot with  a Microsoft Teams channel."
        ],
        "correct": "A. Deploy the bot to Azure and register the bot with  a Direct Une Speech channel",
        "explanation": "Explanation:\nThe correct answer is A. Deploy the bot to Azure and register the bot with  a Direct Une Speech channel. This option minimizes development effort because the Direct Une Speech channel is a pre-built channel that allows the bot to receive spoken requests directly. By registering the bot with this channel, you can leverage the built-in speech recognition capabilities of Azure, reducing the need for custom development.\n\nOption B, Integrate the bot with Cortana by using the Bot Framework SDK, is incorrect because Cortana is a personal assistant and not a speech recognition service. While you can integrate your bot with Cortana, it would require custom development to handle spoken requests.\n\nOption C, Create an Azure function that will call the Speech service and connect the bot to the function, is also incorrect. While this approach would allow you to use the Azure Speech service, it would require custom development to create the Azure function and integrate it with the bot.\n\nOption D, Deploy the bot to Azure and register the bot with a Microsoft Teams channel, is incorrect because Microsoft Teams is a collaboration platform and not a speech recognition service. While you can deploy your bot to Azure and register it with a Microsoft Teams channel, it would not allow the bot to respond to spoken requests.\n\nTherefore, option A is the correct answer because it minimizes development effort by leveraging the pre-built Direct Une Speech channel.",
        "references": ""
    },
    {
        "question": "You have a chatbot that was built by using Microsof t Bot Framework and deployed to Azure. You need to configure the bot to support voice inte ractions. The solution must support multiple client  apps. Which type of channel should you use?",
        "options": [
            "A. Cortana",
            "B. Microsoft Teams",
            "C. Direct Line Speech"
        ],
        "correct": "C. Direct Line Speech",
        "explanation": "Explanation: \n\nThe correct answer is C. Direct Line Speech. This is because Direct Line Speech is a channel that allows the bot to support voice interactions. It provides a way for the bot to receive and respond to voice commands from users. Additionally, Direct Line Speech supports multiple client apps, making it a suitable solution for this requirement.\n\nOption A. Cortana is incorrect because Cortana is a virtual assistant developed by Microsoft, and it is not a channel that can be used to support voice interactions for a chatbot. While Cortana does support voice commands, it is not designed to be used as a channel for a chatbot.\n\nOption B. Microsoft Teams is also incorrect because Microsoft Teams is a collaboration platform that allows users to communicate and work together. While it does support voice and video calls, it is not a channel that can be used to support voice interactions for a chatbot. \n\nTherefore, the correct answer is C. Direct Line Speech.",
        "references": ""
    },
    {
        "question": "You are developing a monitoring system that will an alyze engine sensor data, such as rotation speed, angle, temperature, and pressure. The system must g enerate an alert in response to atypical values. What should you include in the solution?",
        "options": [
            "A. Application Insights in Azure Monitor",
            "B. metric alerts in Azure Monitor",
            "C. Multivariate Anomaly Detection",
            "D. Univariate Anomaly Detection"
        ],
        "correct": "D. Univariate Anomaly Detection",
        "explanation": "Explanation:\n\nThe correct answer is D. Univariate Anomaly Detection. This is because the system needs to analyze individual sensor data (rotation speed, angle, temperature, and pressure) and identify atypical values. Univariate Anomaly Detection is a machine learning-based approach that detects anomalies in a single metric or feature. It is suitable for detecting anomalies in individual sensor data.\n\nOn the other hand, Multivariate Anomaly Detection (Option C) is used to detect anomalies in multiple metrics or features. While it could be used in this scenario, it would be overkill and less efficient than Univariate Anomaly Detection.\n\nApplication Insights in Azure Monitor (Option A) is a monitoring and analytics tool that provides insights into application performance and user behavior. It is not suitable for detecting anomalies in sensor data.\n\nMetric alerts in Azure Monitor (Option B) are used to trigger alerts based on predefined thresholds for metrics. While it could be used to generate alerts, it would require manual configuration of thresholds and would not be able to detect atypical values using machine learning-based anomaly detection.\n\nTherefore, the correct answer is D. Univariate Anomaly Detection.",
        "references": ""
    },
    {
        "question": "DRAG DROP You develop an app in O named App1 that performs sp eech-to-speech translation. You need to configure App1 to translate English to German. How should you complete the speechTransiationConf i g object? To answer, drag the appropriate values to the correct targets. Each value may be us ed once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content. NOTE: Each correct selection is worth one point.",
        "options": [
            "A.",
            "B.",
            "C.",
            "D."
        ],
        "correct": "",
        "explanation": "A. speechTranslationConfig = {\n    voice: {\n        name: \"en-US-JennyNeural\",\n        languageCode: \"en-US\"\n    },\n    targetLanguages: [\"de-DE\"]\n};\n\n**Explanation:**\n\nThe correct answer is A. The speechTranslationConfig object needs to be configured with the voice object specifying the source language (English) and the targetLanguages array specifying the target language (German).\n\nHere's why the other options are incorrect:\n\n**Option B:** This option sets the voice object's languageCode to \"de-DE\", which is the target language (German), not the source language (English).\n\n**Option C:** This option sets the targetLanguages array to [\"en-US\"], which is the source language (English), not the target language (German).\n\n**Option D:** This option sets the voice object's name to \"de-DE-JennyNeural\", which is not a valid voice name for the English language.\n\nThe correct configuration is A, where the voice object specifies the source language (English) and the targetLanguages array specifies the target language (German).",
        "references": ""
    },
    {
        "question": "You train a Conversational Language Understanding m odel to understand the natural language input of us ers. You need to evaluate the accuracy of the model befo re deploying it. What are two methods you can use? Each correct answ er presents a complete solution. NOTE: Each correct selection is worth one point.",
        "options": [
            "A. From the language authoring REST endpoint, retrie ve the model evaluation summary.",
            "B. From Language Studio, enable Active Learning, and  then validate the utterances logged for review.",
            "C. From Language Studio, select Model performance.",
            "D. From the Azure portal, enable log collection in L og Analytics, and then analyze the logs."
        ],
        "correct": "",
        "explanation": "C. From Language Studio, select Model performance. \nB. From Language Studio, enable Active Learning, and then validate the utterances logged for review.\n\nExplanation:\n\nThe correct answers are C and B. Both of these options are methods to evaluate the accuracy of a Conversational Language Understanding model.\n\nOption C is correct because Language Studio provides a Model Performance feature that allows you to evaluate the accuracy of your model. This feature provides metrics such as precision, recall, and F1 score, which help you understand how well your model is performing.\n\nOption B is also correct because Active Learning is a feature in Language Studio that allows you to validate the utterances logged for review. This feature enables you to review and correct the predictions made by your model, which helps to improve its accuracy.\n\nOption A is incorrect because the language authoring REST endpoint is used to create, update, or delete language models, but it does not provide a model evaluation summary.\n\nOption D is incorrect because enabling log collection in Log Analytics is used for monitoring and troubleshooting, but it does not provide a direct way to evaluate the accuracy of a Conversational Language Understanding model.\n\nTherefore, the correct answers are C and B.",
        "references": ""
    }
]